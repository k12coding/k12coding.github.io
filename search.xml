<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hadoop Shell命令</title>
    <url>/2021/11/26/Hadoop%20Shell%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h1 id="Hadoop-Shell命令"><a href="#Hadoop-Shell命令" class="headerlink" title="Hadoop Shell命令"></a>Hadoop Shell命令</h1><h2 id="FS-Shell"><a href="#FS-Shell" class="headerlink" title="FS Shell"></a>FS Shell</h2><p>调用文件系统(FS)Shell命令应使用 bin/hadoop fs &lt;args&gt;的形式。 所有的的FS shell命令使用URI路径作为参数。URI格式是<em>scheme://authority/path</em>。对HDFS文件系统，scheme是<em>hdfs</em>，对本地文件系统，scheme是<em>file</em>。其中scheme和authority参数都是可选的，如果未加指定，就会使用配置中指定的默认scheme。一个HDFS文件或目录比如*/parent/child<em>可以表示成</em>hdfs://namenode:namenodeport/parent/child<em>，或者更简单的</em>/parent/child<em>（假设你配置文件中的默认值是</em>namenode:namenodeport<em>）。大多数FS Shell命令的行为和对应的Unix Shell命令类似，不同之处会在下面介绍各命令使用详情时指出。出错信息会输出到</em>stderr<em>，其他信息输出到</em>stdout*。</p>
<span id="more"></span>

<h3 id="cat"><a href="#cat" class="headerlink" title="cat"></a>cat</h3><p>使用方法：<code>hadoop fs -cat URI [URI …]</code></p>
<p>将路径指定文件的内容输出到<em>stdout</em>。</p>
<p>示例：</p>
<ul>
<li><code>hadoop fs -cat hdfs://host1:port1/file1 hdfs://host2:port2/file2</code></li>
<li><code>hadoop fs -cat file:///file3 /user/hadoop/file4</code></li>
</ul>
<p>返回值：成功返回0，失败返回-1。</p>
<h3 id="chgrp"><a href="#chgrp" class="headerlink" title="chgrp"></a>chgrp</h3><p>使用方法：hadoop fs -chgrp [-R] GROUP URI [URI …] </p>
<p>改变文件所属的组。使用-R将使改变在目录结构下递归进行。命令的使用者必须是文件的所有者或者超级用户。更多的信息请参见<a href="http://hadoop.apache.org/docs/r3.2.2/hadoop-project-dist/hadoop-hdfs/HdfsPermissionsGuide.html">HDFS Permissions Guide</a>。</p>
<h3 id="chmod"><a href="#chmod" class="headerlink" title="chmod"></a>chmod</h3><p>使用方法：<code>hadoop fs -chmod [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; URI [URI …]</code></p>
<p>改变文件的权限。使用-R将使改变在目录结构下递归进行。命令的使用者必须是文件的所有者或者超级用户。更多的信息请参见<a href="http://hadoop.apache.org/docs/r3.2.2/hadoop-project-dist/hadoop-hdfs/HdfsPermissionsGuide.html">HDFS Permissions Guide</a>。</p>
<h3 id="chown"><a href="#chown" class="headerlink" title="chown"></a>chown</h3><p>使用方法：<code>hadoop fs -chown [-R] [OWNER][:[GROUP]] URI [URI ]</code></p>
<p>改变文件的拥有者。使用-R将使改变在目录结构下递归进行。命令的使用者必须是超级用户。更多的信息请参见<a href="http://hadoop.apache.org/docs/r3.2.2/hadoop-project-dist/hadoop-hdfs/HdfsPermissionsGuide.html">HDFS Permissions Guide</a>。</p>
<h3 id="copyFromLocal"><a href="#copyFromLocal" class="headerlink" title="copyFromLocal"></a>copyFromLocal</h3><p>使用方法：<code>hadoop fs -copyFromLocal &lt;localsrc&gt; URI</code></p>
<p>除了限定源路径是一个本地文件外，和<a href="#put"><strong>put</strong></a>命令相似。</p>
<h3 id="copyToLocal"><a href="#copyToLocal" class="headerlink" title="copyToLocal"></a>copyToLocal</h3><p>使用方法：<code>hadoop fs -copyToLocal [-ignorecrc] [-crc] URI &lt;localdst&gt;</code></p>
<p>除了限定目标路径是一个本地文件外，和<a href="#get"><strong>get</strong></a>命令类似。</p>
<h3 id="cp"><a href="#cp" class="headerlink" title="cp"></a>cp</h3><p>使用方法：<code>hadoop fs -cp URI [URI …] &lt;dest&gt;</code></p>
<p>将文件从源路径复制到目标路径。这个命令允许有多个源路径，此时目标路径必须是一个目录。<br>示例：</p>
<ul>
<li><code>hadoop fs -cp /user/hadoop/file1 /user/hadoop/file2</code></li>
<li><code>hadoop fs -cp /user/hadoop/file1 /user/hadoop/file2 /user/hadoop/dir</code></li>
</ul>
<p>返回值：成功返回0，失败返回-1。</p>
<h3 id="du"><a href="#du" class="headerlink" title="du"></a>du</h3><p>使用方法：<code>hadoop fs -du URI [URI …]</code></p>
<p>显示目录中所有文件的大小，或者当只指定一个文件时，显示此文件的大小。<br>示例：<br><code>hadoop fs -du /user/hadoop/dir1 /user/hadoop/file1 hdfs://host:port/user/hadoop/dir1</code><br>返回值：成功返回0，失败返回-1。</p>
<h3 id="dus"><a href="#dus" class="headerlink" title="dus"></a>dus</h3><p>使用方法：<code>hadoop fs -dus &lt;args&gt;</code></p>
<p>显示文件的大小。</p>
<h3 id="expunge"><a href="#expunge" class="headerlink" title="expunge"></a>expunge</h3><p>使用方法：<code>hadoop fs -expunge</code></p>
<p>清空回收站。请参考 <a href="http://hadoop.apache.org/docs/r3.2.2/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html#File_Deletes_and_Undeletes">HDFS Architecture guide</a> 文档以获取更多关于回收站特性的信息。</p>
<h3 id="get"><a href="#get" class="headerlink" title="get"></a>get</h3><p>使用方法：<code>hadoop fs -get [-ignorecrc] [-crc] &lt;src&gt; &lt;localdst&gt;</code></p>
<p>复制文件到本地文件系统。可用-ignorecrc选项复制CRC校验失败的文件。使用-crc选项复制文件以及CRC信息。</p>
<p>示例：</p>
<ul>
<li><code>hadoop fs -get /user/hadoop/file localfile</code></li>
<li><code>hadoop fs -get hdfs://host:port/user/hadoop/file localfile</code></li>
</ul>
<p>返回值：成功返回0，失败返回-1。</p>
<h3 id="getmerge"><a href="#getmerge" class="headerlink" title="getmerge"></a>getmerge</h3><p>使用方法：<code>hadoop fs -getmerge &lt;src&gt; &lt;localdst&gt; [addnl]</code></p>
<p>接受一个源目录和一个目标文件作为输入，并且将源目录中所有的文件连接成本地目标文件。addnl是可选的，用于指定在每个文件结尾添加一个换行符。</p>
<h3 id="ls"><a href="#ls" class="headerlink" title="ls"></a>ls</h3><p>使用方法：<code>hadoop fs -ls &lt;args&gt;</code></p>
<p>如果是文件，则按照如下格式返回文件信息：<br>文件名 &lt;副本数&gt; 文件大小 修改日期 修改时间 权限 用户ID 组ID<br>如果是目录，则返回它直接子文件的一个列表，就像在Unix中一样。目录返回列表的信息如下：<br>目录名 &lt;dir&gt; 修改日期 修改时间 权限 用户ID 组ID<br>示例：</p>
<ul>
<li><code>hadoop fs -ls /user/hadoop/file1 /user/hadoop/file2 hdfs://host:port/user/hadoop/dir1 /nonexistentfile</code></li>
</ul>
<p>返回值：成功返回0，失败返回-1。</p>
<h3 id="lsr"><a href="#lsr" class="headerlink" title="lsr"></a>lsr</h3><p>使用方法：<code>hadoop fs -lsr &lt;args&gt;</code><br>ls命令的递归版本。类似于Unix中的ls -R。</p>
<h3 id="mkdir"><a href="#mkdir" class="headerlink" title="mkdir"></a>mkdir</h3><p>使用方法：<code>hadoop fs -mkdir &lt;paths&gt;</code></p>
<p>接受路径指定的uri作为参数，创建这些目录。其行为类似于Unix的mkdir -p，它会创建路径中的各级父目录。</p>
<p>示例：</p>
<ul>
<li><code>hadoop fs -mkdir /user/hadoop/dir1 /user/hadoop/dir2</code></li>
<li><code>hadoop fs -mkdir hdfs://host1:port1/user/hadoop/dir hdfs://host2:port2/user/hadoop/dir</code></li>
</ul>
<p>返回值：成功返回0，失败返回-1。</p>
<h3 id="movefromLocal"><a href="#movefromLocal" class="headerlink" title="movefromLocal"></a>movefromLocal</h3><p>使用方法：<code>dfs -moveFromLocal &lt;src&gt; &lt;dst&gt;</code></p>
<p>输出一个”not implemented“信息。</p>
<h3 id="mv"><a href="#mv" class="headerlink" title="mv"></a>mv</h3><p>使用方法：<code>hadoop fs -mv URI [URI …] &lt;dest&gt;</code></p>
<p>将文件从源路径移动到目标路径。这个命令允许有多个源路径，此时目标路径必须是一个目录。不允许在不同的文件系统间移动文件。<br>示例：</p>
<ul>
<li><code>hadoop fs -mv /user/hadoop/file1 /user/hadoop/file2</code></li>
<li><code>hadoop fs -mv hdfs://host:port/file1 hdfs://host:port/file2 hdfs://host:port/file3 hdfs://host:port/dir1</code></li>
</ul>
<p>返回值：成功返回0，失败返回-1。</p>
<h3 id="put"><a href="#put" class="headerlink" title="put"></a>put</h3><p>使用方法：<code>hadoop fs -put &lt;localsrc&gt; ... &lt;dst&gt;</code></p>
<p>从本地文件系统中复制单个或多个源路径到目标文件系统。也支持从标准输入中读取输入写入目标文件系统。</p>
<ul>
<li><code>hadoop fs -put localfile /user/hadoop/hadoopfile</code></li>
<li><code>hadoop fs -put localfile1 localfile2 /user/hadoop/hadoopdir</code></li>
<li><code>hadoop fs -put localfile hdfs://host:port/hadoop/hadoopfile</code></li>
<li><code>hadoop fs -put - hdfs://host:port/hadoop/hadoopfile</code><br>从标准输入中读取输入。</li>
</ul>
<p>返回值：成功返回0，失败返回-1。</p>
<h3 id="rm"><a href="#rm" class="headerlink" title="rm"></a>rm</h3><p>使用方法：<code>hadoop fs -rm URI [URI …]</code></p>
<p>删除指定的文件。只删除非空目录和文件。请参考rmr命令了解递归删除。<br>示例：</p>
<ul>
<li><code>hadoop fs -rm hdfs://host:port/file /user/hadoop/emptydir</code></li>
</ul>
<p>返回值：成功返回0，失败返回-1。</p>
<h3 id="rmr"><a href="#rmr" class="headerlink" title="rmr"></a>rmr</h3><p>使用方法：<code>hadoop fs -rmr URI [URI …]</code></p>
<p>delete的递归版本。<br>示例：</p>
<ul>
<li><code>hadoop fs -rmr /user/hadoop/dir</code></li>
<li><code>hadoop fs -rmr hdfs://host:port/user/hadoop/dir</code></li>
</ul>
<p>返回值：成功返回0，失败返回-1。</p>
<h3 id="setrep"><a href="#setrep" class="headerlink" title="setrep"></a>setrep</h3><p>使用方法：<code>hadoop fs -setrep [-R] &lt;path&gt;</code></p>
<p>改变一个文件的副本系数。-R选项用于递归改变目录下所有文件的副本系数。</p>
<p>示例：</p>
<ul>
<li><code>hadoop fs -setrep -w 3 -R /user/hadoop/dir1</code></li>
</ul>
<p>返回值：成功返回0，失败返回-1。</p>
<h3 id="stat"><a href="#stat" class="headerlink" title="stat"></a>stat</h3><p>使用方法：<code>hadoop fs -stat URI [URI …]</code></p>
<p>返回指定路径的统计信息。</p>
<p>示例：</p>
<ul>
<li><code>hadoop fs -stat path</code></li>
</ul>
<p>返回值：成功返回0，失败返回-1。</p>
<h3 id="tail"><a href="#tail" class="headerlink" title="tail"></a>tail</h3><p>使用方法：<code>hadoop fs -tail [-f] URI</code></p>
<p>将文件尾部1K字节的内容输出到stdout。支持-f选项，行为和Unix中一致。</p>
<p>示例：</p>
<ul>
<li><code>hadoop fs -tail pathname</code></li>
</ul>
<p>返回值：成功返回0，失败返回-1。</p>
<h3 id="test"><a href="#test" class="headerlink" title="test"></a>test</h3><p>使用方法：<code>hadoop fs -test -[ezd] URI</code></p>
<p>选项：<br>-e 检查文件是否存在。如果存在则返回0。<br>-z 检查文件是否是0字节。如果是则返回0。<br>-d 如果路径是个目录，则返回1，否则返回0。</p>
<p>示例：</p>
<ul>
<li><code>hadoop fs -test -e filename</code></li>
</ul>
<h3 id="text"><a href="#text" class="headerlink" title="text"></a>text</h3><p>使用方法：<code>hadoop fs -text &lt;src&gt;</code></p>
<p>将源文件输出为文本格式。允许的格式是zip和TextRecordInputStream。</p>
<h3 id="touchz"><a href="#touchz" class="headerlink" title="touchz"></a>touchz</h3><p>使用方法：<code>hadoop fs -touchz URI [URI …]</code></p>
<p>创建一个0字节的空文件。</p>
<p>示例：</p>
<ul>
<li><code>hadoop -touchz pathname</code></li>
</ul>
<p>返回值：成功返回0，失败返回-1。</p>
]]></content>
  </entry>
  <entry>
    <title>Hadoop基础知识</title>
    <url>/2021/11/25/Hadoop%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<h1 id="一、Hadoop"><a href="#一、Hadoop" class="headerlink" title="一、Hadoop"></a>一、Hadoop</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>狭义上：以Hadoop软件本身（hadoop.apache.org），指一个用于大数据分布式存储(HDFS)，分布式计算(MapReduce)和资源调度(YARN)的平台，这三样只能用来做离线批处理，不能用于实时处理，因此才需要生态系统的其他的组件。</p>
<p>广义上：指的是hadoop的生态系统，即其他各种组件在内的一整套软件（sqoop，flume，spark，flink，hbase，kafka，cdh环境等）。hadoop生态系统是一个很庞大的概念，hadoop只是其中最重要最基础的部分，生态系统的每一个子系统只结局的某一个特定的问题域。不是一个全能系统，而是多个小而精的系统。</p>
<h2 id="组成"><a href="#组成" class="headerlink" title="组成"></a>组成</h2><p>Hadoop common：提供一些通用的功能支持其他hadoop模块。</p>
<p><strong>Hadoop Distributed File System</strong>：即分布式文件系统，简称HDFS。主要用来做数据存储，并提供对应用数据高吞吐量的访问。</p>
<p><strong>Hadoop MapReduce</strong>：基于yarn的，能用来并行处理大数据集的计算框架。</p>
<p><strong>Hadoop Yarn</strong>：用于作业调度和集群资源管理的框架。</p>
<h3 id="hdfs支持的三种模式"><a href="#hdfs支持的三种模式" class="headerlink" title="hdfs支持的三种模式"></a>hdfs支持的三种模式</h3><ul>
<li>Local (Standalone) Mode ：本地模式，不启动进程，实际工作中从来没用过</li>
<li>Pseudo-Distributed Mode：伪分布式，启动单个进程（1大 小），应用场景：学习</li>
<li>Fully-Distributed Mode    集群模式，启动多个进程（2个大多个小），应用场景：生产（CDH,按量付费）</li>
</ul>
<p>二、mapreduce on yarn</p>
<p>三、hdfs放置策略</p>
]]></content>
  </entry>
  <entry>
    <title>Windows环境下JDK1.8.0安装与环境变量配置</title>
    <url>/2021/11/17/Windows%E7%8E%AF%E5%A2%83%E4%B8%8BJDK%E5%AE%89%E8%A3%85%E4%B8%8E%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h3 id="一、准备工具"><a href="#一、准备工具" class="headerlink" title="一、准备工具"></a>一、准备工具</h3><h4 id="1-JDK"><a href="#1-JDK" class="headerlink" title="1.JDK"></a>1.JDK</h4><p>JDK安装包：jdk-8u202-windows-x64.exe<br><a href="https://www.oracle.com/java/technologies/javase/javase8-archive-downloads.html">https://www.oracle.com/java/technologies/javase/javase8-archive-downloads.html</a><br>链接：<a href="https://pan.baidu.com/s/1_xEszoPjFIyic61FbFo2cg">https://pan.baidu.com/s/1_xEszoPjFIyic61FbFo2cg</a><br>提取码：x6v8</p>
<h4 id="2-安装前："><a href="#2-安装前：" class="headerlink" title="2.安装前："></a>2.安装前：</h4><p>检验是否配置jdk ctrl+R 运行cmd 分别输入java，javac， java -version （java 和 -version 之间有空格）。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">C:\Windows\System32&gt;javac</span><br><span class="line">&#x27;javac&#x27; 不是内部或外部命令，也不是可运行的程序</span><br><span class="line">或批处理文件。</span><br><span class="line">C:\Windows\System32&gt;java -version</span><br><span class="line">&#x27;java&#x27; 不是内部或外部命令，也不是可运行的程序</span><br><span class="line">或批处理文件。</span><br></pre></td></tr></table></figure>



<h3 id="二、方法-步骤"><a href="#二、方法-步骤" class="headerlink" title="二、方法/步骤"></a>二、方法/步骤</h3><span id="more"></span>
<h4 id="1-安装JDK，JRE，-选择安装目录"><a href="#1-安装JDK，JRE，-选择安装目录" class="headerlink" title="1. 安装JDK，JRE， 选择安装目录"></a>1. 安装JDK，JRE， 选择安装目录</h4><p>安装过程中会出现两次 安装提示 。第一次是安装 jdk ，第二次是安装 jre 。建议两个都安装在同一个java文件夹中的不同文件夹中。（不能都安装在java文件夹的根目录下，jdk和jre安装在同一文件夹会出错）。</p>
<p>（1）双击jdk-8u202-windows-x64.exe 进行安装。</p>
<p> <img src="/2021/11/17/Windows%E7%8E%AF%E5%A2%83%E4%B8%8BJDK%E5%AE%89%E8%A3%85%E4%B8%8E%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/image-1.png"></p>
<p>（2）点击“下一步”继续。</p>
<p> <img src="/2021/11/17/Windows%E7%8E%AF%E5%A2%83%E4%B8%8BJDK%E5%AE%89%E8%A3%85%E4%B8%8E%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/image-2.png"></p>
<p>（3）选择安装路径，然后点击下一步。</p>
<p>默认是在C盘。我这里选择的是E盘。路径为：E:\Java\jdk1.8.0_202\</p>
<p> <img src="/2021/11/17/Windows%E7%8E%AF%E5%A2%83%E4%B8%8BJDK%E5%AE%89%E8%A3%85%E4%B8%8E%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/image-3.png"></p>
<p>（4）中途会进行JRE的安装。选择JRE安装的路径，点击下一步。默认会选择C盘。</p>
<p> <img src="/2021/11/17/Windows%E7%8E%AF%E5%A2%83%E4%B8%8BJDK%E5%AE%89%E8%A3%85%E4%B8%8E%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/image-4.png"> </p>
<p>因为在选择的时候不能新建。自己新建一个文件夹：jre1.8.0_202文件夹。更改路径：E:\Java\jre1.8.0_202\</p>
<p> <img src="/2021/11/17/Windows%E7%8E%AF%E5%A2%83%E4%B8%8BJDK%E5%AE%89%E8%A3%85%E4%B8%8E%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/image-5.png"> </p>
<p>（5）点击下一步，等待安装完成。</p>
<p> <img src="/2021/11/17/Windows%E7%8E%AF%E5%A2%83%E4%B8%8BJDK%E5%AE%89%E8%A3%85%E4%B8%8E%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/image-6.png"> </p>
<p>（6）安装完成，点击关闭。</p>
<p> <img src="/2021/11/17/Windows%E7%8E%AF%E5%A2%83%E4%B8%8BJDK%E5%AE%89%E8%A3%85%E4%B8%8E%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/image-7.png"></p>
<h4 id="2-配置系统环境"><a href="#2-配置系统环境" class="headerlink" title="2.配置系统环境"></a>2.配置系统环境</h4><p>配置环境变量：右击“我的电脑”–&gt;”属性”–&gt;”高级系统设置”–&gt;”环境变量”。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CLASSPATH</span><br><span class="line">.;%JAVA_HOME%\lib;%JAVA_HOME%\lib\dt.jar;%JAVA_HOME%\lib\tools.jar</span><br><span class="line"></span><br><span class="line">JAVA_HOME</span><br><span class="line">E:\Java\jdk1.8.0_202</span><br><span class="line"></span><br><span class="line">PATH</span><br><span class="line">%JAVA_HOME%\bin;%JAVA_HOME%\jre\bin</span><br></pre></td></tr></table></figure>

<p><strong>（1）JAVA_HOME环境变量。</strong></p>
<p>作用：它指向jdk的安装目录，Eclipse/NetBeans/Tomcat等软件就是通过搜索JAVA_HOME变量来找到并使用安装好的jdk。<br>配置方法：在系统变量里点击新建，变量名填写JAVA_HOME，变量值填写JDK的安装路径。（根据自己的安装路径填写）</p>
<p>JAVA_HOME：E:\Java\jdk1.8.0_202</p>
<p> <img src="/2021/11/17/Windows%E7%8E%AF%E5%A2%83%E4%B8%8BJDK%E5%AE%89%E8%A3%85%E4%B8%8E%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/image-8.png"></p>
<p><strong>（2）CLASSPATH环境变量。</strong></p>
<p>作用：是指定类搜索路径，要使用已经编写好的类，前提当然是能够找到它们了，JVM就是通过CLASSPTH来寻找类的。我们需要把jdk安装目录下的lib子目录中的dt.jar和tools.jar设置到CLASSPATH中，当然，当前目录“.”也必须加入到该变量中。<br>配置方法：<br>新建CLASSPATH变量，变量值为：.;%JAVA_HOME%\lib;%JAVA_HOME%\lib\tools.jar 。CLASSPATH变量名字，可以大写也可以小写。注意不要忘记前面的点和中间的分号。且要在英文输入的状态下的分号和逗号。</p>
<p>CLASSPATH ：.;%JAVA_HOME%\lib;%JAVA_HOME%\lib\dt.jar;%JAVA_HOME%\lib\tools.jar;</p>
<p> <img src="/2021/11/17/Windows%E7%8E%AF%E5%A2%83%E4%B8%8BJDK%E5%AE%89%E8%A3%85%E4%B8%8E%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/image-9.png"> </p>
<p><strong>（3）path环境变量</strong></p>
<p>作用：指定命令搜索路径，在i命令行下面执行命令如javac编译java程序时，它会到PATH变量所指定的路径中查找看是否能找到相应的命令程序。我们需要把jdk安装目录下的bin目录增加到现有的PATH变量中，bin目录中包含经常要用到的可执行文件如javac/java/javadoc等待，设置好PATH变量后，就可以在任何目录下执行javac/java等工具了。</p>
<p>在系统变量里找到Path变量，这是系统自带的，不用新建。双击Path，由于原来的变量值已经存在，故应在已有的<strong>变量前追加</strong>上“;%JAVA_HOME%\bin;%JAVA_HOME%\jre\bin”。注意前面的分号。</p>
<p>Path：%JAVA_HOME%\bin;%JAVA_HOME%\jre\bin;</p>
<p> <img src="/2021/11/17/Windows%E7%8E%AF%E5%A2%83%E4%B8%8BJDK%E5%AE%89%E8%A3%85%E4%B8%8E%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/image-10.png"> <img src="/2021/11/17/Windows%E7%8E%AF%E5%A2%83%E4%B8%8BJDK%E5%AE%89%E8%A3%85%E4%B8%8E%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/image-11.png"> </p>
<p>或者：</p>
<p> <img src="/2021/11/17/Windows%E7%8E%AF%E5%A2%83%E4%B8%8BJDK%E5%AE%89%E8%A3%85%E4%B8%8E%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/image-12.png"> </p>
<p>然后点击确定完成。</p>
<h3 id="三、-测试环境。"><a href="#三、-测试环境。" class="headerlink" title="三、 测试环境。"></a>三、 测试环境。</h3><p>检验是否配置成功 ctrl+R 运行cmd 分别输入<code>java</code>，<code>javac</code>， <code>java -version</code>。</p>
<p><strong>1.Java</strong></p>
<p> <img src="/2021/11/17/Windows%E7%8E%AF%E5%A2%83%E4%B8%8BJDK%E5%AE%89%E8%A3%85%E4%B8%8E%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/image-13.png"> </p>
<p><strong>2.Javac</strong></p>
<p> <img src="/2021/11/17/Windows%E7%8E%AF%E5%A2%83%E4%B8%8BJDK%E5%AE%89%E8%A3%85%E4%B8%8E%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/image-14.png"></p>
<p><strong>3.java –version</strong></p>
<p> <img src="/2021/11/17/Windows%E7%8E%AF%E5%A2%83%E4%B8%8BJDK%E5%AE%89%E8%A3%85%E4%B8%8E%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/image-15.png"> </p>
<p>若如图所示 显示版本信息 则说明安装和配置成功!</p>
]]></content>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2021/09/18/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>什么是尾递归</title>
    <url>/2021/11/19/%E4%BB%80%E4%B9%88%E6%98%AF%E5%B0%BE%E9%80%92%E5%BD%92/</url>
    <content><![CDATA[<h3 id="尾递归"><a href="#尾递归" class="headerlink" title="尾递归"></a>尾递归</h3><h4 id="一、概念"><a href="#一、概念" class="headerlink" title="一、概念"></a>一、概念</h4><p>​    如果一个函数中所有递归形式的调用都出现在函数的末尾，我们称这个递归函数是尾递归的。当递归调用是整个函数体中最后执行的语句且<strong>它的返回值不属于表达式的一部分</strong>时，这个递归调用就是尾递归。尾递归函数的特点是在<strong>回归过程中不用做任何操作</strong>，这个特性很重要，因为大多数现代的编译器会利用这种特点自动生成优化的代码。</p>
<span id="more"></span>

<h4 id="二、实例"><a href="#二、实例" class="headerlink" title="二、实例"></a>二、实例</h4><p>以递归的形式计算阶乘：</p>
<p>线性递归:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">long</span> <span class="title">Rescuvie</span><span class="params">( <span class="keyword">long</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (n == <span class="number">1</span>) ? <span class="number">1</span> : n * Rescuvie(n - <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>尾递归:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">long</span> <span class="title">TailRescuvie</span><span class="params">( <span class="keyword">long</span> n, <span class="keyword">long</span> a)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (n == <span class="number">1</span>) ? a : TailRescuvie(n - <span class="number">1</span>, a * n); </span><br><span class="line">&#125; </span><br><span class="line"><span class="function"><span class="keyword">long</span> <span class="title">TailRescuvie</span><span class="params">( <span class="keyword">long</span> n)</span> </span>&#123;<span class="comment">//封装用的</span></span><br><span class="line">    <span class="keyword">return</span> (n == <span class="number">0</span>) ? <span class="number">1</span> : TailRescuvie(n, <span class="number">1</span>); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当n = 5时<br>对于传统线性递归, 他的递归过程如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Rescuvie(5)</span><br><span class="line"></span><br><span class="line">&#123;5 * Rescuvie(4)&#125;</span><br><span class="line"></span><br><span class="line">&#123;5 * &#123;4 * Rescuvie(3)&#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;5 * &#123;4 * &#123;3 * Rescuvie(2)&#125;&#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;5 * &#123;4 * &#123;3 * &#123;2 * Rescuvie(1)&#125;&#125;&#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;5 * &#123;4 * &#123;3 * &#123;2 * 1&#125;&#125;&#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;5 * &#123;4 * &#123;3 * 2&#125;&#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;5 * &#123;4 * 6&#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;5 * 24&#125;</span><br><span class="line"></span><br><span class="line">120</span><br></pre></td></tr></table></figure>

<p>对于尾递归, 他的递归过程如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TailRescuvie(5)                  // 所以在运算上和内存占用上节省了很多,直接传回结果</span><br><span class="line"></span><br><span class="line">TailRescuvie(5, 1)                         return 120</span><br><span class="line">                                                 ↑</span><br><span class="line">TailRescuvie(4, 5)                         return 120</span><br><span class="line">                                                 ↑</span><br><span class="line">TailRescuvie(3, 20)                        return 120</span><br><span class="line">                                                 ↑</span><br><span class="line">TailRescuvie(2, 60)                        return 120</span><br><span class="line">                                                 ↑</span><br><span class="line">TailRescuvie(1, 120)                       return 120</span><br><span class="line">                                                 ↑</span><br><span class="line">120                                //当运行到最后时,return a =&gt; return 120 ,将120返回上一级</span><br></pre></td></tr></table></figure>

<p>说明：其实尾递归也需要下层往上层返回结果，但在返回的过程中不用再做计算，依次返回结果即可。从上可以看到尾递归把返回结果放到了调用的参数里。这个细小的变化导致，TailRescuvie(n)不必像以前一样，非要等到拿到了TailRescuvie(n-1)的返回值，才能计算它自己的返回结果,它完全就等于TailRescuvie(n-1)的返回值。因此理论上：TailRescuvie(n)在调用tailTailRescuvie(n-1)前，完全就可以先销毁自己放在栈上的东西。</p>
<h4 id="三、优势"><a href="#三、优势" class="headerlink" title="三、优势"></a>三、优势</h4><p>​    与普通递归相比，由于尾递归的调用处于方法的最后，因此方法之前所积累下的各种状态对于递归调用结果已经没有任何意义，因此每一个函数在调用下一个函数之前，都能做到先把当前自己占用的栈给先释放了，尾递归的调用链上可以做到只有一个函数在使用栈，因此可以无限地调用！</p>
<p>​    但是，上述的优化是在<strong>某些语言</strong>编译器的优化支持上实现的，尾递归本身并不能消除函数调用栈过长的问题。在一般递归函数func()中，func(n)是依赖于 func(n-1) 的，func(n) 只有在得到 func(n-1) 的结果之后，才能计算它自己的返回值，因此理论上，在 func(n-1) 返回之前，func(n)，不能结束返回。因此func(n)就必须保留它在栈上的数据，直到func(n-1)先返回，而尾递归的实现则可以在编译器的帮助下，消除这个限制。</p>
<h4 id="四、尾递归的调用栈优化特性"><a href="#四、尾递归的调用栈优化特性" class="headerlink" title="四、尾递归的调用栈优化特性"></a>四、尾递归的调用栈优化特性</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">int tail_func(int n, int res)&#123;</span><br><span class="line">     if (n &lt;= 1) return res;</span><br><span class="line">     return tail_func(n - 1, n * res);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()&#123;</span><br><span class="line">    int dummy[1024*1024]; // 尽可能占用栈。</span><br><span class="line">    tail_func(2048*2048, 1);</span><br><span class="line">    return 1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>​    上面这个程序在开了编译优化和没开编译优化的情况下编出来的结果是<strong>不一样</strong>的，如果不开启优化，直接 <code>gcc -o tr func_tail.c</code> 编译然后运行的话，程序会爆栈崩溃，但如果开优化的话：<code>gcc -o tr -O2 func_tail.c</code>，上面的程序最后就能正常运行。 这里面的原因就在于，尾递归的写法只是具备了使当前函数在调用下一个函数前把当前占有的栈销毁，但是会不会真的这样做，是要具体看编译器是否最终这样做，如果在语言层面上，没有规定要优化这种尾调用，那编译器就可以有自己的选择来做不同的实现，在这种情况下，尾递归就不一定能解决一般递归的问题。</p>
<p>参考链接:</p>
<p><a href="https://blog.csdn.net/h330531987/article/details/76218956">什么是尾递归,尾递归的优势以及语言支持情况说明</a></p>
<p><a href="https://www.cnblogs.com/catch/p/3495450.html">说说尾递归</a></p>
]]></content>
  </entry>
  <entry>
    <title>将Hexo部署到GitHub</title>
    <url>/2021/10/24/%E5%B0%86Hexo%E9%83%A8%E7%BD%B2%E5%88%B0GitHub/</url>
    <content><![CDATA[<p>参考<a href="https://hexo.io/zh-cn/docs">Hexo文档</a> </p>
<span id="more"></span>

<h2 id="一、安装Git"><a href="#一、安装Git" class="headerlink" title="一、安装Git"></a>一、安装Git</h2><ol>
<li><p><a href="https://gitforwindows.org/">gitforwindows</a> 下载安装</p>
</li>
<li><p>安装完查看git版本：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git --version</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="二、安装Node-js"><a href="#二、安装Node-js" class="headerlink" title="二、安装Node.js"></a>二、安装Node.js</h2><ol>
<li><p><a href="https://nodejs.org/en/download/">node.js</a> 选择LTS的window版本，下载安装</p>
</li>
<li><p>安装完查看node.js版本</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">node -v</span><br><span class="line">npm -v</span><br></pre></td></tr></table></figure></li>
<li><p>更改npm镜像源：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm config set registry https://registry.npm.taobao.org/</span><br></pre></td></tr></table></figure></li>
<li><p>查看npm镜像源：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm get registry https://registry.npm.taobao.org/</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="三、安装Hexo"><a href="#三、安装Hexo" class="headerlink" title="三、安装Hexo"></a>三、安装Hexo</h2><ol>
<li><p>安装Hexo</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="四、建站"><a href="#四、建站" class="headerlink" title="四、建站"></a>四、建站</h2><ol>
<li><p>初始化博客目录</p>
<p>安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo init &lt;folder&gt;</span><br><span class="line">cd &lt;folder&gt;</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure></li>
<li><p>常用命令：</p>
<ul>
<li>清理缓存： <code>hexo clean</code></li>
<li>生成静态文件： <code>hexo g/generate</code></li>
<li>生成静态文件： <code>hexo s/server</code></li>
<li>组合版：<code>hexo clean &amp;&amp; hexo g &amp;&amp; hexo s</code></li>
<li>发布到github：<code>hexo d</code></li>
</ul>
<p>本地访问地址：<a href="http://localhost:4000/">http://localhost:4000</a></p>
</li>
<li><p>修改网站基本配置信息参考<a href="https://hexo.io/zh-cn/docs/configuration">配置</a></p>
</li>
</ol>
<h2 id="五、将hexo部署到GitHub"><a href="#五、将hexo部署到GitHub" class="headerlink" title="五、将hexo部署到GitHub"></a>五、将hexo部署到GitHub</h2><ol>
<li><p>生成SSH添加到GitHub</p>
<p>生成key，可以git部署网站</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot;</span><br></pre></td></tr></table></figure>

<p>然后需要配置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git config --global user.email “you@example.com”</span><br><span class="line">git config --global user.name “Your Name”</span><br></pre></td></tr></table></figure>

<p>将这个文件拷贝到git的<a href="https://github.com/settings/keys">https://github.com/settings/keys</a><br>查看是否配置成功</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure></li>
<li><p>GitHub创建个人仓库<br>新建一个 repository。如果你希望你的站点能通过域名 <code>&lt;你的 GitHub 用户名&gt;.github.io</code> 访问，你的 repository 应该直接命名为 <code>&lt;你的 GitHub 用户名&gt;.github.io</code>。</p>
</li>
<li><p>安装 hexo-deployer-git.：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure></li>
<li><p>在 _config.yml（如果有已存在的请删除）添加如下配置：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">deploy:  </span><br><span class="line">    type: git  </span><br><span class="line">    repo: https://github.com/&lt;username&gt;/&lt;project&gt; </span><br></pre></td></tr></table></figure></li>
<li><p>运行 hexo </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">clean &amp;&amp; hexo deploy</span><br></pre></td></tr></table></figure></li>
<li><p>查看 <code>username.github.io</code> 上的网页是否部署成功。</p>
</li>
</ol>
<h2 id="六、发布文章"><a href="#六、发布文章" class="headerlink" title="六、发布文章"></a>六、发布文章</h2><ol>
<li><p>创建文章</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo new post &quot;title&quot;</span><br></pre></td></tr></table></figure></li>
<li><p>然后用编辑器修改好文本，发布</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo clean &amp;&amp; hexo g &amp;&amp; hexo s</span><br><span class="line">hexo clean &amp;&amp; hexo deploy</span><br></pre></td></tr></table></figure></li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>简明 VIM 练级攻略（转载）</title>
    <url>/2021/12/02/%E7%AE%80%E6%98%8E-VIM-%E7%BB%83%E7%BA%A7%E6%94%BB%E7%95%A5%EF%BC%88%E8%BD%AC%E8%BD%BD%EF%BC%89/</url>
    <content><![CDATA[<p>vim的学习曲线相当的大（参看<a href="https://coolshell.cn/articles/3125.html">各种文本编辑器的学习曲线</a>），所以，如果你一开始看到的是一大堆VIM的命令分类，你一定会对这个编辑器失去兴趣的。下面的文章翻译自《<a href="http://yannesposito.com/Scratch/en/blog/Learn-Vim-Progressively/">Learn Vim Progressively</a>》，我觉得这是给新手最好的VIM的升级教程了，没有列举所有的命令，只是列举了那些最有用的命令。非常不错。</p>
<p>——————————正文开始——————————</p>
<p>你想以最快的速度学习人类史上最好的文本编辑器VIM吗？你先得懂得如何在VIM幸存下来，然后一点一点地学习各种戏法。</p>
<p><a href="https://www.vim.org/">Vim</a> the Six Billion Dollar editor</p>
<blockquote>
<p>Better, Stronger, Faster.</p>
</blockquote>
<p>学习 <a href="https://www.vim.org/">vim</a> 并且其会成为你最后一个使用的文本编辑器。没有比这个更好的文本编辑器了，非常地难学，但是却不可思议地好用。</p>
<p>我建议下面这四个步骤：</p>
<ol>
<li>存活</li>
<li>感觉良好</li>
<li>觉得更好，更强，更快</li>
<li>使用VIM的超能力</li>
</ol>
<p>当你走完这篇文章，你会成为一个vim的 superstar。</p>
<p>在开始学习以前，我需要给你一些警告：</p>
<ul>
<li>学习vim在开始时是痛苦的。</li>
<li>需要时间</li>
<li>需要不断地练习，就像你学习一个乐器一样。</li>
<li>不要期望你能在3天内把vim练得比别的编辑器更有效率。</li>
<li>事实上，你需要2周时间的苦练，而不是3天。</li>
</ul>
<p>目录</p>
<p><a href="https://coolshell.cn/articles/5426.html#%E7%AC%AC%E4%B8%80%E7%BA%A7_-_%E5%AD%98%E6%B4%BB">第一级 – 存活</a><a href="https://coolshell.cn/articles/5426.html#%E7%AC%AC%E4%BA%8C%E7%BA%A7_-_%E6%84%9F%E8%A7%89%E8%89%AF%E5%A5%BD">第二级 – 感觉良好</a><a href="https://coolshell.cn/articles/5426.html#%E7%AC%AC%E4%B8%89%E7%BA%A7_-_%E6%9B%B4%E5%A5%BD%EF%BC%8C%E6%9B%B4%E5%BC%BA%EF%BC%8C%E6%9B%B4%E5%BF%AB">第三级 – 更好，更强，更快</a><a href="https://coolshell.cn/articles/5426.html#%E6%9B%B4%E5%A5%BD">更好</a><a href="https://coolshell.cn/articles/5426.html#%E6%9B%B4%E5%BC%BA">更强</a><a href="https://coolshell.cn/articles/5426.html#%E6%9B%B4%E5%BF%AB">更快</a><a href="https://coolshell.cn/articles/5426.html#%E7%AC%AC%E5%9B%9B%E7%BA%A7_-_Vim_%E8%B6%85%E8%83%BD%E5%8A%9B">第四级 – Vim 超能力</a><a href="https://coolshell.cn/articles/5426.html#%E5%9C%A8%E5%BD%93%E5%89%8D%E8%A1%8C%E4%B8%8A%E7%A7%BB%E5%8A%A8%E5%85%89%E6%A0%87_0_f_F_t_T">在当前行上移动光标: 0 ^ $ f F t T , ;</a><a href="https://coolshell.cn/articles/5426.html#%E5%8C%BA%E5%9F%9F%E9%80%89%E6%8B%A9_a_%E6%88%96_i">区域选择 a 或 i</a><a href="https://coolshell.cn/articles/5426.html#%E5%9D%97%E6%93%8D%E4%BD%9C">块操作: </a><a href="https://coolshell.cn/articles/5426.html#%E8%87%AA%E5%8A%A8%E6%8F%90%E7%A4%BA%EF%BC%9A_%E5%92%8C">自动提示： 和 </a><a href="https://coolshell.cn/articles/5426.html#%E5%AE%8F%E5%BD%95%E5%88%B6%EF%BC%9A_qa_%E6%93%8D%E4%BD%9C%E5%BA%8F%E5%88%97_q_a">宏录制： qa 操作序列 q, @a, @@</a><a href="https://coolshell.cn/articles/5426.html#%E5%8F%AF%E8%A7%86%E5%8C%96%E9%80%89%E6%8B%A9%EF%BC%9A_vV">可视化选择： v,V,</a><a href="https://coolshell.cn/articles/5426.html#%E5%88%86%E5%B1%8F_split_%E5%92%8C_vsplit">分屏: :split 和 vsplit.</a><a href="https://coolshell.cn/articles/5426.html#%E7%BB%93%E6%9D%9F%E8%AF%AD">结束语</a></p>
<h4 id="第一级-–-存活"><a href="#第一级-–-存活" class="headerlink" title="第一级 – 存活"></a>第一级 – 存活</h4><ol>
<li>安装 <a href="https://www.vim.org/">vim</a></li>
<li>启动 vim</li>
<li><strong>什么也别干！</strong>请先阅读</li>
</ol>
<p>当你安装好一个编辑器后，你一定会想在其中输入点什么东西，然后看看这个编辑器是什么样子。但vim不是这样的，请按照下面的命令操作：</p>
<ul>
<li>启 动Vim后，vim在 <em>Normal</em> 模式下。</li>
<li>让我们进入 <em>Insert</em> 模式，请按下键 i 。(陈皓注：你会看到vim左下角有一个–insert–字样，表示，你可以以插入的方式输入了）</li>
<li>此时，你可以输入文本了，就像你用“记事本”一样。</li>
<li>如果你想返回 <em>Normal</em> 模式，请按 <code>ESC</code> 键。</li>
</ul>
<p>现在，你知道如何在 <em>Insert</em> 和 <em>Normal</em> 模式下切换了。下面是一些命令，可以让你在 <em>Normal</em> 模式下幸存下来：</p>
<blockquote>
<ul>
<li><code>i</code> → <em>Insert</em> 模式，按 <code>ESC</code> 回到 <em>Normal</em> 模式.</li>
<li><code>x</code> → 删当前光标所在的一个字符。</li>
<li><code>:wq</code> → 存盘 + 退出 (<code>:w</code> 存盘, <code>:q</code> 退出)  （陈皓注：:w 后可以跟文件名）</li>
<li><code>dd</code> → 删除当前行，并把删除的行存到剪贴板里</li>
<li><code>p</code> → 粘贴剪贴板</li>
</ul>
<p><strong>推荐</strong>:</p>
<ul>
<li><code>hjkl</code> (强例推荐使用其移动光标，但不必需) →你也可以使用光标键 (←↓↑→). 注: <code>j</code> 就像下箭头。</li>
<li><code>:help &lt;command&gt;</code> → 显示相关命令的帮助。你也可以就输入 <code>:help</code> 而不跟命令。（陈皓注：退出帮助需要输入:q）</li>
</ul>
</blockquote>
<p>你能在vim幸存下来只需要上述的那5个命令，你就可以编辑文本了，你一定要把这些命令练成一种下意识的状态。于是你就可以开始进阶到第二级了。</p>
<p>当是，在你进入第二级时，需要再说一下 <em>Normal</em> 模式。在一般的编辑器下，当你需要copy一段文字的时候，你需要使用 <code>Ctrl</code> 键，比如：<code>Ctrl-C</code>。也就是说，Ctrl键就好像功能键一样，当你按下了功能键Ctrl后，C就不在是C了，而且就是一个命令或是一个快键键了，<strong>在VIM的Normal模式下，所有的键就是功能键了</strong>。这个你需要知道。</p>
<p>标记:</p>
<ul>
<li>下面的文字中，如果是 <code>Ctrl-λ</code>我会写成 <code>&lt;C-λ&gt;</code>.</li>
<li>以 <code>:</code> 开始的命令你需要输入 <code>&lt;enter&gt;</code>回车，例如 — 如果我写成 <code>:q</code> 也就是说你要输入 <code>:q&lt;enter&gt;</code>.</li>
</ul>
<h4 id="第二级-–-感觉良好"><a href="#第二级-–-感觉良好" class="headerlink" title="第二级 – 感觉良好"></a>第二级 – 感觉良好</h4><p>上面的那些命令只能让你存活下来，现在是时候学习一些更多的命令了，下面是我的建议：（陈皓注：所有的命令都需要在Normal模式下使用，如果你不知道现在在什么样的模式，你就狂按几次ESC键）</p>
<ol>
<li><p>各种插入模式</p>
<blockquote>
<ul>
<li><code>a</code> → 在光标后插入</li>
<li><code>o</code> → 在当前行后插入一个新行</li>
<li><code>O</code> → 在当前行前插入一个新行</li>
<li><code>cw</code> → 替换从光标所在位置后到一个单词结尾的字符</li>
</ul>
</blockquote>
</li>
<li><p>简单的移动光标</p>
<blockquote>
<ul>
<li><code>0</code> → 数字零，到行头</li>
<li><code>^</code> → 到本行第一个不是blank字符的位置（所谓blank字符就是空格，tab，换行，回车等）</li>
<li><code>$</code> → 到本行行尾</li>
<li><code>g_</code> → 到本行最后一个不是blank字符的位置。</li>
<li><code>/pattern</code> → 搜索 <code>pattern</code> 的字符串（陈皓注：如果搜索出多个匹配，可按n键到下一个）</li>
</ul>
</blockquote>
</li>
<li><p>拷贝/粘贴</p>
<p>（陈皓注：p/P都可以，p是表示在当前位置之后，P表示在当前位置之前）</p>
<blockquote>
<ul>
<li><code>P</code> → 粘贴</li>
<li><code>yy</code> → 拷贝当前行当行于 <code>ddP</code></li>
</ul>
</blockquote>
</li>
<li><p>Undo/Redo</p>
<blockquote>
<ul>
<li><code>u</code> → undo</li>
<li><code>&lt;C-r&gt;</code> → redo</li>
</ul>
</blockquote>
</li>
<li><p>打开/保存/退出/改变文件</p>
<p>(Buffer)</p>
<blockquote>
<ul>
<li><code>:e &lt;path/to/file&gt;</code> → 打开一个文件</li>
<li><code>:w</code> → 存盘</li>
<li><code>:saveas &lt;path/to/file&gt;</code> → 另存为 <code>&lt;path/to/file&gt;</code></li>
<li><code>:x</code>， <code>ZZ</code> 或 <code>:wq</code> → 保存并退出 (<code>:x</code> 表示仅在需要时保存，ZZ不需要输入冒号并回车)</li>
<li><code>:q!</code> → 退出不保存 <code>:qa!</code> 强行退出所有的正在编辑的文件，就算别的文件有更改。</li>
<li><code>:bn</code> 和 <code>:bp</code> → 你可以同时打开很多文件，使用这两个命令来切换下一个或上一个文件。（陈皓注：我喜欢使用:n到下一个文件）</li>
</ul>
</blockquote>
</li>
</ol>
<p>花点时间熟悉一下上面的命令，一旦你掌握他们了，你就几乎可以干其它编辑器都能干的事了。但是到现在为止，你还是觉得使用vim还是有点笨拙，不过没关系，你可以进阶到第三级了。</p>
<h4 id="第三级-–-更好，更强，更快"><a href="#第三级-–-更好，更强，更快" class="headerlink" title="第三级 – 更好，更强，更快"></a>第三级 – 更好，更强，更快</h4><p>先恭喜你！你干的很不错。我们可以开始一些更为有趣的事了。在第三级，我们只谈那些和vi可以兼容的命令。</p>
<h5 id="更好"><a href="#更好" class="headerlink" title="更好"></a>更好</h5><p>下面，让我们看一下vim是怎么重复自己的：</p>
<ol>
<li><code>.</code> → (小数点) 可以重复上一次的命令</li>
<li>N<command> → 重复某个命令N次</li>
</ol>
<p>下面是一个示例，找开一个文件你可以试试下面的命令：</p>
<blockquote>
<ul>
<li><code>2dd</code> → 删除2行</li>
<li><code>3p</code> → 粘贴文本3次</li>
<li><code>100idesu [ESC]</code> → 会写下 “desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu “</li>
<li><code>.</code> → 重复上一个命令—— 100 “desu “.</li>
<li><code>3.</code> → 重复 3 次 “desu” (注意：不是 300，你看，VIM多聪明啊).</li>
</ul>
</blockquote>
<h5 id="更强"><a href="#更强" class="headerlink" title="更强"></a>更强</h5><p>你要让你的光标移动更有效率，你一定要了解下面的这些命令，<strong>千万别跳过</strong>。</p>
<ol>
<li><p>N<code>G</code> → 到第 N 行 （陈皓注：注意命令中的G是大写的，另我一般使用 : N 到第N行，如 :137 到第137行）</p>
</li>
<li><p><code>gg</code> → 到第一行。（陈皓注：相当于1G，或 :1）</p>
</li>
<li><p><code>G</code> → 到最后一行。</p>
</li>
<li><p>按单词移动：</p>
<blockquote>
<ol>
<li><code>w</code> → 到下一个单词的开头。</li>
<li><code>e</code> → 到下一个单词的结尾。</li>
</ol>
<p>&gt; 如果你认为单词是由默认方式，那么就用小写的e和w。默认上来说，一个单词由字母，数字和下划线组成（陈皓注：程序变量）</p>
<p>&gt; 如果你认为单词是由blank字符分隔符，那么你需要使用大写的E和W。（陈皓注：程序语句）</p>
<p><img src="http://yannesposito.com/Scratch/img/blog/Learn-Vim-Progressively/word_moves.jpg" alt="Word moves example"></p>
</blockquote>
</li>
</ol>
<p>下面，让我来说说最强的光标移动：</p>
<blockquote>
<ul>
<li><code>%</code> : 匹配括号移动，包括 <code>(</code>, <code>&#123;</code>, <code>[</code>. （陈皓注：你需要把光标先移到括号上）</li>
<li><code>*</code> 和 <code>#</code>:  匹配光标当前所在的单词，移动光标到下一个（或上一个）匹配单词（*是下一个，#是上一个）</li>
</ul>
</blockquote>
<p>相信我，上面这三个命令对程序员来说是相当强大的。</p>
<h5 id="更快"><a href="#更快" class="headerlink" title="更快"></a>更快</h5><p>你一定要记住光标的移动，因为很多命令都可以和这些移动光标的命令连动。很多命令都可以如下来干：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;start position&gt;&lt;command&gt;&lt;end position&gt;</span><br></pre></td></tr></table></figure>

<p>例如 <code>0y$</code> 命令意味着：</p>
<ul>
<li><code>0</code> → 先到行头</li>
<li><code>y</code> → 从这里开始拷贝</li>
<li><code>$</code> → 拷贝到本行最后一个字符</li>
</ul>
<p>你可可以输入 <code>ye</code>，从当前位置拷贝到本单词的最后一个字符。</p>
<p>你也可以输入 <code>y2/foo</code> 来拷贝2个 “foo” 之间的字符串。</p>
<p>还有很多时间并不一定你就一定要按y才会拷贝，下面的命令也会被拷贝：</p>
<ul>
<li><code>d</code> (删除 )</li>
<li><code>v</code> (可视化的选择)</li>
<li><code>gU</code> (变大写)</li>
<li><code>gu</code> (变小写)</li>
<li>等等</li>
</ul>
<p>（陈皓注：可视化选择是一个很有意思的命令，你可以先按v，然后移动光标，你就会看到文本被选择，然后，你可能d，也可y，也可以变大写等）</p>
<h4 id="第四级-–-Vim-超能力"><a href="#第四级-–-Vim-超能力" class="headerlink" title="第四级 – Vim 超能力"></a>第四级 – Vim 超能力</h4><p>你只需要掌握前面的命令，你就可以很舒服的使用VIM了。但是，现在，我们向你介绍的是VIM杀手级的功能。下面这些功能是我只用vim的原因。</p>
<h5 id="在当前行上移动光标-0-f-F-t-T"><a href="#在当前行上移动光标-0-f-F-t-T" class="headerlink" title="在当前行上移动光标: 0 ^ $ f F t T , ;"></a>在当前行上移动光标: <code>0</code> <code>^</code> <code>$</code> <code>f</code> <code>F</code> <code>t</code> <code>T</code> <code>,</code> <code>;</code></h5><blockquote>
<ul>
<li><code>0</code> → 到行头</li>
<li><code>^</code> → 到本行的第一个非blank字符</li>
<li><code>$</code> → 到行尾</li>
<li><code>g_</code> → 到本行最后一个不是blank字符的位置。</li>
<li><code>fa</code> → 到下一个为a的字符处，你也可以fs到下一个为s的字符。</li>
<li><code>t,</code> → 到逗号前的第一个字符。逗号可以变成其它字符。</li>
<li><code>3fa</code> → 在当前行查找第三个出现的a。</li>
<li><code>F</code> 和 <code>T</code> → 和 <code>f</code> 和 <code>t</code> 一样，只不过是相反方向。<br><img src="http://yannesposito.com/Scratch/img/blog/Learn-Vim-Progressively/line_moves.jpg" alt="Line moves"></li>
</ul>
</blockquote>
<p>还有一个很有用的命令是 <code>dt&quot;</code> → 删除所有的内容，直到遇到双引号—— <code>&quot;。</code></p>
<h5 id="区域选择-lt-action-gt-a-lt-object-gt-或-lt-action-gt-i-lt-object-gt"><a href="#区域选择-lt-action-gt-a-lt-object-gt-或-lt-action-gt-i-lt-object-gt" class="headerlink" title="区域选择 &lt;action&gt;a&lt;object&gt; 或 &lt;action&gt;i&lt;object&gt;"></a>区域选择 <code>&lt;action&gt;a&lt;object&gt;</code> 或 <code>&lt;action&gt;i&lt;object&gt;</code></h5><p>在visual 模式下，这些命令很强大，其命令格式为</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;action&gt;a&lt;object&gt;` 和 `&lt;action&gt;i&lt;object&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>action可以是任何的命令，如 <code>d</code> (删除), <code>y</code> (拷贝), <code>v</code> (可以视模式选择)。</li>
<li>object 可能是： <code>w</code> 一个单词， <code>W</code> 一个以空格为分隔的单词， <code>s</code> 一个句字， <code>p</code> 一个段落。也可以是一个特别的字符：<code>&quot;、</code> <code>&#39;、</code> <code>)、</code> <code>&#125;、</code> <code>]。</code></li>
</ul>
<p>假设你有一个字符串 <code>(map (+) (&quot;foo&quot;))</code>.而光标键在第一个 <code>o </code>的位置。</p>
<blockquote>
<ul>
<li><code>vi&quot;</code> → 会选择 <code>foo</code>.</li>
<li><code>va&quot;</code> → 会选择 <code>&quot;foo&quot;</code>.</li>
<li><code>vi)</code> → 会选择 <code>&quot;foo&quot;</code>.</li>
<li><code>va)</code> → 会选择<code>(&quot;foo&quot;)</code>.</li>
<li><code>v2i)</code> → 会选择 <code>map (+) (&quot;foo&quot;)</code></li>
<li><code>v2a)</code> → 会选择 <code>(map (+) (&quot;foo&quot;))</code></li>
</ul>
</blockquote>
<p><img src="http://yannesposito.com/Scratch/img/blog/Learn-Vim-Progressively/textobjects.png" alt="Text objects selection"></p>
<h5 id="块操作-lt-C-v-gt"><a href="#块操作-lt-C-v-gt" class="headerlink" title="块操作: &lt;C-v&gt;"></a>块操作: <code>&lt;C-v&gt;</code></h5><p>块操作，典型的操作： <code>0 &lt;C-v&gt; &lt;C-d&gt; I-- [ESC]</code></p>
<ul>
<li><code>^</code> → 到行头</li>
<li><code>&lt;C-v&gt;</code> → 开始块操作</li>
<li><code>&lt;C-d&gt;</code> → 向下移动 (你也可以使用hjkl来移动光标，或是使用%，或是别的)</li>
<li><code>I-- [ESC]</code> → I是插入，插入“<code>--</code>”，按ESC键来为每一行生效。</li>
</ul>
<p><img src="http://yannesposito.com/Scratch/img/blog/Learn-Vim-Progressively/rectangular-blocks.gif" alt="Rectangular blocks"></p>
<p>在Windows下的vim，你需要使用 <code>&lt;C-q&gt;</code> 而不是 <code>&lt;C-v&gt;</code> ，<code>&lt;C-v&gt;</code> 是拷贝剪贴板。</p>
<h5 id="自动提示：-lt-C-n-gt-和-lt-C-p-gt"><a href="#自动提示：-lt-C-n-gt-和-lt-C-p-gt" class="headerlink" title="自动提示： &lt;C-n&gt; 和 &lt;C-p&gt;"></a>自动提示： <code>&lt;C-n&gt;</code> 和 <code>&lt;C-p&gt;</code></h5><p>在 Insert 模式下，你可以输入一个词的开头，然后按 <code>&lt;C-p&gt;或是&lt;C-n&gt;，自动补齐功能就出现了……</code></p>
<p>``<img src="http://yannesposito.com/Scratch/img/blog/Learn-Vim-Progressively/completion.gif" alt="Completion"></p>
<h5 id="宏录制：-qa-操作序列-q-a"><a href="#宏录制：-qa-操作序列-q-a" class="headerlink" title="宏录制： qa 操作序列 q, @a, @@"></a>宏录制： <code>qa</code> 操作序列 <code>q</code>, <code>@a</code>, <code>@@</code></h5><ul>
<li><code>qa</code> 把你的操作记录在寄存器 <code>a。</code></li>
<li>于是 <code>@a</code> 会replay被录制的宏。</li>
<li><code>@@</code> 是一个快捷键用来replay最新录制的宏。</li>
</ul>
<blockquote>
<p>*<strong>示例*</strong></p>
<p>在一个只有一行且这一行只有“1”的文本中，键入如下命令：</p>
<ul>
<li><pre><code>qaYp&lt;C-a&gt;q
</code></pre>
<p>→</p>
<ul>
<li><code>qa</code> 开始录制</li>
<li><code>Yp</code> 复制行.</li>
<li><code>&lt;C-a&gt;</code> 增加1.</li>
<li><code>q</code> 停止录制.</li>
</ul>
</li>
<li><p><code>@a</code> → 在1下面写下 2</p>
</li>
<li><p><code>@@</code> → 在2 正面写下3</p>
</li>
<li><p>现在做 <code>100@@</code> 会创建新的100行，并把数据增加到 103.</p>
</li>
</ul>
</blockquote>
<p><img src="http://yannesposito.com/Scratch/img/blog/Learn-Vim-Progressively/macros.gif" alt="Macros"></p>
<h5 id="可视化选择：-v-V-lt-C-v-gt"><a href="#可视化选择：-v-V-lt-C-v-gt" class="headerlink" title="可视化选择： v,V,&lt;C-v&gt;"></a>可视化选择： <code>v</code>,<code>V</code>,<code>&lt;C-v&gt;</code></h5><p>前面，我们看到了 <code>&lt;C-v&gt;</code>的示例 （在Windows下应该是<C-q>），我们可以使用 <code>v</code> 和 <code>V</code>。一但被选好了，你可以做下面的事：</C-q></p>
<ul>
<li><code>J</code> → 把所有的行连接起来（变成一行）</li>
<li><code>&lt;</code> 或 <code>&gt;</code> → 左右缩进</li>
<li><code>=</code> → 自动给缩进 （陈皓注：这个功能相当强大，我太喜欢了）</li>
</ul>
<p><img src="http://yannesposito.com/Scratch/img/blog/Learn-Vim-Progressively/autoindent.gif" alt="Autoindent"></p>
<p>在所有被选择的行后加上点东西：</p>
<ul>
<li><code>&lt;C-v&gt;</code></li>
<li>选中相关的行 (可使用 <code>j</code> 或 <code>&lt;C-d&gt;</code> 或是 <code>/pattern</code> 或是 <code>%</code> 等……)</li>
<li><code>$</code> 到行最后</li>
<li><code>A</code>, 输入字符串，按 <code>ESC。</code></li>
</ul>
<p><img src="http://yannesposito.com/Scratch/img/blog/Learn-Vim-Progressively/append-to-many-lines.gif" alt="Append to many lines"></p>
<h5 id="分屏-split-和-vsplit"><a href="#分屏-split-和-vsplit" class="headerlink" title="分屏: :split 和 vsplit."></a>分屏: <code>:split</code> 和 <code>vsplit</code>.</h5><p>下面是主要的命令，你可以使用VIM的帮助 <code>:help split</code>. 你可以参考本站以前的一篇文章<a href="https://coolshell.cn/articles/1679.html">VIM分屏</a>。</p>
<blockquote>
<ul>
<li><code>:split</code> → 创建分屏 (<code>:vsplit</code>创建垂直分屏)</li>
<li><code>&lt;C-w&gt;&lt;dir&gt;</code> : dir就是方向，可以是 <code>hjkl</code> 或是 ←↓↑→ 中的一个，其用来切换分屏。</li>
<li><code>&lt;C-w&gt;_</code> (或 <code>&lt;C-w&gt;|</code>) : 最大化尺寸 (<C-w>| 垂直分屏)</C-w></li>
<li><code>&lt;C-w&gt;+</code> (或 <code>&lt;C-w&gt;-</code>) : 增加尺寸</li>
</ul>
</blockquote>
<p><img src="http://yannesposito.com/Scratch/img/blog/Learn-Vim-Progressively/split.gif" alt="Split"></p>
<h4 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h4><ul>
<li><p>上面是作者最常用的90%的命令。</p>
</li>
<li><p>我建议你每天都学1到2个新的命令。</p>
</li>
<li><p>在两到三周后，你会感到vim的强大的。</p>
</li>
<li><p>有时候，学习VIM就像是在死背一些东西。</p>
</li>
<li><p>幸运的是，vim有很多很不错的工具和优秀的文档。</p>
</li>
<li><p>运行vimtutor直到你熟悉了那些基本命令。</p>
</li>
<li><p>其在线帮助文档中你应该要仔细阅读的是 <code>:help usr_02.txt</code>.</p>
</li>
<li><p>你会学习到诸如 <code>!，</code> 目录，寄存器，插件等很多其它的功能。</p>
</li>
</ul>
<p>学习vim就像学弹钢琴一样，一旦学会，受益无穷。</p>
<p>——————————正文结束——————————</p>
<p>对于vi/vim只是点评一点：这是一个你不需要使用鼠标，不需使用小键盘，只需要使用大键盘就可以完成很多复杂功能文本编辑的编辑器。不然，<a href="https://coolshell.cn/articles/1901.html">Visual Studio也不就会有vim的插件了</a>。</p>
]]></content>
  </entry>
  <entry>
    <title>Linux快速整理</title>
    <url>/2021/11/08/Linux%E5%BF%AB%E9%80%9F%E6%95%B4%E7%90%86/</url>
    <content><![CDATA[<p>环境搭建:</p>
<p>vmware虚拟机+XShell登录虚拟机</p>
<p>Linux快速整理：</p>
<ol>
<li><p><code>[root@hadoop001 ~]</code>表示[登录的用户@机器名称 <del>]，“</del>”表示家目录</p>
</li>
<li><p><code>pwd</code>查看当前所在目录路径地址</p>
<p>有时候2个文件夹同名可能会搞错，需要要查看目录</p>
<span id="more"></span></li>
<li><p>切换目录 <code>cd</code></p>
<p>root用户的家目录：/root</p>
<p>xxx用户的家目录：/home/xxx 默认</p>
<p>家目录的修改：vi /etc/passwd 默认不修改</p>
<p>什么情况会修改？部署mysql时，修改mysqladmin的家目录为/usr/local/mysql，方便操作与规范。行业里比较标准的事情</p>
<p><code>cd 回车</code>  /  <code>cd ~ </code>  / <code>cd /root</code> 回到家目录</p>
<p><code>cd -</code>回到上一次访问的目录</p>
<p><code>cd ../</code> 回退上一层目录</p>
<p><code>cd ../../</code> 回退上两层目录</p>
</li>
<li><p>目录 文件夹</p>
<p><strong>绝对路径</strong>：“/”代表根目录，以根目录开始表示</p>
<p>​                    写shell脚本时，路径要用绝对路径。</p>
<p><strong>相对路径</strong>：不以根目录为开始，以当前光标所在目录（pwd结果）为开始表示</p>
<p>查看当前文件夹下的内容 <code>ls</code></p>
</li>
<li><p>清空屏幕 <code>clear</code></p>
</li>
<li><p>ls查看当前光标所在的目录 文件有哪些</p>
<p><code>ls -l</code>  等价于`ll``</p>
<p>``ls -l -a` 查看当前的文件文件夹+ 隐藏文件、文件夹（以.开头）</p>
<p><code>ll -h</code> 显示文件的大小</p>
<p><code>ll -rt</code> 按时间排序</p>
</li>
<li><p>查询命令帮助 <code>--help</code> /<code>man</code></p>
</li>
<li><p>创建文件夹 <code>mkdir</code> </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir [-mp] 目录名称</span><br></pre></td></tr></table></figure>

<p>选项与参数：</p>
<ul>
<li>-m ：配置文件的权限喔！直接配置，不需要看默认权限 (umask) 的脸色～</li>
<li>-p ：帮助你直接将所需要的目录(包含上一级目录)递归创建起来！</li>
</ul>
<p>例如 </p>
<p><code>mkdir -p a/b/c/d</code>递归创建多层目录</p>
<p><code>mkdir a b c d</code>在当前文件夹下创建4个文件夹</p>
<p>删除空的目录：<code>rmdir</code></p>
<p>选项与参数：</p>
<ul>
<li><strong>-p ：</strong>从该目录起，一次删除多级空目录</li>
</ul>
</li>
<li><p>复制文件或目录： <code>cp [-adfilprsu] source destination</code></p>
<p>移动文件与目录，或修改名称： <code>mv [-fiu] source destination</code></p>
<p>移除文件或目录： <code>rm [-fir] 文件或目录</code></p>
<p><strong>思考：mv和cp哪个执行快？</strong></p>
<ul>
<li>同一个文件系统（在同一个分区）内，mv的速度是瞬间的，因为它所有需要的是重命名的目录的文件路径。除了目录条目之外，没有必要更改任何数据。</li>
<li>在文件系统之间移动目录将涉及将数据复制到目标并将其从源中删除。这将与在单个文件系统中复制（复制）数据一样长的时间。</li>
<li>都可修改名称。</li>
</ul>
</li>
<li><p>如何创建一个空文件 或者把一个文件设置为空</p>
<ul>
<li><p>touch rz.log 如何创建一个空文件</p>
<p><code>touch</code>命令用于修改文件或者目录的时间属性，包括存取时间和更改时间。若文件不存在，系统会建立一个新的文件。</p>
</li>
<li><p>echo “” &gt; rz.log1 慎用(不是真正的空，会有1字节的大小)</p>
</li>
<li><p>cat /dev/null &gt; ruoze.log20191113  把一个文件设置为空</p>
</li>
</ul>
</li>
<li><p>查看文件内容</p>
<ul>
<li><p><code>cat</code>命令用于连接文件并打印到标准输出设备上。</p>
<p>-n 或 –number：由 1 开始对所有输出的行数编号。</p>
</li>
<li><p><code>more</code> 命令类似 cat ，不过会以一页一页的形式显示，更方便使用者逐页阅读</p>
<p>空白键（space）- 往下一页显示</p>
<p>b  - 往回（back）一页显示</p>
<p>q  - 退出more</p>
</li>
<li><p><code>less</code> 与 more 类似，less 可以随意浏览文件，支持翻页和搜索，支持向上翻页和向下翻页</p>
<p>/字符串：向下搜索”字符串”的功能</p>
<p>?字符串：向上搜索”字符串”的功能</p>
<p>n：重复前一个搜索（与 / 或 ? 有关）</p>
<p>N：反向重复前一个搜索（与 / 或 ? 有关）</p>
<p>G ：移动到最后一行</p>
<p>g：移动到第一行</p>
<p>q / ZZ ：-退出 less 命令</p>
</li>
</ul>
<p><strong>配置文件，内容较少，可用以上上个命令</strong></p>
<p><strong>log日志，内容较多，用tail命令</strong></p>
<ul>
<li><p><code>tail</code> 可用于查看文件的内容，有一个常用的参数 <strong>-f</strong> 常用于查阅正在改变的日志文件。</p>
<p>实时查看</p>
<p><code>tail -f filename</code> 会把 filename 文件里的最尾部的内容显示在屏幕上，并且不断刷新，只要 filename 更新就可以看到最新的文件内容。</p>
<p><code>tail -F filename</code>等于-f + retry，即使文件丢失后再创建也会更新</p>
<p>补充：flume exec source 切记使用 -F</p>
<p>-n&lt;行数&gt; 显示文件的尾部 n 行内容</p>
<p>-c&lt;数目&gt; 显示的字节数</p>
<p><code>tail -n -5 /test001/text001</code> 与 <code>tail -n 5 /test001/text001</code> 显示的结果相同，均是文件末尾最后 5 行内容。<br><code>tail -n +5 /test001/text001</code> 显示的内容为从第 5 行开始，直到末尾的内容。tail -n 后面的数字有效输入只有单个数字（5）或者加号连接数字（+5）两种。</p>
<p>tail -300f messages 实时查看倒数300行文件<br>tail -300F messages 不能这样写，即不能写成数字+F<br>tail: option used in invalid context – 3</p>
</li>
</ul>
</li>
<li><p>文件上传下载工具</p>
<p>安装： <code>yum install -y lrzsz</code></p>
<p>文件下载到windows：<code>sz</code></p>
<p>windows上传到linux: <code>rz</code></p>
</li>
<li><p>如何定位ERROR</p>
<ul>
<li><p>文件内容很小，几十兆</p>
<p>先下载到windows上，用编辑器打开搜索关键字定位ERROR</p>
</li>
<li><p>文件内容很大，几百兆 2G</p>
<p>cat xxx.log | grep ERROR</p>
<p>| 是管道符，管道符前面的命令结果作为管道符后面命令的输入，grep是过滤命令</p>
</li>
</ul>
</li>
<li><p>grep命令</p>
<p><code>grep</code> 指令用于查找内容包含指定的范本样式的文件，如果发现某文件的内容符合所指定的范本样式，预设 grep 指令会把含有范本样式的那一列显示出来。若不指定任何文件名称，或是所给予的文件名为 **-**，则 grep 指令会从标准输入设备读取数据。</p>
<p>-A&lt;显示行数&gt; 或 –after-context=&lt;显示行数&gt; : 除了显示符合范本样式的那一列之外，并显示该行之后的内容。</p>
<p>-B&lt;显示行数&gt; 或 –before-context=&lt;显示行数&gt;: 除了显示符合样式的那一行之外，并显示该行之前的内容。</p>
<p>-C&lt;显示行数&gt; 或 –context=&lt;显示行数&gt;或-&lt;显示行数&gt;: 除了显示符合样式的那一行之外，并显示该行之前后的内容。</p>
<p>cat xxx.log | grep -A 10 ERROR 后10行<br>cat xxx.log | grep -B 10 ERROR 前10行<br>cat xxx.log | grep -C 30 ERROR 前后各30行  经常用  迅速定位ERROR上下文</p>
<p>cat xxx.log | grep -C 30 ERROR &gt; error.log 新建/覆盖<br>cat xxx.log | grep -C 30 ERROR &gt;&gt; error.log 追加</p>
</li>
<li><p>环境变量$PATH</p>
<p>打印环境变量：<code>echo $PATH</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# echo $PATH</span><br><span class="line">/usr/local/mysql/bin:/usr/java/jdk1.7.0_80/bin:/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin</span><br></pre></td></tr></table></figure>

<p><code>which</code>命令：依次在环境变量$PATH中以冒号分割，查找目录下是否有要查找的命令目录，返回第一个查找到的目录地址</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# which ls</span><br><span class="line">alias ls=&#x27;ls --color=auto&#x27;</span><br><span class="line">	/bin/ls</span><br></pre></td></tr></table></figure>

<p>全局环境变量: /etc/profile    所有人都使用<br>个人环境变量: ~/.bash_profile  </p>
<pre><code>                      ~/.bashrc       个人 不给其他人
</code></pre>
<p>注意：配置个人环境变量文件**.bashrc** 优先。当用ssh远程登录时，**.bashrc** 会自动生效， <strong>.bash_profile</strong>则不会，bug。</p>
<p>生效文件: <code>source xxxx</code></p>
<pre><code>              `. ~/.bashrc`
</code></pre>
<p>（补充：安装unzip命令 ：<code>yum install -y unzip</code> 解压：<code>tar -xzvf xxxx.tar.gz</code>）</p>
<p>配置环境变量:<code>vi /etc/profile</code></p>
<p>环境变量是指的什么<br>K=V  等号前后不能有空格<br>使用环境变量K时用$符号，如： $K</p>
<p>export JAVA_HOME=usr/java/jdk1.8.0_121</p>
<p>export PATH=$JAVA_HOME/bin:$PATH</p>
<p>新配置的变量在前面追加</p>
<p>a. 上下键 移动光标<br>b. 按 i键insert 进入 <strong>编辑模式</strong><br>c. 开始编辑<br>d. 按 esc键退出 编辑模式，进入<strong>命令行模式</strong><br>e. 按 ：（shift+；）键，进入<strong>尾行模式</strong><br>f. 输入 wq 保存退出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ruozedata001 java]# source /etc/profile</span><br><span class="line">[root@ruozedata001 java]# echo $PATH</span><br><span class="line">/usr/java/jdk1.8.0_121/bin:/usr/java/jdk1.8.0_12/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin</span><br><span class="line">[root@ruozedata001 java]# which java</span><br><span class="line">/usr/java/jdk1.8.0_121/bin/java</span><br><span class="line">[root@ruozedata001 java]# </span><br></pre></td></tr></table></figure>

<p>小结:<br>1.command not found<br>没有部署安装包，部署了没有配置环境变量<br>2.习惯<br>当我们以后部署一个软件，bin目录的可执行文件 比如java<br>习惯 当生效环境变量文件，习惯做 which java</p>
</li>
<li><p>别名alias</p>
<p><code>alias</code> 命令用于设置指令的别名。</p>
<p>用户可利用alias，自定指令的别名。若仅输入alias，则可列出目前所有的别名设置。alias的效力仅及于该次登入的操作。若要每次登入是即自动设好别名，可在.profile或.bashrc中设定指令的别名。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">alias[别名]=[指令名称]</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# alias</span><br><span class="line">alias cp=&#x27;cp -i&#x27;</span><br><span class="line">alias l.=&#x27;ls -d .* --color=auto&#x27;</span><br><span class="line">alias ll=&#x27;ls -l --color=auto&#x27;</span><br><span class="line">alias ls=&#x27;ls --color=auto&#x27;</span><br><span class="line">alias mv=&#x27;mv -i&#x27;</span><br><span class="line">alias rm=&#x27;rm -i&#x27;</span><br><span class="line">alias which=&#x27;alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde&#x27;</span><br></pre></td></tr></table></figure>

<p>配置个人环境变量文件**.bashrc** 优先。当用ssh远程登录时，**.bashrc** 会自动生效， <strong>.bash_profile</strong>则不会，bug。</p>
</li>
<li><p>查看历史命令history</p>
<p>当前命令输入状态下：</p>
<pre><code>* 可以按一下**上＼下方向键**，命令行就会显示相对于当前命令的上一条或下一条历史记录．

*  和方向键相同功能的就是组合键**Ctrl+ p** （前面执行过的命令）,**Ctrl +n**（后面执行过的命令）
</code></pre>
<ul>
<li><p>上面两个都是相对于当前命令查询上一条或者下一条命令的历史记录．如果搜索命令历史记录，就用<strong>Ctrl+ r</strong> 组合键进入历史记录搜寻状态，然后，键盘每按一个字母，当前命令行就会搜索出命令历史记录．使用Ctrl+r反向查询历史命令，将匹配的最新一条显示出来</p>
<p>如果还想继续向上查询，继续按<strong>Ctrl+r</strong>。</p>
</li>
</ul>
<p><code>history [n]</code>  n为数字，列出最近的n条命令</p>
<p><code>history -c</code>  将目前shell中的所有history命令消除</p>
<p>使用! 执行历史命令。</p>
<pre><code>* `!  [n]`  n为数字 执行第n条命令
</code></pre>
<ul>
<li><code>! command</code> 从最近的命令查到以command开头的命令执行</li>
<li><code>!!</code> 执行上一条</li>
</ul>
<p>当同一账号，同时登录多个bash时，只有最后一个退出的会写入bash_history,其他的都被覆盖了。</p>
<p>历史命令文件记录在 ~/.bash_history中,要清空历史记录：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat /dev/null &gt;  ~/.bash_history</span><br><span class="line">history -c </span><br></pre></td></tr></table></figure>

<p>拓展：</p>
<p>当刚进公司进入服务器，第一步应该用history 看看这个账号之前做过哪些操作，有可能发现password</p>
</li>
<li><p>删除<br>生成新文件:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">touch xxx.log </span><br><span class="line">cat /dev/null &gt; xxx.log //把文件置空</span><br><span class="line">vi xxx.log</span><br></pre></td></tr></table></figure>

<p>创建文件夹: <code>mkdir</code> </p>
<p> <code>rm</code>（英文全拼：remove）命令用于删除一个文件或者目录。</p>
<ul>
<li><p>-i 删除前逐一询问确认。</p>
</li>
<li><p>-f 即使原档案属性设为唯读，亦直接删除，无需逐一确认。</p>
</li>
<li><p>-r 将目录及以下之档案亦逐一删除。</p>
<p>删除文件可以直接使用rm命令，若删除目录则必须配合选项”-r”，例如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># rm  test.txt </span><br><span class="line">rm：是否删除 一般文件 &quot;test.txt&quot;? y  </span><br><span class="line"># rm  homework  </span><br><span class="line">rm: 无法删除目录&quot;homework&quot;: 是一个目录  </span><br><span class="line"># rm  -r  homework  </span><br><span class="line">rm：是否删除 目录 &quot;homework&quot;? y </span><br></pre></td></tr></table></figure></li>
</ul>
<p>文件一旦通过rm命令删除，则无法恢复，所以必须格外小心地使用该命令。</p>
<p><strong>风险:</strong><br>rm -rf /  高危命令<br>什么场景会发生？ shell脚本:</p>
<p>K=’/home/jepson’</p>
<p>K=’’<br>shell脚本中必须判断 $K命令是否存在<br>rm -rf $K/*</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 6]# K=&#x27;&#x27; //本应该设置K=&#x27;/home/jepson&#x27;</span><br><span class="line">[root@hadoop001 6]# echo $K/</span><br><span class="line">/</span><br><span class="line">[root@hadoop001 6]# ls $K/</span><br><span class="line">6     data  home   lost+found  mnt  proc  selinux  tmp</span><br><span class="line">bin   dev   lib    media       net  root  srv      usr</span><br><span class="line">boot  etc   lib64  misc        opt  sbin  sys      var</span><br></pre></td></tr></table></figure></li>
<li><p>用户 用户组</p>
<p>创建用户：<code>useradd username</code></p>
<p>查看用户信息：<code>id username</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# id ruoze</span><br><span class="line">//uid=501(ruoze) gid=501(ruoze) groups=501(ruoze) 默认值</span><br><span class="line">uid=501(ruoze) gid=502(bigdata) groups=502(bigdata),501(ruoze)</span><br></pre></td></tr></table></figure>

<p>创建一个普通用户，默认创建这个名称的用户组ruoze,<br>且设置这个用户 主组为ruoze，且创建/home/ruoze</p>
<p>查看机器上的用户：<code>cat /etc/passwd</code><br>查看机器上的用户组：<code>cat /etc/group</code></p>
<p>删除用户:<code>userdel username</code></p>
<p>删除用户后，/etc/passwd内会删除用户信息，但是用户home文件夹依然存在。如果组内只有一个成员，成员被删除后，组会自动删除。</p>
<p>模拟切换用户丢失样式</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ruozedata001 ruoze]# ll -a</span><br><span class="line">total 12</span><br><span class="line">drwx------  2 ruoze ruoze  59 Nov 16 21:16 .</span><br><span class="line">drwxr-xr-x. 5 root  root   44 Nov 16 21:16 ..</span><br><span class="line">-rw-r--r--  1 ruoze ruoze  18 Apr 11  2018 .bash_logout</span><br><span class="line">-rw-r--r--  1 ruoze ruoze 193 Apr 11  2018 .bash_profile</span><br><span class="line">-rw-r--r--  1 ruoze ruoze 231 Apr 11  2018 .bashrc</span><br><span class="line">[root@ruozedata001 ruoze]# rm -rf .bash*</span><br><span class="line"></span><br><span class="line">[root@ruozedata001 ~]# su  - ruoze</span><br><span class="line">Last login: Sat Nov 16 21:29:09 CST 2019 on pts/1</span><br><span class="line">-bash-4.2$ </span><br><span class="line">-bash-4.2$ </span><br></pre></td></tr></table></figure>

<p>修正样式（从/etc/skel上把隐藏文件复制到用户home目录下即可）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ruozedata001 ruoze]# cp /etc/skel/.* /home/ruoze/</span><br><span class="line">cp: omitting directory ‘/etc/skel/.’</span><br><span class="line">cp: omitting directory ‘/etc/skel/..’</span><br><span class="line">[root@ruozedata001 ruoze]# ll -a</span><br><span class="line">total 12</span><br><span class="line">drwx------  2 ruoze ruoze  59 Nov 16 21:32 .</span><br><span class="line">drwxr-xr-x. 5 root  root   44 Nov 16 21:16 ..</span><br><span class="line">-rw-r--r--  1 root  root   18 Nov 16 21:32 .bash_logout</span><br><span class="line">-rw-r--r--  1 root  root  193 Nov 16 21:32 .bash_profile</span><br><span class="line">-rw-r--r--  1 root  root  231 Nov 16 21:32 .bashrc</span><br><span class="line">[root@ruozedata001 ruoze]# chown ruoze:ruoze .bash*</span><br><span class="line"></span><br><span class="line">[root@ruozedata001 ruoze]# ll -a</span><br><span class="line">total 12</span><br><span class="line">drwx------  2 ruoze ruoze  59 Nov 16 21:32 .</span><br><span class="line">drwxr-xr-x. 5 root  root   44 Nov 16 21:16 ..</span><br><span class="line">-rw-r--r--  1 ruoze ruoze  18 Nov 16 21:32 .bash_logout</span><br><span class="line">-rw-r--r--  1 ruoze ruoze 193 Nov 16 21:32 .bash_profile</span><br><span class="line">-rw-r--r--  1 ruoze ruoze 231 Nov 16 21:32 .bashrc</span><br><span class="line">[root@ruozedata001 ruoze]# </span><br><span class="line">[root@ruozedata001 ~]# su - ruoze</span><br><span class="line">Last login: Sat Nov 16 21:30:23 CST 2019 on pts/2</span><br><span class="line">[ruoze@ruozedata001 ~]$ </span><br></pre></td></tr></table></figure>

<p>创建用户组：<code>groupadd groupname</code></p>
<p>把用户添加到用户组：<code>usermod -a -G bigdata ruoze</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">usermod	-g, --gid GROUP               force use GROUP as new primary group</span><br><span class="line">		-G, --groups GROUPS           new list of supplementary GROUPS</span><br><span class="line">		-a, --append                  append the user to the supplemental GROUPS</span><br></pre></td></tr></table></figure>

<p>给用户设置密码：<code>passwd username</code>，passwd后不加参数，就是设置当前用户的密码</p>
<p>切换用户：<code>su</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">su username</span><br><span class="line">su - username</span><br></pre></td></tr></table></figure>

<p>加”-“会把当前目录切换到用户的家目录，且执行环境变量文件（.bash_profile和.bashrc都执行）</p>
<p>不加“-”，目录不切换，.bashrc中的配置执行，.bash_profile中的配置不执行。所以配置最好写在.bashrc上。</p>
<p>用户权限问题：connection连接拒绝、Permission denied</p>
<p>普通用户获取root的最大权限<code>vi /etc/sudoers</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Allow root to run any commands anywhere </span><br><span class="line">username   ALL=(root)      NOPASSWD:ALL</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[ruoze@ruozedata001 root]$ ls -l</span><br><span class="line">ls: cannot open directory .: Permission denied</span><br><span class="line">[ruoze@ruozedata001 root]$ cat rz.log</span><br><span class="line">cat: rz.log: Permission denied</span><br><span class="line">[ruoze@ruozedata001 root]$ sudo cat rz.log</span><br><span class="line">www.ruozedata.com</span><br></pre></td></tr></table></figure>

<p>/etc/passwd:</p>
<p>设置为：ruoze:\x:1002:1003::/home/ruoze:/bin/false，然后su切换失败</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ruozedata001 ~]# su - ruoze</span><br><span class="line">Last login: Sat Nov 16 21:57:32 CST 2019 on pts/0</span><br><span class="line">[root@ruozedata001 ~]# </span><br></pre></td></tr></table></figure>

<p>设置为：ruoze:\x:1002:1003::/home/ruoze:/sbin/nologin,然后不允许登录</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ruozedata001 ~]# su - ruoze</span><br><span class="line">Last login: Sat Nov 16 22:08:52 CST 2019 on pts/0</span><br><span class="line">This account is currently not available.</span><br><span class="line">[root@ruozedata001 ~]# </span><br></pre></td></tr></table></figure>

<p>所以以后在CDH中遇到切换用户失败，到/etc/passwd中对应修改为 /bin/bash</p>
</li>
<li><p>权限：chown chmod</p>
<p>错误: Permission denied（permission denied一般用chmod修改文件权限就可，chown不必要）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">chmod -R 777 文件夹/文件路径</span><br><span class="line">chown -R 用户:用户组 文件夹/文件路径</span><br><span class="line">-R, --recursive        operate on files and directories recursively</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ruozedata001 ~]# ll</span><br><span class="line">total 4</span><br><span class="line">drwxr-xr-x 2 root root  6 Nov 16 22:15 ruozedata</span><br><span class="line">-rw-r--r-- 1 root root 18 Nov 16 21:58 rz.log</span><br></pre></td></tr></table></figure>

<p>第一个字符：d:文件夹；-：文件；l：连接；</p>
<p>r: read  4<br>w: write 2<br>x: 执行  1<br>-: 没权限 0</p>
<p>rwx 第一组 7 代表文件或文件夹的用户root，读写执行<br>r-x 第二组 5 代表文件或文件夹的用户组root，读执行<br>r-x 第三组 5 代表其他组的所属用户对这个文件或文件夹的权限: 读执行</p>
</li>
<li><p>查看大小</p>
<p>文件：</p>
<ul>
<li>ll</li>
<li>du -sh </li>
</ul>
<p>文件夹：</p>
<ul>
<li>du -sh</li>
<li>用ll看到的并不是文件夹大小</li>
</ul>
</li>
<li><p>删除执行中的程序或工作:<code>kill</code></p>
<p><code>kill</code> 可将指定的信息送至程序。预设的信息为 SIGTERM(15)，可将指定程序终止。</p>
<p>若仍无法终止该程序，可使用 SIGKILL(9) 信息尝试强制删除程序。程序或工作的编号(pid)可利用 ps 指令或 jobs 指令查看。</p>
<p>root用户将影响用户的进程，非root用户只能影响自己的进程。</p>
<p>使用 <code>kill -l</code> 命令列出所有可用信号。最常用的信号是：</p>
<ul>
<li>1 (HUP)：重新加载进程。</li>
<li>2（INT）：中断（同 Ctrl + C）</li>
<li>3（QUIT）：退出（同 Ctrl + \）</li>
<li>9 (KILL)：强制杀死一个进程。</li>
<li>15 (TERM)：正常停止一个进程。</li>
</ul>
<p>杀死进程</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># kill pid</span><br></pre></td></tr></table></figure>

<p>强制杀死进程</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># kill -KILL pid</span><br><span class="line"># kill -9 pid</span><br></pre></td></tr></table></figure>

<p>发送SIGHUP信号，可以使用一下信号</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># kill -HUP pid</span><br></pre></td></tr></table></figure>

<p>杀死指定用户所有进程</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#kill -9 $(ps -ef | grep hnlinux) //方法一 过滤出hnlinux用户进程 </span><br><span class="line">#kill -u hnlinux //方法二</span><br></pre></td></tr></table></figure>

<p><strong>扩展：kill pid与kill -9 pid的区别</strong></p>
<p><code>kill pid</code>的作用是向进程号为pid的进程发送SIGTERM（这是kill默认发送的信号），该信号是一个结束进程的信号且可以被应用程序捕获。若应用程序没有捕获并响应该信号的逻辑代码，则该信号的默认动作是kill掉进程。这是终止指定进程的推荐做法。</p>
<p> <code>kill -9 pid</code>则是向进程号为pid的进程发送SIGKILL（该信号的编号为9），SIGKILL既不能被应用程序捕获，也不能被阻塞或忽略，其动作是立即结束指定进程。通俗地说，应用程序根本无法“感知”SIGKILL信号，它在完全无准备的情况下，就被收到SIGKILL信号的操作系统给干掉了，显然，在这种“暴力”情况下，应用程序完全没有释放当前占用资源(善后：关闭socket链接、清理临时文件、将自己将要被销毁的消息通知给子进程、重置自己的终止状态)的机会。事实上，SIGKILL信号是直接发给init进程的，它收到该信号后，负责终止pid指定的进程。在某些情况下（如进程已经hang死，无法响应正常信号），就可以使用kill -9来结束进程。</p>
<p><strong>注意：</strong>kill生产上不能随意杀进程，确认是自己服务不影响其他不丢数据，在杀死前周知运维、部门。发送信号时必须小心，只有在万不得已时，才用kill信号(9)，因为进程不能首先捕获它。</p>
</li>
<li><p>其他命令</p>
<ul>
<li><p>搜索 <code>find</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#find   path   -option   [   -print ]   [ -exec   -ok   command ]   &#123;&#125; \;</span><br></pre></td></tr></table></figure>

<p>将当前目录及其子目录下所有文件后缀为 <strong>.c</strong> 的文件列出来:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#find . -name &quot;*.c&quot;</span><br></pre></td></tr></table></figure>

<p>将当前目录及其子目录中的所有文件列出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#find . -type f</span><br></pre></td></tr></table></figure>

<p>将当前目录及其子目录下所有最近 20 天内更新过的文件列出:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#find . -ctime -20</span><br></pre></td></tr></table></figure></li>
<li><p>查看进程：<code>ps -ef</code> </p>
</li>
<li><p>系统情况：<code>top</code>（load average: 0，0，0反映繁忙不繁忙。超过十就很高。）</p>
</li>
<li><p>查看ip通不通：ping ip地址</p>
</li>
<li><p>测试端口号连通性：telnet ip地址 端口号</p>
</li>
</ul>
</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>在Linux系统上部署Mysql</title>
    <url>/2021/11/24/Mysql%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<h1 id="在Linux系统上部署Mysql"><a href="#在Linux系统上部署Mysql" class="headerlink" title="在Linux系统上部署Mysql"></a>在Linux系统上部署Mysql</h1><p>在Linux上部署Mysql的两种方式：</p>
<ul>
<li>rpm包部署：操作简单，适合学习的场景</li>
<li>tar包部署：定制化配置，生产上一般用tar包部署</li>
</ul>
<span id="more"></span>

<h2 id="一、rpm包部署"><a href="#一、rpm包部署" class="headerlink" title="一、rpm包部署"></a>一、rpm包部署</h2><h3 id="0-查看机器上是否已经部署"><a href="#0-查看机器上是否已经部署" class="headerlink" title="0.查看机器上是否已经部署"></a>0.查看机器上是否已经部署</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 mysql]# rpm -qa|grep mysql</span><br><span class="line">mysql-5.1.73-3.el6_5.x86_64</span><br><span class="line">mysql-libs-5.1.73-3.el6_5.x86_64</span><br><span class="line">mysql-server-5.1.73-3.el6_5.x86_64</span><br></pre></td></tr></table></figure>

<p>此处已经部署，先卸载</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 mysql]# rpm -e --nodeps mysql*</span><br></pre></td></tr></table></figure>

<h3 id="1-用yum安装"><a href="#1-用yum安装" class="headerlink" title="1.用yum安装"></a>1.用yum安装</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 mysql]# yum search mysql</span><br><span class="line">[root@hadoop001 mysql]# yum install -y mysql-server.x86_64 mysql.x86_64</span><br></pre></td></tr></table></figure>

<p>安装完毕根据需要修改配置文件:<code>/etc/my.cnf</code></p>
<p>#不用yum安装的话，可到官网下载rpm包，然后通过命令<code>rpm -ivh rpm包</code>进行安装，大同小异</p>
<h3 id="2-启动与停止"><a href="#2-启动与停止" class="headerlink" title="2.启动与停止"></a>2.启动与停止</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 mysql]# service mysqld start</span><br><span class="line">[root@hadoop001 mysql]# service mysqld stop  </span><br></pre></td></tr></table></figure>



<h2 id="二、tar包部署"><a href="#二、tar包部署" class="headerlink" title="二、tar包部署"></a>二、tar包部署</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# mysql --version</span><br><span class="line">mysql  Ver 14.14 Distrib 5.6.23, for linux-glibc2.5 (x86_64) using  EditLine wrapper</span><br></pre></td></tr></table></figure>

<p>我的linux系统上已经部署mysql 5.6.23版本，现在以部署mysql 5.7.11为例再部署一次。</p>
<h3 id="0-前期准备：tar包"><a href="#0-前期准备：tar包" class="headerlink" title="0.前期准备：tar包"></a>0.前期准备：tar包</h3><p>官方网站选择需要的版本下载：<a href="https://downloads.mysql.com/archives/community/">https://downloads.mysql.com/archives/community/</a></p>
<p>我们这里用到的是mysql-5.7.11-linux-glibc2.5-x86_64.tar.gz，点击下载：<a href="https://cdn.mysql.com/archives/mysql-5.7/mysql-5.7.11-linux-glibc2.5-x86_64.tar.gz">mysql-5.7.11-linux-glibc2.5-x86_64.tar.gz</a></p>
<p>然后通过rz命令上传至linux系统</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# cd /usr/local/</span><br><span class="line">[root@hadoop001 local]# rz</span><br><span class="line">[root@hadoop001 local]# ll|grep mysql</span><br><span class="line">-rw-r--r--.  1 root       root 548193637 Nov 21 03:58 mysql-5.7.11-linux-glibc2.5-x86_64.tar.gz</span><br></pre></td></tr></table></figure>

<h3 id="1-解压及创建目录"><a href="#1-解压及创建目录" class="headerlink" title="1.解压及创建目录"></a>1.解压及创建目录</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 local]# tar -xzvf mysql-5.7.11-linux-glibc2.5-x86_64.tar.gz </span><br><span class="line">[root@hadoop001 local]# ln -s mysql-5.7.11-linux-glibc2.5-x86_64 mysql</span><br><span class="line">[root@hadoop001 local]# cd mysql</span><br><span class="line">[root@hadoop001 mysql]# ll</span><br><span class="line">total 52</span><br><span class="line">drwxr-xr-x.  2 7161 wheel  4096 Feb  2  2016 bin</span><br><span class="line">-rw-r--r--.  1 7161 wheel 17987 Feb  2  2016 COPYING</span><br><span class="line">drwxr-xr-x.  2 7161 wheel  4096 Feb  2  2016 docs</span><br><span class="line">drwxr-xr-x.  3 7161 wheel  4096 Feb  2  2016 include</span><br><span class="line">drwxr-xr-x.  5 7161 wheel  4096 Feb  2  2016 lib</span><br><span class="line">drwxr-xr-x.  4 7161 wheel  4096 Feb  2  2016 man</span><br><span class="line">-rw-r--r--.  1 7161 wheel  2478 Feb  2  2016 README</span><br><span class="line">drwxr-xr-x. 28 7161 wheel  4096 Feb  2  2016 share</span><br><span class="line">drwxr-xr-x.  2 7161 wheel  4096 Feb  2  2016 support-files</span><br><span class="line">[root@hadoop001 mysql]# mkdir arch data tmp</span><br><span class="line">[root@hadoop001 mysql]# ll</span><br><span class="line">total 64</span><br><span class="line">drwxr-xr-x.  2 root root   4096 Nov 24 09:38 arch</span><br><span class="line">drwxr-xr-x.  2 7161 wheel  4096 Feb  2  2016 bin</span><br><span class="line">-rw-r--r--.  1 7161 wheel 17987 Feb  2  2016 COPYING</span><br><span class="line">drwxr-xr-x.  2 root root   4096 Nov 24 09:38 data</span><br><span class="line">drwxr-xr-x.  2 7161 wheel  4096 Feb  2  2016 docs</span><br><span class="line">drwxr-xr-x.  3 7161 wheel  4096 Feb  2  2016 include</span><br><span class="line">drwxr-xr-x.  5 7161 wheel  4096 Feb  2  2016 lib</span><br><span class="line">drwxr-xr-x.  4 7161 wheel  4096 Feb  2  2016 man</span><br><span class="line">-rw-r--r--.  1 7161 wheel  2478 Feb  2  2016 README</span><br><span class="line">drwxr-xr-x. 28 7161 wheel  4096 Feb  2  2016 share</span><br><span class="line">drwxr-xr-x.  2 7161 wheel  4096 Feb  2  2016 support-files</span><br><span class="line">drwxr-xr-x.  2 root root   4096 Nov 24 09:38 tmp</span><br></pre></td></tr></table></figure>

<p>arch:binlog日志存储的文件夹</p>
<h3 id="2-创建配置文件-etc-my-cnf"><a href="#2-创建配置文件-etc-my-cnf" class="headerlink" title="2.创建配置文件/etc/my.cnf"></a>2.创建配置文件/etc/my.cnf</h3><p>#defualt start: /etc/my.cnf-&gt;/etc/mysql/my.cnf-&gt;SYSCONFDIR/my.cnf-&gt;$MYSQL_HOME/my.cnf-&gt; –defaults-extra-file-&gt;~/my.cnf </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 mysql]#vi /etc/my.cnf</span><br><span class="line"></span><br><span class="line">[client]</span><br><span class="line">port            = 3306</span><br><span class="line">socket          = /usr/local/mysql/data/mysql.sock</span><br><span class="line">default-character-set=utf8mb4</span><br><span class="line"></span><br><span class="line">[mysqld]</span><br><span class="line">port            = 3306</span><br><span class="line">socket          = /usr/local/mysql/data/mysql.sock</span><br><span class="line">#user 			= mysqladmin</span><br><span class="line"></span><br><span class="line">skip-slave-start</span><br><span class="line"></span><br><span class="line">skip-external-locking</span><br><span class="line">key_buffer_size = 256M</span><br><span class="line">sort_buffer_size = 2M</span><br><span class="line">read_buffer_size = 2M</span><br><span class="line">read_rnd_buffer_size = 4M</span><br><span class="line">query_cache_size= 32M</span><br><span class="line">max_allowed_packet = 16M</span><br><span class="line">myisam_sort_buffer_size=128M</span><br><span class="line">tmp_table_size=32M</span><br><span class="line"></span><br><span class="line">table_open_cache = 512</span><br><span class="line">thread_cache_size = 8</span><br><span class="line">wait_timeout = 86400</span><br><span class="line">interactive_timeout = 86400</span><br><span class="line">max_connections = 600</span><br><span class="line"></span><br><span class="line"># Try number of CPU&#x27;s*2 for thread_concurrency</span><br><span class="line">#thread_concurrency = 32 </span><br><span class="line"></span><br><span class="line">#isolation level and default engine </span><br><span class="line">default-storage-engine = INNODB</span><br><span class="line">transaction-isolation = READ-COMMITTED</span><br><span class="line"></span><br><span class="line">server-id  = 1739</span><br><span class="line">basedir     = /usr/local/mysql</span><br><span class="line">datadir     = /usr/local/mysql/data</span><br><span class="line">pid-file     = /usr/local/mysql/data/hostname.pid</span><br><span class="line"></span><br><span class="line">#open performance schema</span><br><span class="line">log-warnings</span><br><span class="line">sysdate-is-now</span><br><span class="line"></span><br><span class="line">binlog_format = ROW</span><br><span class="line">log_bin_trust_function_creators=1</span><br><span class="line">log-error  = /usr/local/mysql/data/hostname.err</span><br><span class="line">log-bin = /usr/local/mysql/arch/mysql-bin</span><br><span class="line">expire_logs_days = 7</span><br><span class="line"></span><br><span class="line">innodb_write_io_threads=16</span><br><span class="line"></span><br><span class="line">relay-log  = /usr/local/mysql/relay_log/relay-log</span><br><span class="line">relay-log-index = /usr/local/mysql/relay_log/relay-log.index</span><br><span class="line">relay_log_info_file= /usr/local/mysql/relay_log/relay-log.info</span><br><span class="line"></span><br><span class="line">log_slave_updates=1</span><br><span class="line">gtid_mode=OFF</span><br><span class="line">enforce_gtid_consistency=OFF</span><br><span class="line"></span><br><span class="line"># slave</span><br><span class="line">slave-parallel-type=LOGICAL_CLOCK</span><br><span class="line">slave-parallel-workers=4</span><br><span class="line">master_info_repository=TABLE</span><br><span class="line">relay_log_info_repository=TABLE</span><br><span class="line">relay_log_recovery=ON</span><br><span class="line"></span><br><span class="line">#other logs</span><br><span class="line">#general_log =1</span><br><span class="line">#general_log_file  = /usr/local/mysql/data/general_log.err</span><br><span class="line">#slow_query_log=1</span><br><span class="line">#slow_query_log_file=/usr/local/mysql/data/slow_log.err</span><br><span class="line"></span><br><span class="line">#for replication slave</span><br><span class="line">sync_binlog = 500</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#for innodb options </span><br><span class="line">innodb_data_home_dir = /usr/local/mysql/data/</span><br><span class="line">innodb_data_file_path = ibdata1:1G;ibdata2:1G:autoextend</span><br><span class="line"></span><br><span class="line">innodb_log_group_home_dir = /usr/local/mysql/arch</span><br><span class="line">innodb_log_files_in_group = 4</span><br><span class="line">innodb_log_file_size = 1G</span><br><span class="line">innodb_log_buffer_size = 200M</span><br><span class="line"></span><br><span class="line">#根据生产需要，调整pool size </span><br><span class="line">innodb_buffer_pool_size = 2G</span><br><span class="line">#innodb_additional_mem_pool_size = 50M #deprecated in 5.6</span><br><span class="line">tmpdir = /usr/local/mysql/tmp</span><br><span class="line"></span><br><span class="line">innodb_lock_wait_timeout = 1000</span><br><span class="line">#innodb_thread_concurrency = 0</span><br><span class="line">innodb_flush_log_at_trx_commit = 2</span><br><span class="line"></span><br><span class="line">innodb_locks_unsafe_for_binlog=1</span><br><span class="line"></span><br><span class="line">#innodb io features: add for mysql5.5.8</span><br><span class="line">performance_schema</span><br><span class="line">innodb_read_io_threads=4</span><br><span class="line">innodb-write-io-threads=4</span><br><span class="line">innodb-io-capacity=200</span><br><span class="line">#purge threads change default(0) to 1 for purge</span><br><span class="line">innodb_purge_threads=1</span><br><span class="line">innodb_use_native_aio=on</span><br><span class="line"></span><br><span class="line">#case-sensitive file names and separate tablespace</span><br><span class="line">innodb_file_per_table = 1</span><br><span class="line">lower_case_table_names=1</span><br><span class="line"></span><br><span class="line">[mysqldump]</span><br><span class="line">quick</span><br><span class="line">max_allowed_packet = 128M</span><br><span class="line"></span><br><span class="line">[mysql]</span><br><span class="line">no-auto-rehash</span><br><span class="line">default-character-set=utf8mb4</span><br><span class="line"></span><br><span class="line">[mysqlhotcopy]</span><br><span class="line">interactive-timeout</span><br><span class="line"></span><br><span class="line">[myisamchk]</span><br><span class="line">key_buffer_size = 256M</span><br><span class="line">sort_buffer_size = 256M</span><br><span class="line">read_buffer = 2M</span><br><span class="line">write_buffer = 2M</span><br></pre></td></tr></table></figure>

<p>根据生产需要，调整pool size，生产上：innodb_buffer_pool_size = 2G</p>
<p>补充：</p>
<p>配置MySQL的环境变量：/etc/profile:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export MYSQL_HOME=/usr/local/mysql</span><br><span class="line">export PATH=$&#123;MYSQL_HOME&#125;/bin:$PATH</span><br></pre></td></tr></table></figure>

<h3 id="3-创建用户组及用户"><a href="#3-创建用户组及用户" class="headerlink" title="3.创建用户组及用户"></a>3.创建用户组及用户</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 mysql]# groupadd -g 101 dba</span><br><span class="line">[root@hadoop001 mysql]# useradd -u 514 -g dba -G root -d /usr/local/mysql mysqladmin</span><br><span class="line">[root@hadoop001 mysql]# id mysqladmin</span><br><span class="line">uid=514(mysqladmin) gid=101(dba) groups=101(dba),0(root)</span><br></pre></td></tr></table></figure>

<p>一般不需要设置mysqladmin的密码，直接从root或者LDAP用户sudo切换</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 mysql]# passwd mysqladmin</span><br><span class="line">Changing password for user mysqladmin.</span><br><span class="line">New password: </span><br><span class="line">BAD PASSWORD: it is too simplistic/systematic</span><br><span class="line">BAD PASSWORD: is too simple</span><br><span class="line">Retype new password: </span><br><span class="line">passwd: all authentication tokens updated successfully.</span><br></pre></td></tr></table></figure>

<p>如果mysqladmin用户已经存在，更改用户组及home目录地址：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 mysql]# usermod -u 514 -g dba -G root -d /usr/local/mysql mysqladmin</span><br></pre></td></tr></table></figure>

<p>copy 环境变量配置文件至mysqladmin用户的home目录中,为了以下步骤配置个人环境变量</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 mysql]# cp /etc/skel/.* /usr/local/mysql</span><br><span class="line">cp: omitting directory `/etc/skel/.&#x27;</span><br><span class="line">cp: omitting directory `/etc/skel/..&#x27;</span><br><span class="line">cp: omitting directory `/etc/skel/.gnome2&#x27;</span><br><span class="line">cp: omitting directory `/etc/skel/.mozilla&#x27;</span><br><span class="line">[root@hadoop001 mysql]# su - mysqladmin</span><br><span class="line">[mysqladmin@hadoop001 ~]$ exit</span><br><span class="line">logout</span><br><span class="line">[root@hadoop001 mysql]# </span><br></pre></td></tr></table></figure>

<h3 id="4-配置环境变量"><a href="#4-配置环境变量" class="headerlink" title="4.配置环境变量"></a>4.配置环境变量</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 mysql]# vi .bash_profile</span><br><span class="line"># .bash_profile</span><br><span class="line"># Get the aliases and functions</span><br><span class="line"></span><br><span class="line">if [ -f ~/.bashrc ]; then</span><br><span class="line">        . ~/.bashrc</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"># User specific environment and startup programs</span><br><span class="line">export MYSQL_BASE=/usr/local/mysql</span><br><span class="line">export PATH=$&#123;MYSQL_BASE&#125;/bin:$PATH</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">unset USERNAME</span><br><span class="line"></span><br><span class="line">#stty erase ^H</span><br><span class="line">set umask to 022</span><br><span class="line">umask 022</span><br><span class="line">PS1=`uname -n`&quot;:&quot;&#x27;$USER&#x27;&quot;:&quot;&#x27;$PWD&#x27;&quot;:&gt;&quot;; export PS1</span><br></pre></td></tr></table></figure>

<h3 id="5-赋权限和用户组"><a href="#5-赋权限和用户组" class="headerlink" title="5.赋权限和用户组"></a>5.赋权限和用户组</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 mysql]# chown mysqladmin:dba /etc/my.cnf</span><br><span class="line">[root@hadoop001 mysql]# chmod  640 /etc/my.cnf  </span><br><span class="line">[root@hadoop001 mysql]# ll /etc/my.cnf</span><br><span class="line">-rw-r-----. 1 mysqladmin dba 2218 Nov 15 01:07 /etc/my.cnf</span><br><span class="line"></span><br><span class="line">[root@hadoop001 mysql]# chown -R mysqladmin:dba /usr/local/mysql</span><br><span class="line">[root@hadoop001 mysql]# chown -R mysqladmin:dba /usr/local/mysql/*</span><br><span class="line">[root@hadoop001 mysql]# chown -R mysqladmin:dba /usr/local/mysql-5.7.11-linux-glibc2.5-x86_64</span><br><span class="line"></span><br><span class="line">[root@hadoop001 mysql]# chmod -R 755 /usr/local/mysql </span><br><span class="line">[root@hadoop001 mysql]# chmod -R 755 /usr/local/mysql/*</span><br><span class="line">[root@hadoop001 mysql]# chmod -R 755 /usr/local/mysql-5.7.11-linux-glibc2.5-x86_64 </span><br></pre></td></tr></table></figure>

<h3 id="6-配置服务及开机自启动"><a href="#6-配置服务及开机自启动" class="headerlink" title="6.配置服务及开机自启动"></a>6.配置服务及开机自启动</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#将服务文件拷贝到init.d下，并重命名为mysql</span><br><span class="line">[root@hadoop001 mysql]# cp support-files/mysql.server /etc/rc.d/init.d/mysql </span><br><span class="line">#赋予可执行权限</span><br><span class="line">[root@hadoop001 mysql]# chmod +x /etc/rc.d/init.d/mysql</span><br><span class="line">#删除服务</span><br><span class="line">[root@hadoop001 mysql]# chkconfig --del mysql</span><br><span class="line">#添加服务</span><br><span class="line">[root@hadoop001 mysql]# chkconfig --add mysql</span><br><span class="line">[root@hadoop001 mysql]# chkconfig --level 345 mysql on</span><br><span class="line">#开机自启动</span><br><span class="line">[root@hadoop001 mysql]# vi /etc/rc.local </span><br><span class="line"></span><br><span class="line">#!/bin/bash</span><br><span class="line"># THIS FILE IS ADDED FOR COMPATIBILITY PURPOSES</span><br><span class="line">#</span><br><span class="line"># It is highly advisable to create own systemd services or udev rules</span><br><span class="line"># to run scripts during boot instead of using this file.</span><br><span class="line">#</span><br><span class="line"># In contrast to previous versions due to parallel execution during boot</span><br><span class="line"># this script will NOT be run after all other services.</span><br><span class="line">#</span><br><span class="line"># Please note that you must run &#x27;chmod +x /etc/rc.d/rc.local&#x27; to ensure</span><br><span class="line"># that this script will be executed during boot.</span><br><span class="line"></span><br><span class="line">touch /var/lock/subsys/local</span><br><span class="line">su - mysqladmin -c &quot;/etc/init.d/mysql start --federated&quot;</span><br></pre></td></tr></table></figure>

<h3 id="7-安装"><a href="#7-安装" class="headerlink" title="7.安装"></a>7.安装</h3><p>安装libaio及安装mysql的初始db</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 mysql]# yum -y install libaio</span><br><span class="line">[root@hadoop001 mysql]# su - mysqladmin</span><br><span class="line">hadoop001:mysqladmin:/usr/local/mysql:&gt;bin/mysqld \</span><br><span class="line">&gt; --defaults-file=/etc/my.cnf \</span><br><span class="line">&gt; --user=mysqladmin \</span><br><span class="line">&gt; --basedir=/usr/local/mysql/ \</span><br><span class="line">&gt; --datadir=/usr/local/mysql/data/ \</span><br><span class="line">&gt; --initialize</span><br><span class="line">hadoop001:mysqladmin:/usr/local/mysql:&gt;</span><br></pre></td></tr></table></figure>

<p>在初始化时如果加上 –initial-insecure，则会创建空密码的 root@localhost 账号，否则会创建带密码的 root@localhost 账号，密码直接写在 log-error 日志文件中（在5.6版本中是放在 ~/.mysql_secret 文件里，更加隐蔽，不熟悉的话可能会无所适从）</p>
<p>bin/mysqld –defaults-file=/etc/my.cnf –user=mysqladmin –basedir=/usr/local/mysql/ –datadir=/usr/local/mysql/data/ –initialize</p>
<p>查看临时密码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hadoop001:mysqladmin:/usr/local/mysql/data:&gt;cat hostname.err | grep pass</span><br><span class="line">2021-11-24T06:05:28.300539Z 1 [Note] A temporary password is generated for root@localhost: uhsa*57&gt;hacF</span><br></pre></td></tr></table></figure>

<ul>
<li><p>启动Mysql时报错：mysqld_safe mysqld from pid file /usr/local/mysql/data/Linux.pid ended。参考文章<a href="https://blog.csdn.net/alwaysbefine/article/details/107216380">Linux The server quit without updating PID file的几种解决方法</a>发现，是之前在运行5.6版本的Mysql仍在后台运行，占用pid文件，解决方法：ps -ef|grep mysql找出进程，然后kill掉进程后再重新安装。</p>
</li>
<li><p>若遇到报错，需要重新安装</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rm -rf /usr/local/mysql/arch/*</span><br><span class="line">rm -rf /usr/local/mysql/data/*</span><br></pre></td></tr></table></figure>

<p>然后跳到第7步</p>
</li>
</ul>
<h3 id="8-启动"><a href="#8-启动" class="headerlink" title="8.启动"></a>8.启动</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 mysql]# mysql --version</span><br><span class="line">mysql  Ver 14.14 Distrib 5.7.11, for linux-glibc2.5 (x86_64) using  EditLine wrapper</span><br><span class="line">hadoop001:mysqladmin:/usr/local/mysql:&gt;service mysql start</span><br><span class="line">Starting MySQL..                                           [  OK  ]</span><br></pre></td></tr></table></figure>

<h3 id="9-登录及修改用户密码"><a href="#9-登录及修改用户密码" class="headerlink" title="9.登录及修改用户密码"></a>9.登录及修改用户密码</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hadoop001:mysqladmin:/usr/local/mysql:&gt;mysql -uroot -p&#x27;&gt;Wo&gt;kh(GL7;D&#x27;</span><br><span class="line">mysql: [Warning] Using a password on the command line interface can be insecure.</span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 2</span><br><span class="line">Server version: 5.7.11-log</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type &#x27;help;&#x27; or &#x27;\h&#x27; for help. Type &#x27;\c&#x27; to clear the current input statement.</span><br><span class="line"></span><br><span class="line">mysql&gt; alter user root@localhost identified by &#x27;syncdb123!&#x27;;//rd1</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; GRANT ALL PRIVILEGES ON *.* TO &#x27;root&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;syncdb123!&#x27;;</span><br><span class="line">Query OK, 0 rows affected, 1 warning (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; flush privileges;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; exit;</span><br><span class="line">Bye</span><br></pre></td></tr></table></figure>

<p>重要的三句话：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt;create database ruozedata;</span><br><span class="line">mysql&gt;grant all privileges on ruozedata.* to ruoze@&#x27;localhost&#x27; identified by &#x27;123456&#x27;;</span><br><span class="line">mysql&gt;flush privileges;</span><br></pre></td></tr></table></figure>

<h3 id="10-重启"><a href="#10-重启" class="headerlink" title="10.重启"></a>10.重启</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hadoop001:mysqladmin:/usr/local/mysql:&gt;service mysql restart</span><br><span class="line">Shutting down MySQL..                                      [  OK  ]</span><br><span class="line">rm: cannot remove `/var/lock/subsys/mysql&#x27;: Permission denied</span><br><span class="line">Starting MySQL.                                            [  OK  ]</span><br><span class="line">hadoop001:mysqladmin:/usr/local/mysql:&gt;</span><br><span class="line">hadoop001:mysqladmin:/usr/local/mysql:&gt;mysql -uroot -p</span><br><span class="line">Enter password: </span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 2</span><br><span class="line">Server version: 5.7.11-log MySQL Community Server (GPL)</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type &#x27;help;&#x27; or &#x27;\h&#x27; for help. Type &#x27;\c&#x27; to clear the current input statement.</span><br><span class="line"></span><br><span class="line">mysql&gt; </span><br></pre></td></tr></table></figure>



<h2 id="三-（个人）重启机器后遇到问题"><a href="#三-（个人）重启机器后遇到问题" class="headerlink" title="三.（个人）重启机器后遇到问题"></a>三.（个人）重启机器后遇到问题</h2><p>当我重启机器后，mysqladmin并不能直接service mysql start启动Mysql服务，查看data文件夹内发现有 </p>
<p><code>-rw-r-----. 1 mysql dba  53440 Nov 25 00:40 hostname.err</code></p>
<p>即用户权限出现问题。然后切回root用户修改data/*的用户：用户组为mysqladmin:dba再启动，问题解决，过程如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# service mysql status</span><br><span class="line">MySQL is not running, but lock file (/var/lock/subsys/mysql[FAILED]</span><br><span class="line">[root@hadoop001 ~]# service mysql start</span><br><span class="line">Starting MySQL.The server quit without updating PID file (/usr/local/mysql/data/hadoop001.pid).                                                          [FAILED]</span><br><span class="line">[root@hadoop001 ~]# su - mysqladmin</span><br><span class="line">hadoop001:mysqladmin:/usr/local/mysql:&gt;service mysql start</span><br><span class="line">Starting MySQL.The server quit without updating PID file (/usr/local/mysql/data/hadoop001.pid).                                                          [FAILED]</span><br><span class="line">hadoop001:mysqladmin:/usr/local/mysql:&gt;ll</span><br><span class="line">total 68</span><br><span class="line">drwxr-xr-x.  2 mysqladmin dba  4096 Nov 25 00:35 arch</span><br><span class="line">drwxr-xr-x.  2 mysqladmin dba  4096 Feb  2  2016 bin</span><br><span class="line">-rwxr-xr-x.  1 mysqladmin dba 17987 Feb  2  2016 COPYING</span><br><span class="line">drwxr-xr-x.  5 mysqladmin dba  4096 Nov 25 00:40 data</span><br><span class="line">drwxr-xr-x.  2 mysqladmin dba  4096 Feb  2  2016 docs</span><br><span class="line">drwxr-xr-x.  3 mysqladmin dba  4096 Feb  2  2016 include</span><br><span class="line">drwxr-x---.  2 mysqladmin dba  4096 Nov 24 13:15 keyring</span><br><span class="line">drwxr-xr-x.  5 mysqladmin dba  4096 Feb  2  2016 lib</span><br><span class="line">drwxr-xr-x.  4 mysqladmin dba  4096 Feb  2  2016 man</span><br><span class="line">-rwxr-xr-x.  1 mysqladmin dba  2478 Feb  2  2016 README</span><br><span class="line">drwxr-xr-x. 28 mysqladmin dba  4096 Feb  2  2016 share</span><br><span class="line">drwxr-xr-x.  2 mysqladmin dba  4096 Feb  2  2016 support-files</span><br><span class="line">drwxr-xr-x.  2 mysqladmin dba  4096 Nov 25 00:35 tmp</span><br><span class="line">hadoop001:mysqladmin:/usr/local/mysql:&gt;ll data/</span><br><span class="line">total 2097248</span><br><span class="line">-rw-r-----. 1 mysqladmin dba         56 Nov 24 14:55 auto.cnf</span><br><span class="line">-rw-r-----. 1 mysql      dba      53440 Nov 25 00:40 hostname.err</span><br><span class="line">-rw-r-----. 1 mysqladmin dba        294 Nov 25 00:35 ib_buffer_pool</span><br><span class="line">-rw-r-----. 1 mysqladmin dba 1073741824 Nov 25 00:35 ibdata1</span><br><span class="line">-rw-r-----. 1 mysqladmin dba 1073741824 Nov 24 14:55 ibdata2</span><br><span class="line">drwxr-x---. 2 mysqladmin dba       4096 Nov 24 14:55 mysql</span><br><span class="line">drwxr-x---. 2 mysqladmin dba       4096 Nov 24 14:55 performance_schema</span><br><span class="line">drwxr-x---. 2 mysqladmin dba      12288 Nov 24 14:55 sys</span><br><span class="line">hadoop001:mysqladmin:/usr/local/mysql:&gt;exit</span><br><span class="line">logout</span><br><span class="line">[root@hadoop001 ~]# chown mysqladmin:dba /usr/local/mysql/*</span><br><span class="line">[root@hadoop001 ~]# chown mysqladmin:dba /usr/local/mysql/data/*</span><br><span class="line">[root@hadoop001 ~]# su - mysqladmin</span><br><span class="line">hadoop001:mysqladmin:/usr/local/mysql:&gt;ll data/</span><br><span class="line">total 2097248</span><br><span class="line">-rw-r-----. 1 mysqladmin dba         56 Nov 24 14:55 auto.cnf</span><br><span class="line">-rw-r-----. 1 mysqladmin dba      53440 Nov 25 00:40 hostname.err</span><br><span class="line">-rw-r-----. 1 mysqladmin dba        294 Nov 25 00:35 ib_buffer_pool</span><br><span class="line">-rw-r-----. 1 mysqladmin dba 1073741824 Nov 25 00:35 ibdata1</span><br><span class="line">-rw-r-----. 1 mysqladmin dba 1073741824 Nov 24 14:55 ibdata2</span><br><span class="line">drwxr-x---. 2 mysqladmin dba       4096 Nov 24 14:55 mysql</span><br><span class="line">drwxr-x---. 2 mysqladmin dba       4096 Nov 24 14:55 performance_schema</span><br><span class="line">drwxr-x---. 2 mysqladmin dba      12288 Nov 24 14:55 sys</span><br><span class="line">hadoop001:mysqladmin:/usr/local/mysql:&gt;service mysql start</span><br><span class="line">Starting MySQL.                                            [  OK  ]</span><br><span class="line">hadoop001:mysqladmin:/usr/local/mysql:&gt;ll data/</span><br><span class="line">total 2109552</span><br><span class="line">-rw-r-----. 1 mysqladmin dba         56 Nov 24 14:55 auto.cnf</span><br><span class="line">-rw-r-----. 1 mysqladmin dba          5 Nov 25 00:41 hadoop001.pid</span><br><span class="line">-rw-r-----. 1 mysqladmin dba      57597 Nov 25 00:41 hostname.err</span><br><span class="line">-rw-r-----. 1 mysqladmin dba        294 Nov 25 00:35 ib_buffer_pool</span><br><span class="line">-rw-r-----. 1 mysqladmin dba 1073741824 Nov 25 00:41 ibdata1</span><br><span class="line">-rw-r-----. 1 mysqladmin dba 1073741824 Nov 24 14:55 ibdata2</span><br><span class="line">-rw-r-----. 1 mysqladmin dba   12582912 Nov 25 00:41 ibtmp1</span><br><span class="line">drwxr-x---. 2 mysqladmin dba       4096 Nov 24 14:55 mysql</span><br><span class="line">-rw-rw----. 1 mysqladmin dba          5 Nov 25 00:41 mysqld_safe.pid</span><br><span class="line">srwxrwxrwx. 1 mysqladmin dba          0 Nov 25 00:41 mysql.sock</span><br><span class="line">-rw-------. 1 mysqladmin dba          5 Nov 25 00:41 mysql.sock.lock</span><br><span class="line">drwxr-x---. 2 mysqladmin dba       4096 Nov 24 14:55 performance_schema</span><br><span class="line">drwxr-x---. 2 mysqladmin dba      12288 Nov 24 14:55 sys</span><br><span class="line">hadoop001:mysqladmin:/usr/local/mysql:&gt;exit</span><br><span class="line">logout</span><br><span class="line">[root@hadoop001 ~]# </span><br></pre></td></tr></table></figure>

<p>再次重启，问题再次出现，hostname.err的用户用户组为：mysql:mysqladmin</p>
<p>经查阅，发现my.cnf中[mysqld]下有默认启动用户<code>user = mysql</code>，指定为<code>user = mysqladmin</code>后重启，问题不再出现，且mysql服务开机自启动</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">port            = 3306</span><br><span class="line">socket          = /usr/local/mysql/data/mysql.sock</span><br><span class="line">#以下注释为默认参数，不指定的话，user=mysql</span><br><span class="line">#user 			= mysql</span><br><span class="line">user 			= mysqladmin</span><br></pre></td></tr></table></figure>

]]></content>
  </entry>
  <entry>
    <title>SQL练习题</title>
    <url>/2021/11/29/SQL%E7%BB%83%E4%B9%A0%E9%A2%98/</url>
    <content><![CDATA[<h1 id="SQL练习题"><a href="#SQL练习题" class="headerlink" title="SQL练习题"></a>SQL练习题</h1><p>–部门表<br>dept部门表(deptno部门编号/dname部门名称/loc地点)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create table dept (deptno numeric(2),dname varchar(14),loc varchar(13));</span><br><span class="line">insert into dept values (10, &#x27;ACCOUNTING&#x27;, &#x27;NEW YORK&#x27;);</span><br><span class="line">insert into dept values (20, &#x27;RESEARCH&#x27;, &#x27;DALLAS&#x27;);</span><br><span class="line">insert into dept values (30, &#x27;SALES&#x27;, &#x27;CHICAGO&#x27;);</span><br><span class="line">insert into dept values (40, &#x27;OPERATIONS&#x27;, &#x27;BOSTON&#x27;);</span><br></pre></td></tr></table></figure>

<p>–工资等级表<br>salgrade工资等级表(grade 等级/losal此等级的最低/hisal此等级的最高)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create table salgrade (grade numeric,losal numeric,hisal numeric);</span><br><span class="line">insert into salgrade values (1, 700, 1200);</span><br><span class="line">insert into salgrade values (2, 1201, 1400);</span><br><span class="line">insert into salgrade values (3, 1401, 2000);</span><br><span class="line">insert into salgrade values (4, 2001, 3000);</span><br><span class="line">insert into salgrade values (5, 3001, 9999);</span><br></pre></td></tr></table></figure>

<span id="more"></span>

<p>–员工表<br>emp员工表(empno员工号/ename员工姓名/job工作/mgr上级编号/hiredate受雇日期/sal薪金/comm佣金/deptno部门编号)<br>工资 ＝ 薪金 ＋ 佣金</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create table emp (</span><br><span class="line">    empno numeric(4) not null,</span><br><span class="line">    ename varchar(10),</span><br><span class="line">    job varchar(9),</span><br><span class="line">    mgr numeric(4),</span><br><span class="line">    hiredate datetime,</span><br><span class="line">    sal numeric(7, 2),</span><br><span class="line">    comm numeric(7, 2),</span><br><span class="line">    deptno numeric(2)</span><br><span class="line">);</span><br><span class="line">insert into emp values (7369, &#x27;SMITH&#x27;, &#x27;CLERK&#x27;, 7902, &#x27;1980-12-17&#x27;, 800, null, 20);</span><br><span class="line">insert into emp values (7499, &#x27;ALLEN&#x27;, &#x27;SALESMAN&#x27;, 7698, &#x27;1981-02-20&#x27;, 1600, 300, 30);</span><br><span class="line">insert into emp values (7521, &#x27;WARD&#x27;, &#x27;SALESMAN&#x27;, 7698, &#x27;1981-02-22&#x27;, 1250, 500, 30);</span><br><span class="line">insert into emp values (7566, &#x27;JONES&#x27;, &#x27;MANAGER&#x27;, 7839, &#x27;1981-04-02&#x27;, 2975, null, 20);</span><br><span class="line">insert into emp values (7654, &#x27;MARTIN&#x27;, &#x27;SALESMAN&#x27;, 7698, &#x27;1981-09-28&#x27;, 1250, 1400, 30);</span><br><span class="line">insert into emp values (7698, &#x27;BLAKE&#x27;, &#x27;MANAGER&#x27;, 7839, &#x27;1981-05-01&#x27;, 2850, null, 30);</span><br><span class="line">insert into emp values (7782, &#x27;CLARK&#x27;, &#x27;MANAGER&#x27;, 7839, &#x27;1981-06-09&#x27;, 2450, null, 10);</span><br><span class="line">insert into emp values (7788, &#x27;SCOTT&#x27;, &#x27;ANALYST&#x27;, 7566, &#x27;1982-12-09&#x27;, 3000, null, 20);</span><br><span class="line">insert into emp values (7839, &#x27;KING&#x27;, &#x27;PRESIDENT&#x27;, null, &#x27;1981-11-17&#x27;, 5000, null, 10);</span><br><span class="line">insert into emp values (7844, &#x27;TURNER&#x27;, &#x27;SALESMAN&#x27;, 7698, &#x27;1981-09-08&#x27;, 1500, 0, 30);</span><br><span class="line">insert into emp values (7876, &#x27;ADAMS&#x27;, &#x27;CLERK&#x27;, 7788, &#x27;1983-01-12&#x27;, 1100, null, 20);</span><br><span class="line">insert into emp values (7900, &#x27;JAMES&#x27;, &#x27;CLERK&#x27;, 7698, &#x27;1981-12-03&#x27;, 950, null, 30);</span><br><span class="line">insert into emp values (7902, &#x27;FORD&#x27;, &#x27;ANALYST&#x27;, 7566, &#x27;1981-12-03&#x27;, 3000, null, 20);</span><br><span class="line">insert into emp values (7934, &#x27;MILLER&#x27;, &#x27;CLERK&#x27;, 7782, &#x27;1982-01-23&#x27;, 1300, null, 10);</span><br></pre></td></tr></table></figure>

<p>1.查询出部门编号为30的所有员工的编号和姓名</p>
<p>2.找出部门编号为10中所有经理，和部门编号为20中所有销售员的详细资料。</p>
<p>3.查询所有员工详细信息，用工资降序排序，如果工资相同使用入职日期升序排序</p>
<p>4.列出薪金大于1500的各种工作及从事此工作的员工人数。</p>
<p>5.列出在销售部工作的员工的姓名，假定不知道销售部的部门编号。</p>
<p>6.查询姓名以S开头的\以S结尾\包含S字符\第二个字母为L  __</p>
<p>7.查询每种工作的最高工资、最低工资、人数</p>
<p>8.列出薪金 高于 公司平均薪金的所有员工号，员工姓名，所在部门名称，上级领导，工资，工资等级</p>
<p>9.列出薪金  高于  在部门30工作的  所有/任何一个员工的薪金的员工姓名和薪金、部门名称。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; use ruozedata</span><br><span class="line">Database changed</span><br><span class="line">mysql&gt; create table dept (</span><br><span class="line">    -&gt;     deptno numeric(2),</span><br><span class="line">    -&gt;     dname varchar(14),</span><br><span class="line">    -&gt;     loc varchar(13)</span><br><span class="line">    -&gt; );</span><br><span class="line">Query OK, 0 rows affected (0.02 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into dept values (10, &#x27;ACCOUNTING&#x27;, &#x27;NEW YORK&#x27;);</span><br><span class="line">Query OK, 1 row affected (0.02 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into dept values (20, &#x27;RESEARCH&#x27;, &#x27;DALLAS&#x27;);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into dept values (30, &#x27;SALES&#x27;, &#x27;CHICAGO&#x27;);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into dept values (40, &#x27;OPERATIONS&#x27;, &#x27;BOSTON&#x27;);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; create table salgrade (</span><br><span class="line">    -&gt;     grade numeric,</span><br><span class="line">    -&gt;     losal numeric,</span><br><span class="line">    -&gt;     hisal numeric</span><br><span class="line">    -&gt; );</span><br><span class="line">Query OK, 0 rows affected (0.02 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into salgrade values (1, 700, 1200);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into salgrade values (2, 1201, 1400);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into salgrade values (3, 1401, 2000);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into salgrade values (4, 2001, 3000);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into salgrade values (5, 3001, 9999);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; create table emp (</span><br><span class="line">    -&gt;     empno numeric(4) not null,</span><br><span class="line">    -&gt;     ename varchar(10),</span><br><span class="line">    -&gt;     job varchar(9),</span><br><span class="line">    -&gt;     mgr numeric(4),</span><br><span class="line">    -&gt;     hiredate datetime,</span><br><span class="line">    -&gt;     sal numeric(7, 2),</span><br><span class="line">    -&gt;     comm numeric(7, 2),</span><br><span class="line">    -&gt;     deptno numeric(2)</span><br><span class="line">    -&gt; );</span><br><span class="line">Query OK, 0 rows affected (0.02 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into emp values (7369, &#x27;SMITH&#x27;, &#x27;CLERK&#x27;, 7902, &#x27;1980-12-17&#x27;, 800, null, 20);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into emp values (7499, &#x27;ALLEN&#x27;, &#x27;SALESMAN&#x27;, 7698, &#x27;1981-02-20&#x27;, 1600, 300, 30);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into emp values (7521, &#x27;WARD&#x27;, &#x27;SALESMAN&#x27;, 7698, &#x27;1981-02-22&#x27;, 1250, 500, 30);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into emp values (7566, &#x27;JONES&#x27;, &#x27;MANAGER&#x27;, 7839, &#x27;1981-04-02&#x27;, 2975, null, 20);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into emp values (7654, &#x27;MARTIN&#x27;, &#x27;SALESMAN&#x27;, 7698, &#x27;1981-09-28&#x27;, 1250, 1400, 30);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into emp values (7698, &#x27;BLAKE&#x27;, &#x27;MANAGER&#x27;, 7839, &#x27;1981-05-01&#x27;, 2850, null, 30);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into emp values (7782, &#x27;CLARK&#x27;, &#x27;MANAGER&#x27;, 7839, &#x27;1981-06-09&#x27;, 2450, null, 10);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into emp values (7788, &#x27;SCOTT&#x27;, &#x27;ANALYST&#x27;, 7566, &#x27;1982-12-09&#x27;, 3000, null, 20);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into emp values (7839, &#x27;KING&#x27;, &#x27;PRESIDENT&#x27;, null, &#x27;1981-11-17&#x27;, 5000, null, 10); </span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into emp values (7844, &#x27;TURNER&#x27;, &#x27;SALESMAN&#x27;, 7698, &#x27;1981-09-08&#x27;, 1500, 0, 30);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into emp values (7876, &#x27;ADAMS&#x27;, &#x27;CLERK&#x27;, 7788, &#x27;1983-01-12&#x27;, 1100, null, 20);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into emp values (7900, &#x27;JAMES&#x27;, &#x27;CLERK&#x27;, 7698, &#x27;1981-12-03&#x27;, 950, null, 30);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into emp values (7902, &#x27;FORD&#x27;, &#x27;ANALYST&#x27;, 7566, &#x27;1981-12-03&#x27;, 3000, null, 20);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into emp values (7934, &#x27;MILLER&#x27;, &#x27;CLERK&#x27;, 7782, &#x27;1982-01-23&#x27;, 1300, null, 10);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; show tables;</span><br><span class="line">+---------------------+</span><br><span class="line">| Tables_in_ruozedata |</span><br><span class="line">+---------------------+</span><br><span class="line">| dept                |</span><br><span class="line">| emp                 |</span><br><span class="line">| salgrade            |</span><br><span class="line">+---------------------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from dept;</span><br><span class="line">+--------+------------+----------+</span><br><span class="line">| deptno | dname      | loc      |</span><br><span class="line">+--------+------------+----------+</span><br><span class="line">|     10 | ACCOUNTING | NEW YORK |</span><br><span class="line">|     20 | RESEARCH   | DALLAS   |</span><br><span class="line">|     30 | SALES      | CHICAGO  |</span><br><span class="line">|     40 | OPERATIONS | BOSTON   |</span><br><span class="line">+--------+------------+----------+</span><br><span class="line">4 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from emp;</span><br><span class="line">+-------+--------+-----------+------+---------------------+---------+---------+--------+</span><br><span class="line">| empno | ename  | job       | mgr  | hiredate            | sal     | comm    | deptno |</span><br><span class="line">+-------+--------+-----------+------+---------------------+---------+---------+--------+</span><br><span class="line">|  7369 | SMITH  | CLERK     | 7902 | 1980-12-17 00:00:00 |  800.00 |    NULL |     20 |</span><br><span class="line">|  7499 | ALLEN  | SALESMAN  | 7698 | 1981-02-20 00:00:00 | 1600.00 |  300.00 |     30 |</span><br><span class="line">|  7521 | WARD   | SALESMAN  | 7698 | 1981-02-22 00:00:00 | 1250.00 |  500.00 |     30 |</span><br><span class="line">|  7566 | JONES  | MANAGER   | 7839 | 1981-04-02 00:00:00 | 2975.00 |    NULL |     20 |</span><br><span class="line">|  7654 | MARTIN | SALESMAN  | 7698 | 1981-09-28 00:00:00 | 1250.00 | 1400.00 |     30 |</span><br><span class="line">|  7698 | BLAKE  | MANAGER   | 7839 | 1981-05-01 00:00:00 | 2850.00 |    NULL |     30 |</span><br><span class="line">|  7782 | CLARK  | MANAGER   | 7839 | 1981-06-09 00:00:00 | 2450.00 |    NULL |     10 |</span><br><span class="line">|  7788 | SCOTT  | ANALYST   | 7566 | 1982-12-09 00:00:00 | 3000.00 |    NULL |     20 |</span><br><span class="line">|  7839 | KING   | PRESIDENT | NULL | 1981-11-17 00:00:00 | 5000.00 |    NULL |     10 |</span><br><span class="line">|  7844 | TURNER | SALESMAN  | 7698 | 1981-09-08 00:00:00 | 1500.00 |    0.00 |     30 |</span><br><span class="line">|  7876 | ADAMS  | CLERK     | 7788 | 1983-01-12 00:00:00 | 1100.00 |    NULL |     20 |</span><br><span class="line">|  7900 | JAMES  | CLERK     | 7698 | 1981-12-03 00:00:00 |  950.00 |    NULL |     30 |</span><br><span class="line">|  7902 | FORD   | ANALYST   | 7566 | 1981-12-03 00:00:00 | 3000.00 |    NULL |     20 |</span><br><span class="line">|  7934 | MILLER | CLERK     | 7782 | 1982-01-23 00:00:00 | 1300.00 |    NULL |     10 |</span><br><span class="line">+-------+--------+-----------+------+---------------------+---------+---------+--------+</span><br><span class="line">14 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from salgrade;</span><br><span class="line">+-------+-------+-------+</span><br><span class="line">| grade | losal | hisal |</span><br><span class="line">+-------+-------+-------+</span><br><span class="line">|     1 |   700 |  1200 |</span><br><span class="line">|     2 |  1201 |  1400 |</span><br><span class="line">|     3 |  1401 |  2000 |</span><br><span class="line">|     4 |  2001 |  3000 |</span><br><span class="line">|     5 |  3001 |  9999 |</span><br><span class="line">+-------+-------+-------+</span><br><span class="line">5 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; </span><br></pre></td></tr></table></figure>

<h2 id="一、查询出部门编号为30的所有员工的编号和姓名"><a href="#一、查询出部门编号为30的所有员工的编号和姓名" class="headerlink" title="一、查询出部门编号为30的所有员工的编号和姓名"></a>一、查询出部门编号为30的所有员工的编号和姓名</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; select empno,ename from emp where deptno = 30;</span><br><span class="line">+-------+--------+</span><br><span class="line">| empno | ename  |</span><br><span class="line">+-------+--------+</span><br><span class="line">|  7499 | ALLEN  |</span><br><span class="line">|  7521 | WARD   |</span><br><span class="line">|  7654 | MARTIN |</span><br><span class="line">|  7698 | BLAKE  |</span><br><span class="line">|  7844 | TURNER |</span><br><span class="line">|  7900 | JAMES  |</span><br><span class="line">+-------+--------+</span><br><span class="line">6 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>

<h2 id="二、找出部门编号为10中所有经理，和部门编号为20中所有销售员的详细资料。"><a href="#二、找出部门编号为10中所有经理，和部门编号为20中所有销售员的详细资料。" class="headerlink" title="二、找出部门编号为10中所有经理，和部门编号为20中所有销售员的详细资料。"></a>二、找出部门编号为10中所有经理，和部门编号为20中所有销售员的详细资料。</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; select * from emp where job = &quot;MANAGER&quot; and deptno = 10 union all select * from emp where job = &quot;SALESMAN&quot; and deptno = 20;</span><br><span class="line">+-------+-------+---------+------+---------------------+---------+------+--------+</span><br><span class="line">| empno | ename | job     | mgr  | hiredate            | sal     | comm | deptno |</span><br><span class="line">+-------+-------+---------+------+---------------------+---------+------+--------+</span><br><span class="line">|  7782 | CLARK | MANAGER | 7839 | 1981-06-09 00:00:00 | 2450.00 | NULL |     10 |</span><br><span class="line">+-------+-------+---------+------+---------------------+---------+------+--------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from emp where job = &quot;MANAGER&quot; and deptno = 10 or job = &quot;SALESMAN&quot; and deptno = 20;</span><br><span class="line">+-------+-------+---------+------+---------------------+---------+------+--------+</span><br><span class="line">| empno | ename | job     | mgr  | hiredate            | sal     | comm | deptno |</span><br><span class="line">+-------+-------+---------+------+---------------------+---------+------+--------+</span><br><span class="line">|  7782 | CLARK | MANAGER | 7839 | 1981-06-09 00:00:00 | 2450.00 | NULL |     10 |</span><br><span class="line">+-------+-------+---------+------+---------------------+---------+------+--------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure>

<h2 id="三、查询所有员工详细信息，用工资降序排序，如果工资相同使用入职日期升序排序"><a href="#三、查询所有员工详细信息，用工资降序排序，如果工资相同使用入职日期升序排序" class="headerlink" title="三、查询所有员工详细信息，用工资降序排序，如果工资相同使用入职日期升序排序"></a>三、查询所有员工详细信息，用工资降序排序，如果工资相同使用入职日期升序排序</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; select * from emp order by sal desc, hiredate;</span><br><span class="line">+-------+--------+-----------+------+---------------------+---------+---------+--------+</span><br><span class="line">| empno | ename  | job       | mgr  | hiredate            | sal     | comm    | deptno |</span><br><span class="line">+-------+--------+-----------+------+---------------------+---------+---------+--------+</span><br><span class="line">|  7839 | KING   | PRESIDENT | NULL | 1981-11-17 00:00:00 | 5000.00 |    NULL |     10 |</span><br><span class="line">|  7902 | FORD   | ANALYST   | 7566 | 1981-12-03 00:00:00 | 3000.00 |    NULL |     20 |</span><br><span class="line">|  7788 | SCOTT  | ANALYST   | 7566 | 1982-12-09 00:00:00 | 3000.00 |    NULL |     20 |</span><br><span class="line">|  7566 | JONES  | MANAGER   | 7839 | 1981-04-02 00:00:00 | 2975.00 |    NULL |     20 |</span><br><span class="line">|  7698 | BLAKE  | MANAGER   | 7839 | 1981-05-01 00:00:00 | 2850.00 |    NULL |     30 |</span><br><span class="line">|  7782 | CLARK  | MANAGER   | 7839 | 1981-06-09 00:00:00 | 2450.00 |    NULL |     10 |</span><br><span class="line">|  7499 | ALLEN  | SALESMAN  | 7698 | 1981-02-20 00:00:00 | 1600.00 |  300.00 |     30 |</span><br><span class="line">|  7844 | TURNER | SALESMAN  | 7698 | 1981-09-08 00:00:00 | 1500.00 |    0.00 |     30 |</span><br><span class="line">|  7934 | MILLER | CLERK     | 7782 | 1982-01-23 00:00:00 | 1300.00 |    NULL |     10 |</span><br><span class="line">|  7521 | WARD   | SALESMAN  | 7698 | 1981-02-22 00:00:00 | 1250.00 |  500.00 |     30 |</span><br><span class="line">|  7654 | MARTIN | SALESMAN  | 7698 | 1981-09-28 00:00:00 | 1250.00 | 1400.00 |     30 |</span><br><span class="line">|  7876 | ADAMS  | CLERK     | 7788 | 1983-01-12 00:00:00 | 1100.00 |    NULL |     20 |</span><br><span class="line">|  7900 | JAMES  | CLERK     | 7698 | 1981-12-03 00:00:00 |  950.00 |    NULL |     30 |</span><br><span class="line">|  7369 | SMITH  | CLERK     | 7902 | 1980-12-17 00:00:00 |  800.00 |    NULL |     20 |</span><br><span class="line">+-------+--------+-----------+------+---------------------+---------+---------+--------+</span><br><span class="line">14 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>

<h2 id="四、列出薪金大于1500的各种工作及从事此工作的员工人数。"><a href="#四、列出薪金大于1500的各种工作及从事此工作的员工人数。" class="headerlink" title="四、列出薪金大于1500的各种工作及从事此工作的员工人数。"></a>四、列出薪金大于1500的各种工作及从事此工作的员工人数。</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; select job,count(job) from emp where sal &gt; 1500 group by job ;</span><br><span class="line">+-----------+------------+</span><br><span class="line">| job       | count(job) |</span><br><span class="line">+-----------+------------+</span><br><span class="line">| ANALYST   |          2 |</span><br><span class="line">| MANAGER   |          3 |</span><br><span class="line">| PRESIDENT |          1 |</span><br><span class="line">| SALESMAN  |          1 |</span><br><span class="line">+-----------+------------+</span><br><span class="line">4 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>

<h2 id="五、列出在销售部工作的员工的姓名，假定不知道销售部的部门编号。"><a href="#五、列出在销售部工作的员工的姓名，假定不知道销售部的部门编号。" class="headerlink" title="五、列出在销售部工作的员工的姓名，假定不知道销售部的部门编号。"></a>五、列出在销售部工作的员工的姓名，假定不知道销售部的部门编号。</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; select ename from emp left join dept on emp.deptno = dept.deptno where dept.dname = &quot;SALES&quot;;</span><br><span class="line">+--------+</span><br><span class="line">| ename  |</span><br><span class="line">+--------+</span><br><span class="line">| ALLEN  |</span><br><span class="line">| WARD   |</span><br><span class="line">| MARTIN |</span><br><span class="line">| BLAKE  |</span><br><span class="line">| TURNER |</span><br><span class="line">| JAMES  |</span><br><span class="line">+--------+</span><br><span class="line">6 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select ename from emp</span><br><span class="line">    -&gt; where deptno=</span><br><span class="line">    -&gt; (select deptno from dept where dname=&#x27;SALES&#x27;);</span><br><span class="line">+--------+</span><br><span class="line">| ename  |</span><br><span class="line">+--------+</span><br><span class="line">| ALLEN  |</span><br><span class="line">| WARD   |</span><br><span class="line">| MARTIN |</span><br><span class="line">| BLAKE  |</span><br><span class="line">| TURNER |</span><br><span class="line">| JAMES  |</span><br><span class="line">+--------+</span><br><span class="line">6 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>

<h2 id="六、查询姓名以S开头的-以S结尾-包含S字符-第二个字母为L"><a href="#六、查询姓名以S开头的-以S结尾-包含S字符-第二个字母为L" class="headerlink" title="六、查询姓名以S开头的\以S结尾\包含S字符\第二个字母为L"></a>六、查询姓名以S开头的\以S结尾\包含S字符\第二个字母为L</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; select ename from emp where ename like &quot;S%&quot;;</span><br><span class="line">+-------+</span><br><span class="line">| ename |</span><br><span class="line">+-------+</span><br><span class="line">| SMITH |</span><br><span class="line">| SCOTT |</span><br><span class="line">+-------+</span><br><span class="line">2 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select ename from emp where ename like &quot;%S&quot;;</span><br><span class="line">+-------+</span><br><span class="line">| ename |</span><br><span class="line">+-------+</span><br><span class="line">| JONES |</span><br><span class="line">| ADAMS |</span><br><span class="line">| JAMES |</span><br><span class="line">+-------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select ename from emp where ename like &quot;%S%&quot;;</span><br><span class="line">+-------+</span><br><span class="line">| ename |</span><br><span class="line">+-------+</span><br><span class="line">| SMITH |</span><br><span class="line">| JONES |</span><br><span class="line">| SCOTT |</span><br><span class="line">| ADAMS |</span><br><span class="line">| JAMES |</span><br><span class="line">+-------+</span><br><span class="line">5 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select ename from emp where ename like &quot;_L%&quot;;</span><br><span class="line">+-------+</span><br><span class="line">| ename |</span><br><span class="line">+-------+</span><br><span class="line">| ALLEN |</span><br><span class="line">| BLAKE |</span><br><span class="line">| CLARK |</span><br><span class="line">+-------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>

<h2 id="七、查询每种工作的最高工资、最低工资、人数"><a href="#七、查询每种工作的最高工资、最低工资、人数" class="headerlink" title="七、查询每种工作的最高工资、最低工资、人数"></a>七、查询每种工作的最高工资、最低工资、人数</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; select job,max(sal+ifnull(comm,0)) as sal_max,min(sal+ifnull(comm,0)) as sal_min,count(empno) as count from emp group by job;</span><br><span class="line">+-----------+---------+---------+-------+</span><br><span class="line">| job       | sal_max | sal_min | count |</span><br><span class="line">+-----------+---------+---------+-------+</span><br><span class="line">| ANALYST   | 3000.00 | 3000.00 |     2 |</span><br><span class="line">| CLERK     | 1300.00 |  800.00 |     4 |</span><br><span class="line">| MANAGER   | 2975.00 | 2450.00 |     3 |</span><br><span class="line">| PRESIDENT | 5000.00 | 5000.00 |     1 |</span><br><span class="line">| SALESMAN  | 2650.00 | 1500.00 |     4 |</span><br><span class="line">+-----------+---------+---------+-------+</span><br><span class="line">5 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>

<h2 id="八、列出薪金-高于-公司平均薪金的所有员工号，员工姓名，所在部门名称，上级领导，工资，工资等级"><a href="#八、列出薪金-高于-公司平均薪金的所有员工号，员工姓名，所在部门名称，上级领导，工资，工资等级" class="headerlink" title="八、列出薪金 高于 公司平均薪金的所有员工号，员工姓名，所在部门名称，上级领导，工资，工资等级"></a>八、列出薪金 高于 公司平均薪金的所有员工号，员工姓名，所在部门名称，上级领导，工资，工资等级</h2><ol>
<li><p>找出平均薪金：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; select avg(sal+ifnull(comm,0)) from emp;</span><br><span class="line">+-------------------------+</span><br><span class="line">| avg(sal+ifnull(comm,0)) |</span><br><span class="line">+-------------------------+</span><br><span class="line">|             2230.357143 |</span><br><span class="line">+-------------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>薪金 高于 公司平均薪金的所有员工号,员工姓名,工资：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; select empno,ename,sal+ifnull(comm,0) as empsal from emp where sal+ifnull(comm,0) &gt; (select avg(sal+ifnull(comm,0)) from emp);</span><br><span class="line">+-------+--------+---------+</span><br><span class="line">| empno | ename  | empsal  |</span><br><span class="line">+-------+--------+---------+</span><br><span class="line">|  7566 | JONES  | 2975.00 |</span><br><span class="line">|  7654 | MARTIN | 2650.00 |</span><br><span class="line">|  7698 | BLAKE  | 2850.00 |</span><br><span class="line">|  7782 | CLARK  | 2450.00 |</span><br><span class="line">|  7788 | SCOTT  | 3000.00 |</span><br><span class="line">|  7839 | KING   | 5000.00 |</span><br><span class="line">|  7902 | FORD   | 3000.00 |</span><br><span class="line">+-------+--------+---------+</span><br><span class="line">7 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></li>
<li><p>加上部门名称,工资等级</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; select </span><br><span class="line">    -&gt; empno,ename,sal+ifnull(comm,0) as empsal,dname,grade</span><br><span class="line">    -&gt; from emp left join dept </span><br><span class="line">    -&gt; on emp.deptno = dept.deptno </span><br><span class="line">    -&gt; left join salgrade</span><br><span class="line">    -&gt; on sal+ifnull(comm,0) between losal and hisal</span><br><span class="line">    -&gt; where </span><br><span class="line">    -&gt; sal+ifnull(comm,0) &gt; (select avg(sal+ifnull(comm,0)) from emp);</span><br><span class="line">+-------+--------+---------+------------+-------+</span><br><span class="line">| empno | ename  | empsal  | dname      | grade |</span><br><span class="line">+-------+--------+---------+------------+-------+</span><br><span class="line">|  7782 | CLARK  | 2450.00 | ACCOUNTING |     4 |</span><br><span class="line">|  7566 | JONES  | 2975.00 | RESEARCH   |     4 |</span><br><span class="line">|  7788 | SCOTT  | 3000.00 | RESEARCH   |     4 |</span><br><span class="line">|  7902 | FORD   | 3000.00 | RESEARCH   |     4 |</span><br><span class="line">|  7654 | MARTIN | 2650.00 | SALES      |     4 |</span><br><span class="line">|  7698 | BLAKE  | 2850.00 | SALES      |     4 |</span><br><span class="line">|  7839 | KING   | 5000.00 | ACCOUNTING |     5 |</span><br><span class="line">+-------+--------+---------+------------+-------+</span><br><span class="line">7 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></li>
<li><p>加上领导名称</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; select </span><br><span class="line">    -&gt; e1.empno,e1.ename,e1.sal+ifnull(e1.comm,0) as empsal,dname,grade,e2.ename as mgrname</span><br><span class="line">    -&gt; from emp e1 </span><br><span class="line">    -&gt; left join emp e2 on e1.mgr = e2.empno </span><br><span class="line">    -&gt; left join dept on e1.deptno = dept.deptno </span><br><span class="line">    -&gt; left join salgrade on e1.sal+ifnull(e1.comm,0) between losal and hisal</span><br><span class="line">    -&gt; where e1.sal+ifnull(e1.comm,0) &gt; (select avg(sal+ifnull(comm,0)) from emp);</span><br><span class="line">+-------+--------+---------+------------+-------+---------+</span><br><span class="line">| empno | ename  | empsal  | dname      | grade | mgrname |</span><br><span class="line">+-------+--------+---------+------------+-------+---------+</span><br><span class="line">|  7782 | CLARK  | 2450.00 | ACCOUNTING |     4 | KING    |</span><br><span class="line">|  7788 | SCOTT  | 3000.00 | RESEARCH   |     4 | JONES   |</span><br><span class="line">|  7902 | FORD   | 3000.00 | RESEARCH   |     4 | JONES   |</span><br><span class="line">|  7566 | JONES  | 2975.00 | RESEARCH   |     4 | KING    |</span><br><span class="line">|  7654 | MARTIN | 2650.00 | SALES      |     4 | BLAKE   |</span><br><span class="line">|  7698 | BLAKE  | 2850.00 | SALES      |     4 | KING    |</span><br><span class="line">|  7839 | KING   | 5000.00 | ACCOUNTING |     5 | NULL    |</span><br><span class="line">+-------+--------+---------+------------+-------+---------+</span><br><span class="line">7 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="九、列出薪金-高于-在部门30工作的-所有-任意一个员工的薪金的员工姓名和薪金、部门名称。"><a href="#九、列出薪金-高于-在部门30工作的-所有-任意一个员工的薪金的员工姓名和薪金、部门名称。" class="headerlink" title="九、列出薪金  高于  在部门30工作的  所有/任意一个员工的薪金的员工姓名和薪金、部门名称。"></a>九、列出薪金  高于  在部门30工作的  所有/任意一个员工的薪金的员工姓名和薪金、部门名称。</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; select ename,sal+ifnull(comm,0) as empsal,dname  from emp  left join dept on emp.deptno = dept.deptno where sal+ifnull(comm,0) &gt; ALL( select sal+ifnull(comm,0) from emp where deptno=30 );</span><br><span class="line">+-------+---------+------------+</span><br><span class="line">| ename | empsal  | dname      |</span><br><span class="line">+-------+---------+------------+</span><br><span class="line">| KING  | 5000.00 | ACCOUNTING |</span><br><span class="line">| JONES | 2975.00 | RESEARCH   |</span><br><span class="line">| SCOTT | 3000.00 | RESEARCH   |</span><br><span class="line">| FORD  | 3000.00 | RESEARCH   |</span><br><span class="line">+-------+---------+------------+</span><br><span class="line">4 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select ename,sal+ifnull(comm,0) as empsal,dname  from emp  left join dept on emp.deptno = dept.deptno where sal+ifnull(comm,0) &gt; ANY( select sal+ifnull(comm,0) from emp where deptno==30 );</span><br><span class="line">+--------+---------+------------+</span><br><span class="line">| ename  | empsal  | dname      |</span><br><span class="line">+--------+---------+------------+</span><br><span class="line">| CLARK  | 2450.00 | ACCOUNTING |</span><br><span class="line">| KING   | 5000.00 | ACCOUNTING |</span><br><span class="line">| MILLER | 1300.00 | ACCOUNTING |</span><br><span class="line">| JONES  | 2975.00 | RESEARCH   |</span><br><span class="line">| SCOTT  | 3000.00 | RESEARCH   |</span><br><span class="line">| ADAMS  | 1100.00 | RESEARCH   |</span><br><span class="line">| FORD   | 3000.00 | RESEARCH   |</span><br><span class="line">| ALLEN  | 1900.00 | SALES      |</span><br><span class="line">| WARD   | 1750.00 | SALES      |</span><br><span class="line">| MARTIN | 2650.00 | SALES      |</span><br><span class="line">| BLAKE  | 2850.00 | SALES      |</span><br><span class="line">| TURNER | 1500.00 | SALES      |</span><br><span class="line">+--------+---------+------------+</span><br><span class="line">12 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>

]]></content>
  </entry>
  <entry>
    <title>hdfs伪分布式部署</title>
    <url>/2021/11/25/hdfs%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<h1 id="hdfs伪分布式部署"><a href="#hdfs伪分布式部署" class="headerlink" title="hdfs伪分布式部署"></a>hdfs伪分布式部署</h1><p><a href="https://hadoop.apache.org/release.html">Releases Archive</a>中选择要部署的版本，我们以<a href="https://hadoop.apache.org/release/3.2.2.html">Release 3.2.2 available</a>版本为例</p>
<p>参考文档：<a href="https://hadoop.apache.org/docs/r3.2.2/hadoop-project-dist/hadoop-common/SingleCluster.html">Hadoop: Setting up a Single Node Cluster.</a></p>
<h2 id="一、部署"><a href="#一、部署" class="headerlink" title="一、部署"></a>一、部署</h2><h3 id="1-软件要求"><a href="#1-软件要求" class="headerlink" title="1.软件要求"></a>1.软件要求</h3><ul>
<li>Java：Hadoop对Java版本有要求，具体参考<a href="https://cwiki.apache.org/confluence/display/HADOOP/Hadoop+Java+Versions">Hadoop Java Versions</a>，基本上Java8通用</li>
<li>ssh</li>
</ul>
<p>补充：组件名称<code>大写-数字</code>，如：SPARK-2908，表明该组件是有问题的</p>
<span id="more"></span>

<h3 id="2-tar包解压"><a href="#2-tar包解压" class="headerlink" title="2.tar包解压"></a>2.tar包解压</h3><p>点击下载:<a href="https://archive.apache.org/dist/hadoop/common/hadoop-3.2.2/hadoop-3.2.2.tar.gz">hadoop-3.2.2.tar.gz</a></p>
<p>下载后通过rz命令上传至Linux系统</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 ~]$ ll software/</span><br><span class="line">total 805204</span><br><span class="line">-rw-r--r--.  1 hadoop hadoop 395448622 Nov 21 10:03 hadoop-3.2.2.tar.gz</span><br></pre></td></tr></table></figure>

<p>解压hadoop到app目录下，创建软连接</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 ~]$ tar -xzvf software/hadoop-3.2.2.tar.gz -C app/</span><br><span class="line">[hadoop@hadoop001 ~]$ cd app</span><br><span class="line">[hadoop@hadoop001 app]$ </span><br><span class="line">[hadoop@hadoop001 app]$ ln -s /home/hadoop/app/hadoop-3.2.2 hadoop</span><br><span class="line">[hadoop@hadoop001 app]$ ll</span><br><span class="line">total 2</span><br><span class="line">lrwxrwxrwx. 1 hadoop hadoop   29 Nov 25 16:28 hadoop -&gt; /home/hadoop/app/hadoop-3.2.2</span><br><span class="line">drwxr-xr-x. 9 hadoop hadoop 4096 Jan  3  2021 hadoop-3.2.2</span><br></pre></td></tr></table></figure>

<h3 id="3-查看文件目录"><a href="#3-查看文件目录" class="headerlink" title="3.查看文件目录"></a>3.查看文件目录</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 app]$ cd hadoop/</span><br><span class="line">[hadoop@hadoop001 hadoop]$ ll</span><br><span class="line">total 216</span><br><span class="line">drwxr-xr-x. 2 hadoop hadoop   4096 Jan  3  2021 bin				#命令执行脚本</span><br><span class="line">drwxr-xr-x. 3 hadoop hadoop   4096 Jan  3  2021 etc				#配置文件</span><br><span class="line">drwxr-xr-x. 2 hadoop hadoop   4096 Jan  3  2021 include</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop   4096 Nov 21 10:14 input</span><br><span class="line">drwxr-xr-x. 3 hadoop hadoop   4096 Jan  3  2021 lib</span><br><span class="line">drwxr-xr-x. 4 hadoop hadoop   4096 Jan  3  2021 libexec</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 150569 Dec  5  2020 LICENSE.txt</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop   4096 Nov 21 10:48 logs</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop  21943 Dec  5  2020 NOTICE.txt</span><br><span class="line">drwxr-xr-x. 3 hadoop hadoop   4096 Nov 21 11:01 output</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop   1361 Dec  5  2020 README.txt</span><br><span class="line">drwxr-xr-x. 3 hadoop hadoop   4096 Jan  3  2021 sbin			#启动停止脚本</span><br><span class="line">drwxr-xr-x. 4 hadoop hadoop   4096 Jan  3  2021 share</span><br></pre></td></tr></table></figure>

<p>大部分的大数据项目解压后目录：bin</p>
<h3 id="4-手动配置Java环境变量（必须）"><a href="#4-手动配置Java环境变量（必须）" class="headerlink" title="4.手动配置Java环境变量（必须）"></a>4.手动配置Java环境变量（必须）</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ vi etc/hadoop/hadoop-env.sh </span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># The java implementation to use. By default, this environment</span><br><span class="line"># variable is REQUIRED on ALL platforms except OS X!</span><br><span class="line"># export JAVA_HOME=/usr/java/latest</span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_45</span><br></pre></td></tr></table></figure>

<h3 id="5-执行bin-hadoop查看hdfs使用说明"><a href="#5-执行bin-hadoop查看hdfs使用说明" class="headerlink" title="5.执行bin/hadoop查看hdfs使用说明"></a>5.执行bin/hadoop查看hdfs使用说明</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ bin/hadoop</span><br><span class="line">Usage: hadoop [OPTIONS] SUBCOMMAND [SUBCOMMAND OPTIONS]</span><br><span class="line"> or    hadoop [OPTIONS] CLASSNAME [CLASSNAME OPTIONS]</span><br><span class="line">  where CLASSNAME is a user-provided Java class</span><br><span class="line"></span><br><span class="line">  OPTIONS is none or any of:</span><br><span class="line"></span><br><span class="line">buildpaths                       attempt to add class files from build tree</span><br><span class="line">--config dir                     Hadoop config directory</span><br><span class="line">--debug                          turn on shell script debug mode</span><br><span class="line">--help                           usage information</span><br><span class="line">hostnames list[,of,host,names]   hosts to use in slave mode</span><br><span class="line">hosts filename                   list of hosts to use in slave mode</span><br><span class="line">loglevel level                   set the log4j level for this command</span><br><span class="line">workers                          turn on worker mode</span><br><span class="line"></span><br><span class="line">  SUBCOMMAND is one of:</span><br><span class="line">  </span><br><span class="line">    Admin Commands:</span><br><span class="line"></span><br><span class="line">daemonlog     get/set the log level for each daemon</span><br><span class="line"></span><br><span class="line">    Client Commands:</span><br><span class="line"></span><br><span class="line">archive       create a Hadoop archive</span><br><span class="line">checknative   check native Hadoop and compression libraries availability</span><br><span class="line">classpath     prints the class path needed to get the Hadoop jar and the required libraries</span><br><span class="line">conftest      validate configuration XML files</span><br><span class="line">credential    interact with credential providers</span><br><span class="line">distch        distributed metadata changer</span><br><span class="line">distcp        copy file or directories recursively</span><br><span class="line">dtutil        operations related to delegation tokens</span><br><span class="line">envvars       display computed Hadoop environment variables</span><br><span class="line">fs            run a generic filesystem user client</span><br><span class="line">gridmix       submit a mix of synthetic job, modeling a profiled from production load</span><br><span class="line">jar &lt;jar&gt;     run a jar file. NOTE: please use &quot;yarn jar&quot; to launch YARN applications, not</span><br><span class="line">              this command.</span><br><span class="line">jnipath       prints the java.library.path</span><br><span class="line">kdiag         Diagnose Kerberos Problems</span><br><span class="line">kerbname      show auth_to_local principal conversion</span><br><span class="line">key           manage keys via the KeyProvider</span><br><span class="line">rumenfolder   scale a rumen input trace</span><br><span class="line">rumentrace    convert logs into a rumen trace</span><br><span class="line">s3guard       manage metadata on S3</span><br><span class="line">trace         view and modify Hadoop tracing settings</span><br><span class="line">version       print the version</span><br><span class="line"></span><br><span class="line">    Daemon Commands:</span><br><span class="line"></span><br><span class="line">kms           run KMS, the Key Management Server</span><br><span class="line"></span><br><span class="line">SUBCOMMAND may print help when invoked w/o parameters or with -h.</span><br></pre></td></tr></table></figure>

<h3 id="6-修改配置文件：伪分布式部署"><a href="#6-修改配置文件：伪分布式部署" class="headerlink" title="6.修改配置文件：伪分布式部署"></a>6.修改配置文件：伪分布式部署</h3><ul>
<li>前置修改： <strong>/etc/host</strong></li>
</ul>
<p>通过命令<code>ifconfig</code>找到本机ip地址</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ ifconfig</span><br><span class="line">eth0      Link encap:Ethernet  HWaddr 00:0C:29:E2:5A:5E  </span><br><span class="line">          inet addr:XXX.XXX.XXX.XXX//这个ip地址</span><br><span class="line">          inet6 addr: fea2::24c:29fs:fee2:5a7e/64 Scope:Link</span><br><span class="line">          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</span><br><span class="line">          RX packets:2742 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:3033 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:1000 </span><br><span class="line">          RX bytes:267707 (261.4 KiB)  TX bytes:1724144 (1.6 MiB)</span><br></pre></td></tr></table></figure>

<p><code>vi  /etc/host</code>修改域名与ip的对应关系（注意，在后面追加即可，前面的信息不要修改）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ cat /etc/host</span><br><span class="line">cat: /etc/host: No such file or directory</span><br><span class="line">[hadoop@hadoop001 hadoop]$ cat /etc/hosts</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">XXX.XXX.XXX.XXX hadoop001</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>etc/hadoop/core-site.xml</strong></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ vi etc/hadoop/core-site.xml </span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<p>我的域名：hadoop001,所以</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;hdfs://hadoop001:9000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<p>个人补充：可顺便添加以下代码更改tmp目录地址</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/home/hadoop/tmp/hadoop-$&#123;user.name&#125;&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>etc/hadoop/hdfs-site.xml</strong></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ vi etc/hadoop/hdfs-site.xml </span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<p>个人补充：可顺便添加以下代码（我的域名：hadoop001）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">		&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;hadoop001:9868&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;dfs.namenode.secondary.https-address&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;hadoop001:9869&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<p><strong>个人补充：</strong></p>
<ul>
<li><strong>etc/hadoop/workers</strong></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ vi etc/hadoop/workers</span><br><span class="line">hadoop001</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>etc/hadoop/hadoop-env.sh</strong></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ vi etc/hadoop/hadoop-env.sh</span><br><span class="line"># Where pid files are stored.  /tmp by default.</span><br><span class="line"># export HADOOP_PID_DIR=/tmp</span><br><span class="line">export HADOOP_PID_DIR=/home/hadoop/tmp</span><br></pre></td></tr></table></figure>

<h3 id="7-设置SSH私钥取消密码"><a href="#7-设置SSH私钥取消密码" class="headerlink" title="7.设置SSH私钥取消密码"></a>7.设置<em>SSH</em>私钥取消密码</h3><p>通过命令<code>ssh localhost</code>检查是否可以用ssh免密连接到localhost</p>
<ul>
<li>成功：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ ssh localhost</span><br><span class="line">Last login: Sat Oct  9 17:05:54 2021 from localhost</span><br></pre></td></tr></table></figure>

<ul>
<li>失败：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ ssh localhost</span><br><span class="line">hadoop@localhost&#x27;s password: </span><br><span class="line">Permission denied, please try again.</span><br></pre></td></tr></table></figure>

<p>执行以下命令：<code>ssh-keygen</code>，然后回车两次，若有Overwrite (y/n)?，则输入 y回车</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ ssh-keygen</span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file in which to save the key (/home/hadoop/.ssh/id_rsa): </span><br><span class="line">/home/hadoop/.ssh/id_rsa already exists.</span><br><span class="line">Overwrite (y/n)? y</span><br><span class="line">Enter passphrase (empty for no passphrase): </span><br><span class="line">Enter same passphrase again: </span><br><span class="line">Your identification has been saved in /home/hadoop/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved in /home/hadoop/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">9c:1c:53:05:cd:dc:23:1b:51:62:06:b0:92:57:66:da hadoop@hadoop001</span><br><span class="line">The key&#x27;s randomart image is:</span><br><span class="line">+--[ RSA 2048]----+</span><br><span class="line">|        ..BB*+ . |</span><br><span class="line">|       . O o*.o  |</span><br><span class="line">|      o * E  +.  |</span><br><span class="line">|       = + .     |</span><br><span class="line">|       S         |</span><br><span class="line">|                 |</span><br><span class="line">|                 |</span><br><span class="line">|                 |</span><br><span class="line">|                 |</span><br><span class="line">+-----------------+</span><br><span class="line">[hadoop@hadoop001 hadoop]$ ll ~/.ssh/</span><br><span class="line">total 16</span><br><span class="line">-rw-------. 1 hadoop hadoop  796 Nov 21 10:34 authorized_keys</span><br><span class="line">-rw-------. 1 hadoop hadoop 1675 Nov 25 17:04 id_rsa</span><br><span class="line">-rw-r--r--. 1 hadoop hadoop  398 Nov 25 17:04 id_rsa.pub</span><br><span class="line">-rw-r--r--. 1 hadoop hadoop  798 Nov 21 10:29 known_hosts</span><br></pre></td></tr></table></figure>

<p>添加ssh密钥到authorized_keys中,更改权限</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line">[hadoop@hadoop001 hadoop]$ chmod 600 ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure>

<p>测试：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ ssh localhost</span><br><span class="line">Last login: Thu Nov 25 16:57:28 2021 from localhost</span><br></pre></td></tr></table></figure>

<h2 id="二、执行"><a href="#二、执行" class="headerlink" title="二、执行"></a>二、执行</h2><p>我的系统中环境变量配置了HADOOP_HOME：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export HADOOP_HOME=/home/hadoop/app/hadoop</span><br><span class="line">export HADOOP_MAPRED_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_COMMON_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_HDFS_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_YARN_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native</span><br><span class="line">export PATH=$&#123;HADOOP_HOME&#125;/bin:$&#123;HADOOP_HOME&#125;/sbin:$PATH</span><br></pre></td></tr></table></figure>

<h3 id="本地执行"><a href="#本地执行" class="headerlink" title="本地执行"></a>本地执行</h3><p>以下介绍为在本地执行一个MapReduce任务：</p>
<h4 id="1-格式化文件系统"><a href="#1-格式化文件系统" class="headerlink" title="1.格式化文件系统"></a>1.格式化文件系统</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ hdfs namenode -format</span><br></pre></td></tr></table></figure>

<h4 id="2-启动NameNode节点和DataNode节点"><a href="#2-启动NameNode节点和DataNode节点" class="headerlink" title="2.启动NameNode节点和DataNode节点"></a>2.启动NameNode节点和DataNode节点</h4><p>The hadoop daemon log output is written to the <code>$HADOOP_LOG_DIR</code> directory (defaults to <code>$HADOOP_HOME/logs</code>).</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ start-dfs.sh </span><br><span class="line">Starting namenodes on [hadoop001]</span><br><span class="line">Starting datanodes</span><br><span class="line">Starting secondary namenodes [hadoop001]</span><br></pre></td></tr></table></figure>

<p>启动后，可以用jps命令查看：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ jps</span><br><span class="line">6530 Jps</span><br><span class="line">6355 SecondaryNameNode</span><br><span class="line">6197 DataNode</span><br><span class="line">6089 NameNode</span><br></pre></td></tr></table></figure>

<hr>
<p>个人补充：jps后发现DataNode节点丢失，没在运行。原因大概是我格式化太多次namenode导致csid不同步，网上解决办法是data和name文件夹的dfs/data/cruurt/VERSION的id进行同步。最终个人解决方法如下：</p>
<ol>
<li><p>找到自己临时文档/tmp/即core.site.xml文件中的/home/hadoop/data/tmp路径</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ cat etc/hadoop/core-site.xml </span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;/home/hadoop/tmp/hadoop-$&#123;user.name&#125;&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li>
<li><p>删除<code>home/hadoop/tmp</code>目录下文件，重新格式化Namenode</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ rm -rf tmp/*</span><br><span class="line">[hadoop@hadoop001 hadoop]$ hdfs namenode -format</span><br></pre></td></tr></table></figure></li>
<li><p>重启hdfs，问题解决</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ start-dfs.sh </span><br><span class="line">Starting namenodes on [hadoop001]</span><br><span class="line">Starting datanodes</span><br><span class="line">Starting secondary namenodes [hadoop001]</span><br><span class="line">2021-11-25 18:17:14,032 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">[hadoop@hadoop001 hadoop]$ jps</span><br><span class="line">14148 SecondaryNameNode</span><br><span class="line">13991 DataNode</span><br><span class="line">13883 NameNode</span><br><span class="line">14270 Jps</span><br><span class="line">[hadoop@hadoop001 hadoop]$ </span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="3-通过浏览器访问NameNode"><a href="#3-通过浏览器访问NameNode" class="headerlink" title="3.通过浏览器访问NameNode"></a>3.通过浏览器访问NameNode</h4><ul>
<li>NameNode - <code>http://localhost:9870/</code></li>
<li>hadoop 2.x版本是50070端口，现在版本是9870端口</li>
</ul>
<h4 id="4-在hdfs中创建目录执行MapReduce-jobs"><a href="#4-在hdfs中创建目录执行MapReduce-jobs" class="headerlink" title="4.在hdfs中创建目录执行MapReduce jobs"></a>4.在hdfs中创建目录执行MapReduce jobs</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs  -ls /</span><br><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs  -mkdir /user</span><br><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs  -ls /</span><br><span class="line">Found 1 items</span><br><span class="line">drwxr-xr-x   - hadoop supergroup          0 2021-11-25 19:58 /user</span><br><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs  -mkdir /user/hadoop</span><br><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs  -ls /user</span><br><span class="line">Found 1 items</span><br><span class="line">drwxr-xr-x   - hadoop supergroup          0 2021-11-25 19:59 /user/hadoop</span><br></pre></td></tr></table></figure>

<h4 id="5-复制input文件夹下的文件到hdfs系统中"><a href="#5-复制input文件夹下的文件到hdfs系统中" class="headerlink" title="5.复制input文件夹下的文件到hdfs系统中"></a>5.复制input文件夹下的文件到hdfs系统中</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs  -mkdir input</span><br><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs -put etc/hadoop/*.xml input</span><br><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs  -ls /user/hadoop</span><br><span class="line">Found 1 items</span><br><span class="line">drwxr-xr-x   - hadoop supergroup          0 2021-11-25 20:05 /user/hadoop/input</span><br><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs  -ls /user/hadoop/input</span><br><span class="line">Found 9 items</span><br><span class="line">-rw-r--r--   1 hadoop supergroup       9213 2021-11-25 20:05 /user/hadoop/input/capacity-scheduler.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup        975 2021-11-25 20:05 /user/hadoop/input/core-site.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup      11392 2021-11-25 20:05 /user/hadoop/input/hadoop-policy.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup       1068 2021-11-25 20:05 /user/hadoop/input/hdfs-site.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup        620 2021-11-25 20:05 /user/hadoop/input/httpfs-site.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup       3518 2021-11-25 20:05 /user/hadoop/input/kms-acls.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup        682 2021-11-25 20:05 /user/hadoop/input/kms-site.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup        758 2021-11-25 20:05 /user/hadoop/input/mapred-site.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup        690 2021-11-25 20:05 /user/hadoop/input/yarn-site.xml</span><br><span class="line">[hadoop@hadoop001 hadoop]$ </span><br></pre></td></tr></table></figure>

<p>可以看到，在第一句命令中，input的路径并没有写成<code>/user/hadoop/input</code>，因为执行后会在当前用户的路径下执行</p>
<h4 id="6-执行MapReduce任务"><a href="#6-执行MapReduce任务" class="headerlink" title="6.执行MapReduce任务"></a>6.执行MapReduce任务</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input output &#x27;dfs[a-z.]+&#x27;</span><br><span class="line">2021-11-25 20:10:12,608 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">2021-11-25 20:10:13,702 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties</span><br><span class="line">2021-11-25 20:10:13,807 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).</span><br><span class="line">2021-11-25 20:10:13,807 INFO impl.MetricsSystemImpl: JobTracker metrics system started</span><br><span class="line">2021-11-25 20:10:14,497 INFO input.FileInputFormat: Total input files to process : 9</span><br><span class="line">......</span><br><span class="line">	File Input Format Counters </span><br><span class="line">		Bytes Read=232</span><br><span class="line">	File Output Format Counters </span><br><span class="line">		Bytes Written=90</span><br></pre></td></tr></table></figure>

<h4 id="7-查看执行结果"><a href="#7-查看执行结果" class="headerlink" title="7.查看执行结果"></a>7.查看执行结果</h4><ul>
<li><p>直接在hdfs系统上看：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs  -ls /user/hadoop/output</span><br><span class="line">Found 2 items</span><br><span class="line">-rw-r--r--   1 hadoop supergroup          0 2021-11-25 20:10 /user/hadoop/output/_SUCCESS</span><br><span class="line">-rw-r--r--   1 hadoop supergroup         90 2021-11-25 20:10 /user/hadoop/output/part-r-00000</span><br><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs -cat output/*</span><br><span class="line">cat: `output/output&#x27;: No such file or directory</span><br><span class="line">1	dfsadmin</span><br><span class="line">1	dfs.replication</span><br></pre></td></tr></table></figure></li>
<li><p>拿到linux系统上看：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs -get output output</span><br><span class="line">[hadoop@hadoop001 hadoop]$ cat output/*</span><br><span class="line">1	dfsadmin</span><br><span class="line">1	dfs.replication</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="8-停止服务"><a href="#8-停止服务" class="headerlink" title="8.停止服务"></a>8.停止服务</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ stop-dfs.sh </span><br><span class="line">Stopping namenodes on [hadoop001]</span><br><span class="line">Stopping datanodes</span><br><span class="line">Stopping secondary namenodes [hadoop001]</span><br><span class="line">[hadoop@hadoop001 hadoop]$ </span><br></pre></td></tr></table></figure>


<h3 id="YARN上执行"><a href="#YARN上执行" class="headerlink" title="YARN上执行"></a>YARN上执行</h3><p>想要在YARN上执行MapReduce任务，需要设置参数运行ResourceManager守护进程和NodeManager守护进程。下面执行的基础是已经执行上述<a href="#%E6%9C%AC%E5%9C%B0%E6%89%A7%E8%A1%8C">本地执行1~4</a>的步骤。</p>
<h4 id="1-修改配置文件"><a href="#1-修改配置文件" class="headerlink" title="1.修改配置文件"></a>1.修改配置文件</h4><ul>
<li><p><strong>etc/hadoop/mapred-site.xml</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.application.classpath&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>etc/hadoop/yarn-site.xml</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ,HADOOP_MAPRED_HOME&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<p>个人：HADOOP_CONF_DIR还没配置</p>
</li>
</ul>
<h4 id="2-启动ResourceManager守护进程和NodeManager守护进程"><a href="#2-启动ResourceManager守护进程和NodeManager守护进程" class="headerlink" title="2.启动ResourceManager守护进程和NodeManager守护进程"></a>2.启动ResourceManager守护进程和NodeManager守护进程</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ start-yarn.sh </span><br><span class="line">Starting resourcemanager</span><br><span class="line">Starting nodemanagers</span><br><span class="line">[hadoop@hadoop001 hadoop]$ jps</span><br><span class="line">20592 Jps</span><br><span class="line">18579 NameNode</span><br><span class="line">20392 ResourceManager</span><br><span class="line">18843 SecondaryNameNode</span><br><span class="line">18686 DataNode</span><br><span class="line">20495 NodeManager</span><br></pre></td></tr></table></figure>

<h4 id="3-通过浏览器访问访问ResourceManager"><a href="#3-通过浏览器访问访问ResourceManager" class="headerlink" title="3.通过浏览器访问访问ResourceManager"></a>3.通过浏览器访问访问ResourceManager</h4><ul>
<li>ResourceManager - <code>http://localhost:8088/</code></li>
</ul>
<h4 id="4-执行MapReduce任务"><a href="#4-执行MapReduce任务" class="headerlink" title="4.执行MapReduce任务"></a>4.执行MapReduce任务</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input output &#x27;dfs[a-z.]+&#x27;</span><br><span class="line">2021-11-26 08:15:32,639 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">2021-11-26 08:15:34,024 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032</span><br><span class="line">2021-11-26 08:15:35,285 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/hadoop/.staging/job_1637885511879_0001</span><br><span class="line">2021-11-26 08:15:36,280 INFO input.FileInputFormat: Total input files to process : 9</span><br><span class="line">2021-11-26 08:15:36,379 INFO mapreduce.JobSubmitter: number of splits:9</span><br><span class="line">2021-11-26 08:15:36,974 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1637885511879_0001</span><br><span class="line">2021-11-26 08:15:36,976 INFO mapreduce.JobSubmitter: Executing with tokens: []</span><br><span class="line">2021-11-26 08:15:37,319 INFO conf.Configuration: resource-types.xml not found</span><br><span class="line">2021-11-26 08:15:37,320 INFO resource.ResourceUtils: Unable to find &#x27;resource-types.xml&#x27;.</span><br><span class="line">2021-11-26 08:15:37,878 INFO impl.YarnClientImpl: Submitted application application_1637885511879_0001</span><br><span class="line">2021-11-26 08:15:37,945 INFO mapreduce.Job: The url to track the job: http://hadoop001:8088/proxy/application_1637885511879_0001/</span><br><span class="line">2021-11-26 08:15:37,945 INFO mapreduce.Job: Running job: job_1637885511879_0001</span><br><span class="line">2021-11-26 08:15:55,539 INFO mapreduce.Job: Job job_1637885511879_0001 running in uber mode : false</span><br><span class="line">2021-11-26 08:15:55,550 INFO mapreduce.Job:  map 0% reduce 0%</span><br><span class="line">2021-11-26 08:16:43,204 INFO mapreduce.Job:  map 44% reduce 0%</span><br><span class="line">2021-11-26 08:16:44,369 INFO mapreduce.Job:  map 67% reduce 0%</span><br><span class="line">2021-11-26 08:17:05,488 INFO mapreduce.Job:  map 100% reduce 0%</span><br><span class="line">2021-11-26 08:17:06,495 INFO mapreduce.Job:  map 100% reduce 100%</span><br><span class="line">2021-11-26 08:17:07,508 INFO mapreduce.Job: Job job_1637885511879_0001 completed successfully</span><br><span class="line">2021-11-26 08:17:07,638 INFO mapreduce.Job: Counters: 55</span><br><span class="line">	File System Counters</span><br><span class="line">		FILE: Number of bytes read=128</span><br><span class="line">		FILE: Number of bytes written=2350649</span><br><span class="line">		FILE: Number of read operations=0</span><br><span class="line">		FILE: Number of large read operations=0</span><br><span class="line">		FILE: Number of write operations=0</span><br><span class="line">		HDFS: Number of bytes read=29993</span><br><span class="line">		HDFS: Number of bytes written=232</span><br><span class="line">		HDFS: Number of read operations=32</span><br><span class="line">		HDFS: Number of large read operations=0</span><br><span class="line">		HDFS: Number of write operations=2</span><br><span class="line">		HDFS: Number of bytes read erasure-coded=0</span><br><span class="line">	Job Counters </span><br><span class="line">		Killed map tasks=1</span><br><span class="line">		Launched map tasks=10</span><br><span class="line">		Launched reduce tasks=1</span><br><span class="line">		Data-local map tasks=10</span><br><span class="line">		Total time spent by all maps in occupied slots (ms)=333545</span><br><span class="line">		Total time spent by all reduces in occupied slots (ms)=18937</span><br><span class="line">		Total time spent by all map tasks (ms)=333545</span><br><span class="line">		Total time spent by all reduce tasks (ms)=18937</span><br><span class="line">		Total vcore-milliseconds taken by all map tasks=333545</span><br><span class="line">		Total vcore-milliseconds taken by all reduce tasks=18937</span><br><span class="line">		Total megabyte-milliseconds taken by all map tasks=341550080</span><br><span class="line">		Total megabyte-milliseconds taken by all reduce tasks=19391488</span><br><span class="line">	Map-Reduce Framework</span><br><span class="line">		Map input records=781</span><br><span class="line">		Map output records=4</span><br><span class="line">		Map output bytes=114</span><br><span class="line">		Map output materialized bytes=176</span><br><span class="line">		Input split bytes=1077</span><br><span class="line">		Combine input records=4</span><br><span class="line">		Combine output records=4</span><br><span class="line">		Reduce input groups=4</span><br><span class="line">		Reduce shuffle bytes=176</span><br><span class="line">		Reduce input records=4</span><br><span class="line">		Reduce output records=4</span><br><span class="line">		Spilled Records=8</span><br><span class="line">		Shuffled Maps =9</span><br><span class="line">		Failed Shuffles=0</span><br><span class="line">		Merged Map outputs=9</span><br><span class="line">		GC time elapsed (ms)=6070</span><br><span class="line">		CPU time spent (ms)=7920</span><br><span class="line">		Physical memory (bytes) snapshot=1882726400</span><br><span class="line">		Virtual memory (bytes) snapshot=27148435456</span><br><span class="line">		Total committed heap usage (bytes)=1269469184</span><br><span class="line">		Peak Map Physical memory (bytes)=211144704</span><br><span class="line">		Peak Map Virtual memory (bytes)=2715578368</span><br><span class="line">		Peak Reduce Physical memory (bytes)=106315776</span><br><span class="line">		Peak Reduce Virtual memory (bytes)=2720391168</span><br><span class="line">	Shuffle Errors</span><br><span class="line">		BAD_ID=0</span><br><span class="line">		CONNECTION=0</span><br><span class="line">		IO_ERROR=0</span><br><span class="line">		WRONG_LENGTH=0</span><br><span class="line">		WRONG_MAP=0</span><br><span class="line">		WRONG_REDUCE=0</span><br><span class="line">	File Input Format Counters </span><br><span class="line">		Bytes Read=28916</span><br><span class="line">	File Output Format Counters </span><br><span class="line">		Bytes Written=232</span><br><span class="line">2021-11-26 08:17:07,682 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032</span><br><span class="line">org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://hadoop001:9000/user/hadoop/output already exists</span><br><span class="line">	at org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:164)</span><br><span class="line">	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:277)</span><br><span class="line">	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)</span><br><span class="line">	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1565)</span><br><span class="line">	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1562)</span><br><span class="line">	at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">	at javax.security.auth.Subject.doAs(Subject.java:422)</span><br><span class="line">	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)</span><br><span class="line">	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1562)</span><br><span class="line">	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1583)</span><br><span class="line">	at org.apache.hadoop.examples.Grep.run(Grep.java:94)</span><br><span class="line">	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)</span><br><span class="line">	at org.apache.hadoop.examples.Grep.main(Grep.java:103)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span><br><span class="line">	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">	at java.lang.reflect.Method.invoke(Method.java:497)</span><br><span class="line">	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)</span><br><span class="line">	at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)</span><br><span class="line">	at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span><br><span class="line">	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">	at java.lang.reflect.Method.invoke(Method.java:497)</span><br><span class="line">	at org.apache.hadoop.util.RunJar.run(RunJar.java:323)</span><br><span class="line">	at org.apache.hadoop.util.RunJar.main(RunJar.java:236)</span><br></pre></td></tr></table></figure>

<p><img src="/2021/11/25/hdfs%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2/image-20211126093406585.png" alt="通过浏览器查看任务"></p>
<h4 id="5-停止服务"><a href="#5-停止服务" class="headerlink" title="5.停止服务"></a>5.停止服务</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ stop-yarn.sh </span><br><span class="line">Stopping nodemanagers</span><br><span class="line">localhost: WARNING: nodemanager did not stop gracefully after 5 seconds: Trying to kill with kill -9</span><br><span class="line">Stopping resourcemanager</span><br><span class="line">[hadoop@hadoop001 hadoop]$ jps</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
</search>
