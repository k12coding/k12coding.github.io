<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"k12coding.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.8.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>
<meta name="description" content="一、Hadoop支持LZO压缩1.lzoplzo格式文件压缩解压需要用到服务器的lzop工具，hadoop 的native库（hadoop checknative是没有的lzo,zip相关信息）并不支持 123#安装以前先执行以下命令[hadoop@hadoop001 ~]$ which lzop&#x2F;usr&#x2F;bin&#x2F;lzop   【注意】这代表你已经有lzop，如果找不到，就执行以下命令 12345">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop支持LZO压缩">
<meta property="og:url" content="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/index.html">
<meta property="og:site_name" content="k12的博客">
<meta property="og:description" content="一、Hadoop支持LZO压缩1.lzoplzo格式文件压缩解压需要用到服务器的lzop工具，hadoop 的native库（hadoop checknative是没有的lzo,zip相关信息）并不支持 123#安装以前先执行以下命令[hadoop@hadoop001 ~]$ which lzop&#x2F;usr&#x2F;bin&#x2F;lzop   【注意】这代表你已经有lzop，如果找不到，就执行以下命令 12345">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/lzo-1.png">
<meta property="og:image" content="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/image-20220113183629075.png">
<meta property="og:image" content="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/lzo-2.png">
<meta property="og:image" content="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/image-20220114164409879.png">
<meta property="og:image" content="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/lzo-3.png">
<meta property="og:image" content="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/image-20220114171956115.png">
<meta property="og:image" content="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/image-20220114172032219.png">
<meta property="og:image" content="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/lzo-4.png">
<meta property="article:published_time" content="2022-01-18T15:17:28.000Z">
<meta property="article:modified_time" content="2022-01-18T17:39:13.265Z">
<meta property="article:author" content="k12">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/lzo-1.png">


<link rel="canonical" href="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/","path":"2022/01/18/Hadoop支持LZO压缩/","title":"Hadoop支持LZO压缩"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Hadoop支持LZO压缩 | k12的博客</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">k12的博客</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">k12的笔记</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E3%80%81Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9"><span class="nav-text">一、Hadoop支持LZO压缩</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-lzop"><span class="nav-text">1.lzop</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E5%AE%89%E8%A3%85hadoop-lzo"><span class="nav-text">2.安装hadoop-lzo</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8B%E8%BD%BD"><span class="nav-text">下载</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%A7%A3%E5%8E%8B"><span class="nav-text">解压</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9pom-xml"><span class="nav-text">修改pom.xml</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A3%B0%E6%98%8E%E4%B8%A4%E4%B8%AA%E4%B8%B4%E6%97%B6%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="nav-text">声明两个临时环境变量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BC%96%E8%AF%91%EF%BC%88%E4%B8%8D%E9%9C%80%E8%A6%81%E9%98%BF%E9%87%8C%E4%BA%91%E4%BB%93%E5%BA%93%EF%BC%89"><span class="nav-text">编译（不需要阿里云仓库）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8A%E4%BC%A0jar%E5%8C%85"><span class="nav-text">上传jar包</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-text">修改配置文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95"><span class="nav-text">测试</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-LZO%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95"><span class="nav-text">3.LZO创建索引</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9B%E5%BB%BALZO%E6%96%87%E4%BB%B6%E7%9A%84%E7%B4%A2%E5%BC%95"><span class="nav-text">创建LZO文件的索引</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%89%A7%E8%A1%8Cwc-%E6%B2%A1%E6%9C%89%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95"><span class="nav-text">执行wc(没有创建索引)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9%E4%B8%8A%E4%BC%A0%E7%9A%84LZO%E6%96%87%E4%BB%B6%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95"><span class="nav-text">对上传的LZO文件创建索引</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%89%A7%E8%A1%8Cwc-%E5%B7%B2%E7%BB%8F%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95"><span class="nav-text">执行wc(已经创建索引)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E3%80%81Hive%E6%94%AF%E6%8C%81%E5%A4%84%E7%90%86LZO%E5%8E%8B%E7%BC%A9%E6%A0%BC%E5%BC%8F%E7%9A%84%E6%95%B0%E6%8D%AE%E7%9A%84%E7%BB%9F%E8%AE%A1%E6%9F%A5%E8%AF%A2"><span class="nav-text">二、Hive支持处理LZO压缩格式的数据的统计查询</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%80%E5%90%AF%E5%8E%8B%E7%BC%A9%E7%9A%84%E6%96%B9%E5%BC%8F"><span class="nav-text">开启压缩的方式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E4%B8%8E%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="nav-text">数据与环境准备</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%AA%E5%BC%80%E5%90%AF%EF%BC%88%E6%9C%AA%E6%B7%BB%E5%8A%A0%E7%B4%A2%E5%BC%95%EF%BC%89"><span class="nav-text">未开启（未添加索引）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BB%BA%E8%A1%A8"><span class="nav-text">建表</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%8E%E6%9C%AC%E5%9C%B0load-LZO%E5%8E%8B%E7%BC%A9%E6%95%B0%E6%8D%AEbigemp-data-lzo%E5%88%B0%E8%A1%A8big-emp"><span class="nav-text">从本地load LZO压缩数据bigemp.data.lzo到表big_emp</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9F%A5%E7%9C%8B%E5%A4%A7%E5%B0%8F"><span class="nav-text">查看大小</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9F%A5%E8%AF%A2%E7%BB%9F%E8%AE%A1%E6%B5%8B%E8%AF%95"><span class="nav-text">查询统计测试</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B7%B2%E5%BC%80%E5%90%AF%EF%BC%88%E5%B7%B2%E6%B7%BB%E5%8A%A0%E7%B4%A2%E5%BC%95%EF%BC%89"><span class="nav-text">已开启（已添加索引）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BC%80%E5%90%AF%E5%8E%8B%E7%BC%A9"><span class="nav-text">开启压缩</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BB%BA%E8%A1%A8%EF%BC%8C%E5%B9%B6%E6%8F%92%E5%85%A5big-emp%E7%9A%84%E6%95%B0%E6%8D%AE"><span class="nav-text">建表，并插入big_emp的数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9E%84%E5%BB%BALZO%E6%96%87%E4%BB%B6%E7%B4%A2%E5%BC%95"><span class="nav-text">构建LZO文件索引</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9F%A5%E8%AF%A2%E7%BB%9F%E8%AE%A1%E6%B5%8B%E8%AF%95-1"><span class="nav-text">查询统计测试</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A1%A5%E5%85%85"><span class="nav-text">补充</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive%E6%94%AF%E6%8C%81%E5%A4%84%E7%90%86LZO%E5%8E%8B%E7%BC%A9%E6%A0%BC%E5%BC%8F%E5%88%86%E7%89%87%E6%AD%A5%E9%AA%A4"><span class="nav-text">Hive支持处理LZO压缩格式分片步骤</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">k12</p>
  <div class="site-description" itemprop="description">2</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">59</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="k12">
      <meta itemprop="description" content="2">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="k12的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hadoop支持LZO压缩
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-01-18 23:17:28" itemprop="dateCreated datePublished" datetime="2022-01-18T23:17:28+08:00">2022-01-18</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2022-01-19 01:39:13" itemprop="dateModified" datetime="2022-01-19T01:39:13+08:00">2022-01-19</time>
      </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h2 id="一、Hadoop支持LZO压缩"><a href="#一、Hadoop支持LZO压缩" class="headerlink" title="一、Hadoop支持LZO压缩"></a>一、Hadoop支持LZO压缩</h2><h3 id="1-lzop"><a href="#1-lzop" class="headerlink" title="1.lzop"></a>1.lzop</h3><p>lzo格式文件压缩解压需要用到服务器的lzop工具，hadoop 的<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=native&spm=1001.2101.3001.7020">native</a>库（hadoop checknative是没有的lzo,zip相关信息）并不支持</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#安装以前先执行以下命令</span><br><span class="line">[hadoop@hadoop001 ~]$ which lzop</span><br><span class="line">/usr/bin/lzop</span><br></pre></td></tr></table></figure>

<p> 【<em><strong>注意</strong></em>】这代表你已经有lzop，如果找不到，就执行以下命令</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#若没有执行如下安装命令【这些命令一定要在root用户下安装，否则没有权限】</span><br><span class="line">[root@hadoop001 ~]# yum install -y svn ncurses-devel</span><br><span class="line">[root@hadoop001 ~]# yum install -y gcc gcc-c++ make cmake</span><br><span class="line">[root@hadoop001 ~]# yum install -y openssl openssl-devel svn ncurses-devel zlib-devel libtool</span><br><span class="line">[root@hadoop001 ~]# yum install -y lzo lzo-devel lzop autoconf automake cmake </span><br><span class="line">[root@hadoop001 ~]# yum -y install lzo-devel zlib-devel gcc autoconf automake libtool</span><br></pre></td></tr></table></figure>

<h3 id="2-安装hadoop-lzo"><a href="#2-安装hadoop-lzo" class="headerlink" title="2.安装hadoop-lzo"></a>2.安装hadoop-lzo</h3><ol>
<li><h4 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/twitter/hadoop-lzo/archive/master.zip</span><br></pre></td></tr></table></figure></li>
<li><h4 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 source]$ ll</span><br><span class="line">total 1028</span><br><span class="line">drwxrwxr-x. 18 hadoop hadoop    4096 Oct 13 20:53 hadoop-2.6.0-cdh5.7.0</span><br><span class="line">drwxr-xr-x. 18 hadoop hadoop    4096 Jan  3  2021 hadoop-3.2.2-src</span><br><span class="line">-rw-rw-r--.  1 hadoop hadoop 1040294 Jan 11 21:57 master</span><br><span class="line">[hadoop@hadoop001 source]$ unzip master</span><br><span class="line">[hadoop@hadoop001 source]$ ll</span><br><span class="line">total 1028</span><br><span class="line">drwxrwxr-x. 18 hadoop hadoop    4096 Oct 13 20:53 hadoop-2.6.0-cdh5.7.0</span><br><span class="line">drwxr-xr-x. 18 hadoop hadoop    4096 Jan  3  2021 hadoop-3.2.2-src</span><br><span class="line">drwxrwxr-x.  5 hadoop hadoop    4096 Jan 11 22:03 hadoop-lzo-master</span><br><span class="line">-rw-rw-r--.  1 hadoop hadoop 1040294 Jan 11 21:57 master</span><br></pre></td></tr></table></figure></li>
<li><h4 id="修改pom-xml"><a href="#修改pom-xml" class="headerlink" title="修改pom.xml"></a>修改pom.xml</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 source]cd hadoop-lzo-master</span><br><span class="line">[hadoop@hadoop001 hadoop-lzo-master]$ vi pom.xml </span><br><span class="line">&lt;hadoop.current.version&gt;3.2.2&lt;/hadoop.current.version&gt;</span><br></pre></td></tr></table></figure></li>
<li><h4 id="声明两个临时环境变量"><a href="#声明两个临时环境变量" class="headerlink" title="声明两个临时环境变量"></a>声明两个临时环境变量</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop-lzo-master]$ </span><br><span class="line">export C_INCLUDE_PATH=/home/hadoop/app/hadoop/lzo/include     </span><br><span class="line">[hadoop@hadoop001 hadoop-lzo-master]$ </span><br><span class="line">export LIBRARY_PATH=/home/hadoop/app/hadoop/lzo/lib </span><br></pre></td></tr></table></figure></li>
<li><h4 id="编译（不需要阿里云仓库）"><a href="#编译（不需要阿里云仓库）" class="headerlink" title="编译（不需要阿里云仓库）"></a>编译（不需要阿里云仓库）</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop-lzo-master]$ mvn clean package -Dmaven.test.skip=true</span><br></pre></td></tr></table></figure>

<p>查看编译后的jar，hadoop-lzo-0.4.21-SNAPSHOT.jar则为我们需要的jar</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop-lzo-master]$ cd target/</span><br><span class="line">[hadoop@hadoop001 target]$ ll</span><br><span class="line">total 444</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop   4096 Jan 11 22:03 antrun</span><br><span class="line">drwxrwxr-x. 4 hadoop hadoop   4096 Jan 11 22:03 apidocs</span><br><span class="line">drwxrwxr-x. 5 hadoop hadoop   4096 Jan 11 22:03 classes</span><br><span class="line">drwxrwxr-x. 3 hadoop hadoop   4096 Jan 11 22:03 generated-sources</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 180550 Jan 11 22:03 hadoop-lzo-0.4.21-SNAPSHOT.jar</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 181006 Jan 11 22:03 hadoop-lzo-0.4.21-SNAPSHOT-javadoc.jar</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop  52043 Jan 11 22:03 hadoop-lzo-0.4.21-SNAPSHOT-sources.jar</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop   4096 Jan 11 22:03 javadoc-bundle-options</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop   4096 Jan 11 22:03 maven-archiver</span><br><span class="line">drwxrwxr-x. 3 hadoop hadoop   4096 Jan 11 22:03 native</span><br><span class="line">drwxrwxr-x. 3 hadoop hadoop   4096 Jan 11 22:03 test-classes</span><br></pre></td></tr></table></figure></li>
<li><h4 id="上传jar包"><a href="#上传jar包" class="headerlink" title="上传jar包"></a>上传jar包</h4><p>将hadoop-lzo-0.4.21-SNAPSHOT.jar包复制到我们的hadoop的$HADOOP_HOME/share/hadoop/common/目录下才能被hadoop使用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 target]$ cp hadoop-lzo-0.4.21-SNAPSHOT.jar ~/app/hadoop/share/hadoop/common/ </span><br></pre></td></tr></table></figure>

<p>如果是集群，需要使用<code>xsync hadoop-lzo-0.4.21.jar</code>命令同步到集群中的其他机器</p>
</li>
<li><h4 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h4><p>core-site.xml</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;io.compression.codecs&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;</span><br><span class="line">		org.apache.hadoop.io.compress.GzipCodec,</span><br><span class="line">		org.apache.hadoop.io.compress.DefaultCodec,</span><br><span class="line">		org.apache.hadoop.io.compress.BZip2Codec,</span><br><span class="line">		org.apache.hadoop.io.compress.SnappyCodec,</span><br><span class="line">		com.hadoop.compression.lzo.LzoCodec,</span><br><span class="line">		com.hadoop.compression.lzo.LzopCodec</span><br><span class="line">	&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;io.compression.codec.lzo.class&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;com.hadoop.compression.lzo.LzoCodec&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<p>mapred-site.xml（如果修改了，则默认输出格式为lzo）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;mapreduce.map.output.compress&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;mapreduce.map.output.compress.codec&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;com.hadoop.compression.lzo.LzoCodec&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.output.fileoutputformat.compress&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;mapreduce.output.fileoutputformat.compress.codec&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;com.hadoop.compression.lzo.LzopCodec&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li>
<li><h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><ul>
<li><p><strong>配置了mapred-site.xml</strong>:</p>
<p>hadoop jar ${HADOOP_HOME}/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar wordcount /input /output</p>
</li>
<li><p>没有配置mapred-site.xml(指定输出文件格式为lzo)：</p>
<p>hadoop jar ${HADOOP_HOME}/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar wordcount <strong>-Dmapreduce.output.fileoutputformat.compress=true</strong> <strong>-Dmapreduce.output.fileoutputformat.compress.codec=com.hadoop.compression.lzo.LzopCodec</strong> /input /output</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 mapreduce]$ hadoop jar /home/hadoop/app/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar wordcount -Dmapreduce.output.fileoutputformat.compress=true -Dmapreduce.output.fileoutputformat.compress.codec=com.hadoop.compression.lzo.LzopCodec /wc/input/wc.data /output</span><br><span class="line">[hadoop@hadoop001 mapreduce]$ hadoop fs -ls /output</span><br><span class="line">-rw-r--r--   1 hadoop supergroup          0 2022-01-11 22:18 /output/_SUCCESS</span><br><span class="line">-rw-r--r--   1 hadoop supergroup         95 2022-01-11 22:18 /output/part-r-00000.lzo</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="3-LZO创建索引"><a href="#3-LZO创建索引" class="headerlink" title="3.LZO创建索引"></a>3.LZO创建索引</h3><ol>
<li><h3 id="创建LZO文件的索引"><a href="#创建LZO文件的索引" class="headerlink" title="创建LZO文件的索引"></a>创建LZO文件的索引</h3><p>创建LZO文件的索引，LZO压缩文件的可切片特性依赖于其索引，故我们需要手动为LZO压缩文件创建索引。若无索引，则LZO文件的切片只有一个。</p>
<p>命令：<code>hadoop jar $HADOOP_HOME/share/hadoop/common/hadoop-lzo-0.4.21-SNAPSHOT.jar com.hadoop.compression.lzo.DistributedLzoIndexer XXX.lzo</code></p>
</li>
<li><h3 id="执行wc-没有创建索引"><a href="#执行wc-没有创建索引" class="headerlink" title="执行wc(没有创建索引)"></a>执行wc(没有创建索引)</h3><p>创建需要分片处理的bigwcneedspilt.data.lzo（203M）文件，并上传到hdfs上</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 data]$ lzop bigwcneedspilt.data</span><br><span class="line">[hadoop@hadoop001 data]$ du -sh bigwc*</span><br><span class="line">157M	bigwc.data</span><br><span class="line">51M	bigwc.data.lzo</span><br><span class="line">625M	bigwcneedspilt.data</span><br><span class="line">203M	bigwcneedspilt.data.lzo</span><br><span class="line">18M	bigwc.txt</span><br><span class="line">[hadoop@hadoop001 data]$ hadoop fs -put bigwcneedspilt.data.lzo /user/hadoop/data/</span><br></pre></td></tr></table></figure>

<p>执行wc(没有创建索引)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 ~]$ hadoop jar /home/hadoop/app/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar wordcount -Dmapreduce.job.inputformat.class=com.hadoop.mapreduce.LzoTextInputFormat /user/hadoop/data/bigwcneedspilt.data.lzo /output1</span><br></pre></td></tr></table></figure>

<p><img src="/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/lzo-1.png" alt="image-20220113175318333"></p>
<p>可以看到此时切片并没有生效，依然只有一个</p>
</li>
<li><h3 id="对上传的LZO文件创建索引"><a href="#对上传的LZO文件创建索引" class="headerlink" title="对上传的LZO文件创建索引"></a>对上传的LZO文件创建索引</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 ~]$ hadoop jar /home/hadoop/app/hadoop/share/hadoop/common/hadoop-lzo-0.4.21-SNAPSHOT.jar  com.hadoop.compression.lzo.DistributedLzoIndexer /user/hadoop/data/bigwcneedspilt.data.lzo</span><br></pre></td></tr></table></figure>

<p><img src="/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/image-20220113183629075.png" alt="image-20220113183629075"></p>
</li>
<li><h3 id="执行wc-已经创建索引"><a href="#执行wc-已经创建索引" class="headerlink" title="执行wc(已经创建索引)"></a>执行wc(已经创建索引)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 ~]$ hadoop jar /home/hadoop/app/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar wordcount -Dmapreduce.job.inputformat.class=com.hadoop.mapreduce.LzoTextInputFormat /user/hadoop/data/bigwcneedspilt.data.lzo /output2</span><br></pre></td></tr></table></figure>

<p><img src="/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/lzo-2.png" alt="image-20220113193027590"></p>
<p>此时已经成功切片</p>
</li>
</ol>
<h2 id="二、Hive支持处理LZO压缩格式的数据的统计查询"><a href="#二、Hive支持处理LZO压缩格式的数据的统计查询" class="headerlink" title="二、Hive支持处理LZO压缩格式的数据的统计查询"></a>二、Hive支持处理LZO压缩格式的数据的统计查询</h2><h3 id="开启压缩的方式"><a href="#开启压缩的方式" class="headerlink" title="开启压缩的方式"></a>开启压缩的方式</h3><ul>
<li>在**<code>$HIVE_HOME/conf/hive-site.xml</code>**中设置</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 设置hive语句执行输出文件是否开启压缩,具体的压缩算法和压缩格式取决于hadoop中</span><br><span class="line">设置的相关参数 --&gt;</span><br><span class="line">&lt;!-- 默认值:false --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.exec.compress.output&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">        This controls whether the final outputs of a query (to a local/HDFS file or a Hive table) </span><br><span class="line">        is compressed. </span><br><span class="line">        The compression codec and other options are determined from Hadoop config variables </span><br><span class="line">        mapred.output.compress*</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- 控制多个MR Job的中间结果文件是否启用压缩,具体的压缩算法和压缩格式取决于hadoop中</span><br><span class="line">设置的相关参数 --&gt;</span><br><span class="line">&lt;!-- 默认值:false --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.exec.compress.intermediate&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">        This controls whether intermediate files produced by Hive between multiple map-reduce jobs are compressed. </span><br><span class="line">        The compression codec and other options are determined from Hadoop config variables mapred.output.compress*</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>在hive中开启</p>
<p>查看默认状态：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (hive)&gt; SET hive.exec.compress.output;</span><br><span class="line">hive.exec.compress.output=false</span><br><span class="line">hive (hive)&gt; set mapreduce.output.fileoutputformat.compress.codec;</span><br><span class="line">mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.DefaultCodec</span><br></pre></td></tr></table></figure>

<p>开启支持压缩，格式为lzop（lzo在文件构建索引后才会支持数据分片）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (hive)&gt; SET hive.exec.compress.output=true;</span><br><span class="line">hive (hive)&gt; SET mapreduce.output.fileoutputformat.compress.codec=com.hadoop.compression.lzo.LzopCodec;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="数据与环境准备"><a href="#数据与环境准备" class="headerlink" title="数据与环境准备"></a>数据与环境准备</h3><p>数据准备：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 data]$ lzop bigemp.data </span><br><span class="line">[hadoop@hadoop001 data]$ du -sh bigemp*</span><br><span class="line">823M	bigemp.data</span><br><span class="line">206M	bigemp.data.lzo</span><br></pre></td></tr></table></figure>

<p>为了方便测试分片，我重启了hadoop，修改了hdfs-site.xml设置了blocksize=10M。然后mapr-site.xml没有配置上面的4个值。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;dfs.blocksize&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;10485760&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<h3 id="未开启（未添加索引）"><a href="#未开启（未添加索引）" class="headerlink" title="未开启（未添加索引）"></a>未开启（未添加索引）</h3><h4 id="建表"><a href="#建表" class="headerlink" title="建表"></a>建表</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE big_emp (id int,name string,dept string)</span><br><span class="line">ROW FORMAT DELIMITED FIELDS TERMINATED BY &#x27;\t&#x27;</span><br><span class="line">STORED AS INPUTFORMAT &quot;com.hadoop.mapred.DeprecatedLzoTextInputFormat&quot;</span><br><span class="line">OUTPUTFORMAT &quot;org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat&quot;</span><br></pre></td></tr></table></figure>

<h4 id="从本地load-LZO压缩数据bigemp-data-lzo到表big-emp"><a href="#从本地load-LZO压缩数据bigemp-data-lzo到表big-emp" class="headerlink" title="从本地load LZO压缩数据bigemp.data.lzo到表big_emp"></a>从本地load LZO压缩数据<code>bigemp.data.lzo</code>到表<code>big_emp</code></h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA LOCAL INPATH &#x27;/home/hadoop/data/bigemp.data.lzo&#x27; OVERWRITE INTO TABLE big_emp</span><br></pre></td></tr></table></figure>

<h4 id="查看大小"><a href="#查看大小" class="headerlink" title="查看大小"></a>查看大小</h4><p><img src="/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/image-20220114164409879.png" alt="image-20220114164409879"></p>
<h4 id="查询统计测试"><a href="#查询统计测试" class="headerlink" title="查询统计测试"></a>查询统计测试</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select count(1) from big_emp;</span><br></pre></td></tr></table></figure>

<p><img src="/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/lzo-3.png" alt="image-20220114045505294"></p>
<p>因为我们的块大小是默认的128M，而bigemp.data.lzo这个lzo压缩文件的大小远远大于128M*1.1，但是我们可以看见Map只有一个，可见lzo是不支持分片的。</p>
<h3 id="已开启（已添加索引）"><a href="#已开启（已添加索引）" class="headerlink" title="已开启（已添加索引）"></a><strong>已开启（已添加索引）</strong></h3><h4 id="开启压缩"><a href="#开启压缩" class="headerlink" title="开启压缩"></a>开启压缩</h4><p>生成的压缩文件格式必须为设置为<strong>LzopCodec</strong>，lzoCode的压缩文件格式后缀为<code>.lzo_deflate</code>是无法创建索引的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive (hive)&gt; SET hive.exec.compress.output=true;</span><br><span class="line">hive (hive)&gt; SET mapreduce.output.fileoutputformat.compress.codec=com.hadoop.compression.lzo.LzopCodec;</span><br><span class="line">hive (hive)&gt; SET hive.exec.compress.output;</span><br><span class="line">hive.exec.compress.output=true</span><br><span class="line">hive (hive)&gt; SET mapreduce.output.fileoutputformat.compress.codec;</span><br><span class="line">mapreduce.output.fileoutputformat.compress.codec=com.hadoop.compression.lzo.LzopCodec</span><br></pre></td></tr></table></figure>

<h4 id="建表，并插入big-emp的数据"><a href="#建表，并插入big-emp的数据" class="headerlink" title="建表，并插入big_emp的数据"></a>建表，并插入big_emp的数据</h4><p>（若不是直接load的lzo文件，需要开启压缩，且压缩格式为LzopCodec，load数据并不能改变文件格式和压缩格式。）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE big_emp_split ROW FORMAT DELIMITED FIELDS TERMINATED BY &#x27;\t&#x27;</span><br><span class="line">STORED AS INPUTFORMAT &quot;com.hadoop.mapred.DeprecatedLzoTextInputFormat&quot;</span><br><span class="line">OUTPUTFORMAT &quot;org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat&quot;</span><br><span class="line">as select * from big_emp;</span><br></pre></td></tr></table></figure>

<p><img src="/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/image-20220114171956115.png" alt="image-20220114171956115"></p>
<h4 id="构建LZO文件索引"><a href="#构建LZO文件索引" class="headerlink" title="构建LZO文件索引"></a>构建LZO文件索引</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /home/hadoop/app/hadoop/share/hadoop/common/hadoop-lzo-0.4.21-SNAPSHOT.jar com.hadoop.compression.lzo.LzoIndexer /user/hive/warehouse/hive.db/big_emp_split</span><br></pre></td></tr></table></figure>

<p><img src="/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/image-20220114172032219.png" alt="image-20220114172032219"></p>
<h4 id="查询统计测试-1"><a href="#查询统计测试-1" class="headerlink" title="查询统计测试"></a>查询统计测试</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select count(1) from big_emp_split;</span><br></pre></td></tr></table></figure>

<p><strong>当做到这步，遇到好几个问题：</strong></p>
<ol>
<li><p>直接返回结果，没有启动MR</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive (hive)&gt; select count(1) from big_emp_split;</span><br><span class="line">OK</span><br><span class="line">_c0</span><br><span class="line">39999996</span><br><span class="line">Time taken: 0.27 seconds, Fetched: 1 row(s)</span><br></pre></td></tr></table></figure>

<p>可能是有缓存，添加where条件可以运行MR程序。</p>
</li>
<li><p>当设置<code>SET mapreduce.output.fileoutputformat.compress.codec=com.hadoop.compression.lzo.LzopCodec;</code>后，count(1)报错。</p>
<p>设置成<code>SET mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.DefaultCodec;</code>可以运行成功。</p>
<p>参考：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/blfshiye/p/5424097.html">https://www.cnblogs.com/blfshiye/p/5424097.html</a></p>
</li>
<li><p>但结果比未生成索引时的多了几条，map数量仍然为1，即生成索引后仍然没有分片成功。推断是把索引文件作为输入了，所以数据变多。网上查阅，应该是因为把索引文件当成小文件合并了，所以map数量为1，且数据变多。解决办法：修改<code>CombineHiveInputFormat</code>为<code>HiveInputFormat</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat;</span><br></pre></td></tr></table></figure>

<p>参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43589563/article/details/122353909">https://blog.csdn.net/weixin_43589563/article/details/122353909</a></p>
</li>
<li><p>问题解决，分片成功。</p>
<p><img src="/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/lzo-4.png" alt="image-20220114163716493"></p>
<p>这里我们可以看到map数量是21，也就是说lzo压缩文件构建索引以后是支持分片的。</p>
</li>
</ol>
<h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><p>这个开启压缩，在生成表的时候需要（生成lzo文件），在做统计的时候不需要设置。lzo文件生成索引后，索引不被合并掉，就支持分片。</p>
<h3 id="Hive支持处理LZO压缩格式分片步骤"><a href="#Hive支持处理LZO压缩格式分片步骤" class="headerlink" title="Hive支持处理LZO压缩格式分片步骤"></a>Hive支持处理LZO压缩格式分片步骤</h3><ol>
<li><p>默认设置即可</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SET hive.exec.compress.output=false;</span><br><span class="line">SET mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.DefaultCodec</span><br></pre></td></tr></table></figure></li>
<li><p>更改hive.input.format，防止索引被合并</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat;</span><br></pre></td></tr></table></figure></li>
<li><p>为lzo文件创建索引</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /home/hadoop/app/hadoop/share/hadoop/common/hadoop-lzo-0.4.21-SNAPSHOT.jar com.hadoop.compression.lzo.LzoIndexer /user/hive/warehouse/hive.db/big_emp_split</span><br></pre></td></tr></table></figure></li>
<li><p>统计查询</p>
</li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/01/18/%E6%90%AD%E5%BB%BAHUE%EF%BC%8C%E9%9B%86%E6%88%90hdfs-Hive-MySql/" rel="prev" title="搭建HUE，集成hdfs,Hive,MySQL">
                  <i class="fa fa-chevron-left"></i> 搭建HUE，集成hdfs,Hive,MySQL
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/01/19/CentOS6-5%E5%AE%89%E8%A3%85NodeJS14-18-3/" rel="next" title="CentOS6.5安装NodeJS14.18.3">
                  CentOS6.5安装NodeJS14.18.3 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">k12</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  





</body>
</html>
