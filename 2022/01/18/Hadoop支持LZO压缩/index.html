<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="一、Hadoop支持LZO压缩1.lzoplzo格式文件压缩解压需要用到服务器的lzop工具，hadoop 的native库（hadoop checknative是没有的lzo,zip相关信息）并不支持 123#安装以前先执行以下命令[hadoop@hadoop001 ~]$ which lzop&#x2F;usr&#x2F;bin&#x2F;lzop   【注意】这代表你已经有lzop，如果找不到，就执行以下命令 12345">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop支持LZO压缩">
<meta property="og:url" content="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/index.html">
<meta property="og:site_name" content="k12的博客">
<meta property="og:description" content="一、Hadoop支持LZO压缩1.lzoplzo格式文件压缩解压需要用到服务器的lzop工具，hadoop 的native库（hadoop checknative是没有的lzo,zip相关信息）并不支持 123#安装以前先执行以下命令[hadoop@hadoop001 ~]$ which lzop&#x2F;usr&#x2F;bin&#x2F;lzop   【注意】这代表你已经有lzop，如果找不到，就执行以下命令 12345">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/lzo-1.png">
<meta property="og:image" content="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/image-20220113183629075.png">
<meta property="og:image" content="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/lzo-2.png">
<meta property="og:image" content="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/image-20220114164409879.png">
<meta property="og:image" content="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/lzo-3.png">
<meta property="og:image" content="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/image-20220114171956115.png">
<meta property="og:image" content="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/image-20220114172032219.png">
<meta property="og:image" content="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/lzo-4.png">
<meta property="article:published_time" content="2022-01-18T15:17:28.000Z">
<meta property="article:modified_time" content="2022-01-18T17:39:13.265Z">
<meta property="article:author" content="k12">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/lzo-1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://k12coding.github.io/2022/01/18/Hadoop支持LZO压缩/"/>





  <title>Hadoop支持LZO压缩 | k12的博客</title>
  








<meta name="generator" content="Hexo 5.4.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">k12的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">k12的笔记</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://k12coding.github.io/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="k12的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Hadoop支持LZO压缩</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2022-01-18T23:17:28+08:00">
                2022-01-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="一、Hadoop支持LZO压缩"><a href="#一、Hadoop支持LZO压缩" class="headerlink" title="一、Hadoop支持LZO压缩"></a>一、Hadoop支持LZO压缩</h2><h3 id="1-lzop"><a href="#1-lzop" class="headerlink" title="1.lzop"></a>1.lzop</h3><p>lzo格式文件压缩解压需要用到服务器的lzop工具，hadoop 的<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=native&spm=1001.2101.3001.7020">native</a>库（hadoop checknative是没有的lzo,zip相关信息）并不支持</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#安装以前先执行以下命令</span><br><span class="line">[hadoop@hadoop001 ~]$ which lzop</span><br><span class="line">/usr/bin/lzop</span><br></pre></td></tr></table></figure>

<p> 【<em><strong>注意</strong></em>】这代表你已经有lzop，如果找不到，就执行以下命令</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#若没有执行如下安装命令【这些命令一定要在root用户下安装，否则没有权限】</span><br><span class="line">[root@hadoop001 ~]# yum install -y svn ncurses-devel</span><br><span class="line">[root@hadoop001 ~]# yum install -y gcc gcc-c++ make cmake</span><br><span class="line">[root@hadoop001 ~]# yum install -y openssl openssl-devel svn ncurses-devel zlib-devel libtool</span><br><span class="line">[root@hadoop001 ~]# yum install -y lzo lzo-devel lzop autoconf automake cmake </span><br><span class="line">[root@hadoop001 ~]# yum -y install lzo-devel zlib-devel gcc autoconf automake libtool</span><br></pre></td></tr></table></figure>

<h3 id="2-安装hadoop-lzo"><a href="#2-安装hadoop-lzo" class="headerlink" title="2.安装hadoop-lzo"></a>2.安装hadoop-lzo</h3><ol>
<li><h4 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/twitter/hadoop-lzo/archive/master.zip</span><br></pre></td></tr></table></figure></li>
<li><h4 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 source]$ ll</span><br><span class="line">total 1028</span><br><span class="line">drwxrwxr-x. 18 hadoop hadoop    4096 Oct 13 20:53 hadoop-2.6.0-cdh5.7.0</span><br><span class="line">drwxr-xr-x. 18 hadoop hadoop    4096 Jan  3  2021 hadoop-3.2.2-src</span><br><span class="line">-rw-rw-r--.  1 hadoop hadoop 1040294 Jan 11 21:57 master</span><br><span class="line">[hadoop@hadoop001 source]$ unzip master</span><br><span class="line">[hadoop@hadoop001 source]$ ll</span><br><span class="line">total 1028</span><br><span class="line">drwxrwxr-x. 18 hadoop hadoop    4096 Oct 13 20:53 hadoop-2.6.0-cdh5.7.0</span><br><span class="line">drwxr-xr-x. 18 hadoop hadoop    4096 Jan  3  2021 hadoop-3.2.2-src</span><br><span class="line">drwxrwxr-x.  5 hadoop hadoop    4096 Jan 11 22:03 hadoop-lzo-master</span><br><span class="line">-rw-rw-r--.  1 hadoop hadoop 1040294 Jan 11 21:57 master</span><br></pre></td></tr></table></figure></li>
<li><h4 id="修改pom-xml"><a href="#修改pom-xml" class="headerlink" title="修改pom.xml"></a>修改pom.xml</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 source]cd hadoop-lzo-master</span><br><span class="line">[hadoop@hadoop001 hadoop-lzo-master]$ vi pom.xml </span><br><span class="line">&lt;hadoop.current.version&gt;3.2.2&lt;/hadoop.current.version&gt;</span><br></pre></td></tr></table></figure></li>
<li><h4 id="声明两个临时环境变量"><a href="#声明两个临时环境变量" class="headerlink" title="声明两个临时环境变量"></a>声明两个临时环境变量</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop-lzo-master]$ </span><br><span class="line">export C_INCLUDE_PATH=/home/hadoop/app/hadoop/lzo/include     </span><br><span class="line">[hadoop@hadoop001 hadoop-lzo-master]$ </span><br><span class="line">export LIBRARY_PATH=/home/hadoop/app/hadoop/lzo/lib </span><br></pre></td></tr></table></figure></li>
<li><h4 id="编译（不需要阿里云仓库）"><a href="#编译（不需要阿里云仓库）" class="headerlink" title="编译（不需要阿里云仓库）"></a>编译（不需要阿里云仓库）</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop-lzo-master]$ mvn clean package -Dmaven.test.skip=true</span><br></pre></td></tr></table></figure>

<p>查看编译后的jar，hadoop-lzo-0.4.21-SNAPSHOT.jar则为我们需要的jar</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop-lzo-master]$ cd target/</span><br><span class="line">[hadoop@hadoop001 target]$ ll</span><br><span class="line">total 444</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop   4096 Jan 11 22:03 antrun</span><br><span class="line">drwxrwxr-x. 4 hadoop hadoop   4096 Jan 11 22:03 apidocs</span><br><span class="line">drwxrwxr-x. 5 hadoop hadoop   4096 Jan 11 22:03 classes</span><br><span class="line">drwxrwxr-x. 3 hadoop hadoop   4096 Jan 11 22:03 generated-sources</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 180550 Jan 11 22:03 hadoop-lzo-0.4.21-SNAPSHOT.jar</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 181006 Jan 11 22:03 hadoop-lzo-0.4.21-SNAPSHOT-javadoc.jar</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop  52043 Jan 11 22:03 hadoop-lzo-0.4.21-SNAPSHOT-sources.jar</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop   4096 Jan 11 22:03 javadoc-bundle-options</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop   4096 Jan 11 22:03 maven-archiver</span><br><span class="line">drwxrwxr-x. 3 hadoop hadoop   4096 Jan 11 22:03 native</span><br><span class="line">drwxrwxr-x. 3 hadoop hadoop   4096 Jan 11 22:03 test-classes</span><br></pre></td></tr></table></figure></li>
<li><h4 id="上传jar包"><a href="#上传jar包" class="headerlink" title="上传jar包"></a>上传jar包</h4><p>将hadoop-lzo-0.4.21-SNAPSHOT.jar包复制到我们的hadoop的$HADOOP_HOME/share/hadoop/common/目录下才能被hadoop使用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 target]$ cp hadoop-lzo-0.4.21-SNAPSHOT.jar ~/app/hadoop/share/hadoop/common/ </span><br></pre></td></tr></table></figure>

<p>如果是集群，需要使用<code>xsync hadoop-lzo-0.4.21.jar</code>命令同步到集群中的其他机器</p>
</li>
<li><h4 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h4><p>core-site.xml</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;io.compression.codecs&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;</span><br><span class="line">		org.apache.hadoop.io.compress.GzipCodec,</span><br><span class="line">		org.apache.hadoop.io.compress.DefaultCodec,</span><br><span class="line">		org.apache.hadoop.io.compress.BZip2Codec,</span><br><span class="line">		org.apache.hadoop.io.compress.SnappyCodec,</span><br><span class="line">		com.hadoop.compression.lzo.LzoCodec,</span><br><span class="line">		com.hadoop.compression.lzo.LzopCodec</span><br><span class="line">	&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;io.compression.codec.lzo.class&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;com.hadoop.compression.lzo.LzoCodec&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<p>mapred-site.xml（如果修改了，则默认输出格式为lzo）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;mapreduce.map.output.compress&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;mapreduce.map.output.compress.codec&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;com.hadoop.compression.lzo.LzoCodec&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.output.fileoutputformat.compress&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;mapreduce.output.fileoutputformat.compress.codec&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;com.hadoop.compression.lzo.LzopCodec&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li>
<li><h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><ul>
<li><p><strong>配置了mapred-site.xml</strong>:</p>
<p>hadoop jar ${HADOOP_HOME}/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar wordcount /input /output</p>
</li>
<li><p>没有配置mapred-site.xml(指定输出文件格式为lzo)：</p>
<p>hadoop jar ${HADOOP_HOME}/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar wordcount <strong>-Dmapreduce.output.fileoutputformat.compress=true</strong> <strong>-Dmapreduce.output.fileoutputformat.compress.codec=com.hadoop.compression.lzo.LzopCodec</strong> /input /output</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 mapreduce]$ hadoop jar /home/hadoop/app/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar wordcount -Dmapreduce.output.fileoutputformat.compress=true -Dmapreduce.output.fileoutputformat.compress.codec=com.hadoop.compression.lzo.LzopCodec /wc/input/wc.data /output</span><br><span class="line">[hadoop@hadoop001 mapreduce]$ hadoop fs -ls /output</span><br><span class="line">-rw-r--r--   1 hadoop supergroup          0 2022-01-11 22:18 /output/_SUCCESS</span><br><span class="line">-rw-r--r--   1 hadoop supergroup         95 2022-01-11 22:18 /output/part-r-00000.lzo</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="3-LZO创建索引"><a href="#3-LZO创建索引" class="headerlink" title="3.LZO创建索引"></a>3.LZO创建索引</h3><ol>
<li><h3 id="创建LZO文件的索引"><a href="#创建LZO文件的索引" class="headerlink" title="创建LZO文件的索引"></a>创建LZO文件的索引</h3><p>创建LZO文件的索引，LZO压缩文件的可切片特性依赖于其索引，故我们需要手动为LZO压缩文件创建索引。若无索引，则LZO文件的切片只有一个。</p>
<p>命令：<code>hadoop jar $HADOOP_HOME/share/hadoop/common/hadoop-lzo-0.4.21-SNAPSHOT.jar com.hadoop.compression.lzo.DistributedLzoIndexer XXX.lzo</code></p>
</li>
<li><h3 id="执行wc-没有创建索引"><a href="#执行wc-没有创建索引" class="headerlink" title="执行wc(没有创建索引)"></a>执行wc(没有创建索引)</h3><p>创建需要分片处理的bigwcneedspilt.data.lzo（203M）文件，并上传到hdfs上</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 data]$ lzop bigwcneedspilt.data</span><br><span class="line">[hadoop@hadoop001 data]$ du -sh bigwc*</span><br><span class="line">157M	bigwc.data</span><br><span class="line">51M	bigwc.data.lzo</span><br><span class="line">625M	bigwcneedspilt.data</span><br><span class="line">203M	bigwcneedspilt.data.lzo</span><br><span class="line">18M	bigwc.txt</span><br><span class="line">[hadoop@hadoop001 data]$ hadoop fs -put bigwcneedspilt.data.lzo /user/hadoop/data/</span><br></pre></td></tr></table></figure>

<p>执行wc(没有创建索引)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 ~]$ hadoop jar /home/hadoop/app/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar wordcount -Dmapreduce.job.inputformat.class=com.hadoop.mapreduce.LzoTextInputFormat /user/hadoop/data/bigwcneedspilt.data.lzo /output1</span><br></pre></td></tr></table></figure>

<p><img src="/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/lzo-1.png" alt="image-20220113175318333"></p>
<p>可以看到此时切片并没有生效，依然只有一个</p>
</li>
<li><h3 id="对上传的LZO文件创建索引"><a href="#对上传的LZO文件创建索引" class="headerlink" title="对上传的LZO文件创建索引"></a>对上传的LZO文件创建索引</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 ~]$ hadoop jar /home/hadoop/app/hadoop/share/hadoop/common/hadoop-lzo-0.4.21-SNAPSHOT.jar  com.hadoop.compression.lzo.DistributedLzoIndexer /user/hadoop/data/bigwcneedspilt.data.lzo</span><br></pre></td></tr></table></figure>

<p><img src="/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/image-20220113183629075.png" alt="image-20220113183629075"></p>
</li>
<li><h3 id="执行wc-已经创建索引"><a href="#执行wc-已经创建索引" class="headerlink" title="执行wc(已经创建索引)"></a>执行wc(已经创建索引)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 ~]$ hadoop jar /home/hadoop/app/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar wordcount -Dmapreduce.job.inputformat.class=com.hadoop.mapreduce.LzoTextInputFormat /user/hadoop/data/bigwcneedspilt.data.lzo /output2</span><br></pre></td></tr></table></figure>

<p><img src="/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/lzo-2.png" alt="image-20220113193027590"></p>
<p>此时已经成功切片</p>
</li>
</ol>
<h2 id="二、Hive支持处理LZO压缩格式的数据的统计查询"><a href="#二、Hive支持处理LZO压缩格式的数据的统计查询" class="headerlink" title="二、Hive支持处理LZO压缩格式的数据的统计查询"></a>二、Hive支持处理LZO压缩格式的数据的统计查询</h2><h3 id="开启压缩的方式"><a href="#开启压缩的方式" class="headerlink" title="开启压缩的方式"></a>开启压缩的方式</h3><ul>
<li>在**<code>$HIVE_HOME/conf/hive-site.xml</code>**中设置</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 设置hive语句执行输出文件是否开启压缩,具体的压缩算法和压缩格式取决于hadoop中</span><br><span class="line">设置的相关参数 --&gt;</span><br><span class="line">&lt;!-- 默认值:false --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.exec.compress.output&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">        This controls whether the final outputs of a query (to a local/HDFS file or a Hive table) </span><br><span class="line">        is compressed. </span><br><span class="line">        The compression codec and other options are determined from Hadoop config variables </span><br><span class="line">        mapred.output.compress*</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- 控制多个MR Job的中间结果文件是否启用压缩,具体的压缩算法和压缩格式取决于hadoop中</span><br><span class="line">设置的相关参数 --&gt;</span><br><span class="line">&lt;!-- 默认值:false --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.exec.compress.intermediate&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">        This controls whether intermediate files produced by Hive between multiple map-reduce jobs are compressed. </span><br><span class="line">        The compression codec and other options are determined from Hadoop config variables mapred.output.compress*</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>在hive中开启</p>
<p>查看默认状态：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (hive)&gt; SET hive.exec.compress.output;</span><br><span class="line">hive.exec.compress.output=false</span><br><span class="line">hive (hive)&gt; set mapreduce.output.fileoutputformat.compress.codec;</span><br><span class="line">mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.DefaultCodec</span><br></pre></td></tr></table></figure>

<p>开启支持压缩，格式为lzop（lzo在文件构建索引后才会支持数据分片）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (hive)&gt; SET hive.exec.compress.output=true;</span><br><span class="line">hive (hive)&gt; SET mapreduce.output.fileoutputformat.compress.codec=com.hadoop.compression.lzo.LzopCodec;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="数据与环境准备"><a href="#数据与环境准备" class="headerlink" title="数据与环境准备"></a>数据与环境准备</h3><p>数据准备：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 data]$ lzop bigemp.data </span><br><span class="line">[hadoop@hadoop001 data]$ du -sh bigemp*</span><br><span class="line">823M	bigemp.data</span><br><span class="line">206M	bigemp.data.lzo</span><br></pre></td></tr></table></figure>

<p>为了方便测试分片，我重启了hadoop，修改了hdfs-site.xml设置了blocksize=10M。然后mapr-site.xml没有配置上面的4个值。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;dfs.blocksize&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;10485760&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<h3 id="未开启（未添加索引）"><a href="#未开启（未添加索引）" class="headerlink" title="未开启（未添加索引）"></a>未开启（未添加索引）</h3><h4 id="建表"><a href="#建表" class="headerlink" title="建表"></a>建表</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE big_emp (id int,name string,dept string)</span><br><span class="line">ROW FORMAT DELIMITED FIELDS TERMINATED BY &#x27;\t&#x27;</span><br><span class="line">STORED AS INPUTFORMAT &quot;com.hadoop.mapred.DeprecatedLzoTextInputFormat&quot;</span><br><span class="line">OUTPUTFORMAT &quot;org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat&quot;</span><br></pre></td></tr></table></figure>

<h4 id="从本地load-LZO压缩数据bigemp-data-lzo到表big-emp"><a href="#从本地load-LZO压缩数据bigemp-data-lzo到表big-emp" class="headerlink" title="从本地load LZO压缩数据bigemp.data.lzo到表big_emp"></a>从本地load LZO压缩数据<code>bigemp.data.lzo</code>到表<code>big_emp</code></h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA LOCAL INPATH &#x27;/home/hadoop/data/bigemp.data.lzo&#x27; OVERWRITE INTO TABLE big_emp</span><br></pre></td></tr></table></figure>

<h4 id="查看大小"><a href="#查看大小" class="headerlink" title="查看大小"></a>查看大小</h4><p><img src="/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/image-20220114164409879.png" alt="image-20220114164409879"></p>
<h4 id="查询统计测试"><a href="#查询统计测试" class="headerlink" title="查询统计测试"></a>查询统计测试</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select count(1) from big_emp;</span><br></pre></td></tr></table></figure>

<p><img src="/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/lzo-3.png" alt="image-20220114045505294"></p>
<p>因为我们的块大小是默认的128M，而bigemp.data.lzo这个lzo压缩文件的大小远远大于128M*1.1，但是我们可以看见Map只有一个，可见lzo是不支持分片的。</p>
<h3 id="已开启（已添加索引）"><a href="#已开启（已添加索引）" class="headerlink" title="已开启（已添加索引）"></a><strong>已开启（已添加索引）</strong></h3><h4 id="开启压缩"><a href="#开启压缩" class="headerlink" title="开启压缩"></a>开启压缩</h4><p>生成的压缩文件格式必须为设置为<strong>LzopCodec</strong>，lzoCode的压缩文件格式后缀为<code>.lzo_deflate</code>是无法创建索引的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive (hive)&gt; SET hive.exec.compress.output=true;</span><br><span class="line">hive (hive)&gt; SET mapreduce.output.fileoutputformat.compress.codec=com.hadoop.compression.lzo.LzopCodec;</span><br><span class="line">hive (hive)&gt; SET hive.exec.compress.output;</span><br><span class="line">hive.exec.compress.output=true</span><br><span class="line">hive (hive)&gt; SET mapreduce.output.fileoutputformat.compress.codec;</span><br><span class="line">mapreduce.output.fileoutputformat.compress.codec=com.hadoop.compression.lzo.LzopCodec</span><br></pre></td></tr></table></figure>

<h4 id="建表，并插入big-emp的数据"><a href="#建表，并插入big-emp的数据" class="headerlink" title="建表，并插入big_emp的数据"></a>建表，并插入big_emp的数据</h4><p>（若不是直接load的lzo文件，需要开启压缩，且压缩格式为LzopCodec，load数据并不能改变文件格式和压缩格式。）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE big_emp_split ROW FORMAT DELIMITED FIELDS TERMINATED BY &#x27;\t&#x27;</span><br><span class="line">STORED AS INPUTFORMAT &quot;com.hadoop.mapred.DeprecatedLzoTextInputFormat&quot;</span><br><span class="line">OUTPUTFORMAT &quot;org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat&quot;</span><br><span class="line">as select * from big_emp;</span><br></pre></td></tr></table></figure>

<p><img src="/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/image-20220114171956115.png" alt="image-20220114171956115"></p>
<h4 id="构建LZO文件索引"><a href="#构建LZO文件索引" class="headerlink" title="构建LZO文件索引"></a>构建LZO文件索引</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /home/hadoop/app/hadoop/share/hadoop/common/hadoop-lzo-0.4.21-SNAPSHOT.jar com.hadoop.compression.lzo.LzoIndexer /user/hive/warehouse/hive.db/big_emp_split</span><br></pre></td></tr></table></figure>

<p><img src="/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/image-20220114172032219.png" alt="image-20220114172032219"></p>
<h4 id="查询统计测试-1"><a href="#查询统计测试-1" class="headerlink" title="查询统计测试"></a>查询统计测试</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select count(1) from big_emp_split;</span><br></pre></td></tr></table></figure>

<p><strong>当做到这步，遇到好几个问题：</strong></p>
<ol>
<li><p>直接返回结果，没有启动MR</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive (hive)&gt; select count(1) from big_emp_split;</span><br><span class="line">OK</span><br><span class="line">_c0</span><br><span class="line">39999996</span><br><span class="line">Time taken: 0.27 seconds, Fetched: 1 row(s)</span><br></pre></td></tr></table></figure>

<p>可能是有缓存，添加where条件可以运行MR程序。</p>
</li>
<li><p>当设置<code>SET mapreduce.output.fileoutputformat.compress.codec=com.hadoop.compression.lzo.LzopCodec;</code>后，count(1)报错。</p>
<p>设置成<code>SET mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.DefaultCodec;</code>可以运行成功。</p>
<p>参考：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/blfshiye/p/5424097.html">https://www.cnblogs.com/blfshiye/p/5424097.html</a></p>
</li>
<li><p>但结果比未生成索引时的多了几条，map数量仍然为1，即生成索引后仍然没有分片成功。推断是把索引文件作为输入了，所以数据变多。网上查阅，应该是因为把索引文件当成小文件合并了，所以map数量为1，且数据变多。解决办法：修改<code>CombineHiveInputFormat</code>为<code>HiveInputFormat</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat;</span><br></pre></td></tr></table></figure>

<p>参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43589563/article/details/122353909">https://blog.csdn.net/weixin_43589563/article/details/122353909</a></p>
</li>
<li><p>问题解决，分片成功。</p>
<p><img src="/2022/01/18/Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9/lzo-4.png" alt="image-20220114163716493"></p>
<p>这里我们可以看到map数量是21，也就是说lzo压缩文件构建索引以后是支持分片的。</p>
</li>
</ol>
<h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><p>这个开启压缩，在生成表的时候需要（生成lzo文件），在做统计的时候不需要设置。lzo文件生成索引后，索引不被合并掉，就支持分片。</p>
<h3 id="Hive支持处理LZO压缩格式分片步骤"><a href="#Hive支持处理LZO压缩格式分片步骤" class="headerlink" title="Hive支持处理LZO压缩格式分片步骤"></a>Hive支持处理LZO压缩格式分片步骤</h3><ol>
<li><p>默认设置即可</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SET hive.exec.compress.output=false;</span><br><span class="line">SET mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.DefaultCodec</span><br></pre></td></tr></table></figure></li>
<li><p>更改hive.input.format，防止索引被合并</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat;</span><br></pre></td></tr></table></figure></li>
<li><p>为lzo文件创建索引</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /home/hadoop/app/hadoop/share/hadoop/common/hadoop-lzo-0.4.21-SNAPSHOT.jar com.hadoop.compression.lzo.LzoIndexer /user/hive/warehouse/hive.db/big_emp_split</span><br></pre></td></tr></table></figure></li>
<li><p>统计查询</p>
</li>
</ol>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2022/01/18/%E6%90%AD%E5%BB%BAHUE%EF%BC%8C%E9%9B%86%E6%88%90hdfs-Hive-MySql/" rel="next" title="搭建HUE，集成hdfs,Hive,MySQL">
                <i class="fa fa-chevron-left"></i> 搭建HUE，集成hdfs,Hive,MySQL
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2022/01/19/CentOS6-5%E5%AE%89%E8%A3%85NodeJS14-18-3/" rel="prev" title="CentOS6.5安装NodeJS14.18.3">
                CentOS6.5安装NodeJS14.18.3 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">62</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E3%80%81Hadoop%E6%94%AF%E6%8C%81LZO%E5%8E%8B%E7%BC%A9"><span class="nav-number">1.</span> <span class="nav-text">一、Hadoop支持LZO压缩</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-lzop"><span class="nav-number">1.1.</span> <span class="nav-text">1.lzop</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E5%AE%89%E8%A3%85hadoop-lzo"><span class="nav-number">1.2.</span> <span class="nav-text">2.安装hadoop-lzo</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8B%E8%BD%BD"><span class="nav-number">1.2.1.</span> <span class="nav-text">下载</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%A7%A3%E5%8E%8B"><span class="nav-number">1.2.2.</span> <span class="nav-text">解压</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9pom-xml"><span class="nav-number">1.2.3.</span> <span class="nav-text">修改pom.xml</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A3%B0%E6%98%8E%E4%B8%A4%E4%B8%AA%E4%B8%B4%E6%97%B6%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="nav-number">1.2.4.</span> <span class="nav-text">声明两个临时环境变量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BC%96%E8%AF%91%EF%BC%88%E4%B8%8D%E9%9C%80%E8%A6%81%E9%98%BF%E9%87%8C%E4%BA%91%E4%BB%93%E5%BA%93%EF%BC%89"><span class="nav-number">1.2.5.</span> <span class="nav-text">编译（不需要阿里云仓库）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8A%E4%BC%A0jar%E5%8C%85"><span class="nav-number">1.2.6.</span> <span class="nav-text">上传jar包</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">1.2.7.</span> <span class="nav-text">修改配置文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95"><span class="nav-number">1.2.8.</span> <span class="nav-text">测试</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-LZO%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95"><span class="nav-number">1.3.</span> <span class="nav-text">3.LZO创建索引</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9B%E5%BB%BALZO%E6%96%87%E4%BB%B6%E7%9A%84%E7%B4%A2%E5%BC%95"><span class="nav-number">1.4.</span> <span class="nav-text">创建LZO文件的索引</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%89%A7%E8%A1%8Cwc-%E6%B2%A1%E6%9C%89%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95"><span class="nav-number">1.5.</span> <span class="nav-text">执行wc(没有创建索引)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9%E4%B8%8A%E4%BC%A0%E7%9A%84LZO%E6%96%87%E4%BB%B6%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95"><span class="nav-number">1.6.</span> <span class="nav-text">对上传的LZO文件创建索引</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%89%A7%E8%A1%8Cwc-%E5%B7%B2%E7%BB%8F%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95"><span class="nav-number">1.7.</span> <span class="nav-text">执行wc(已经创建索引)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E3%80%81Hive%E6%94%AF%E6%8C%81%E5%A4%84%E7%90%86LZO%E5%8E%8B%E7%BC%A9%E6%A0%BC%E5%BC%8F%E7%9A%84%E6%95%B0%E6%8D%AE%E7%9A%84%E7%BB%9F%E8%AE%A1%E6%9F%A5%E8%AF%A2"><span class="nav-number">2.</span> <span class="nav-text">二、Hive支持处理LZO压缩格式的数据的统计查询</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%80%E5%90%AF%E5%8E%8B%E7%BC%A9%E7%9A%84%E6%96%B9%E5%BC%8F"><span class="nav-number">2.1.</span> <span class="nav-text">开启压缩的方式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E4%B8%8E%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="nav-number">2.2.</span> <span class="nav-text">数据与环境准备</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%AA%E5%BC%80%E5%90%AF%EF%BC%88%E6%9C%AA%E6%B7%BB%E5%8A%A0%E7%B4%A2%E5%BC%95%EF%BC%89"><span class="nav-number">2.3.</span> <span class="nav-text">未开启（未添加索引）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BB%BA%E8%A1%A8"><span class="nav-number">2.3.1.</span> <span class="nav-text">建表</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%8E%E6%9C%AC%E5%9C%B0load-LZO%E5%8E%8B%E7%BC%A9%E6%95%B0%E6%8D%AEbigemp-data-lzo%E5%88%B0%E8%A1%A8big-emp"><span class="nav-number">2.3.2.</span> <span class="nav-text">从本地load LZO压缩数据bigemp.data.lzo到表big_emp</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9F%A5%E7%9C%8B%E5%A4%A7%E5%B0%8F"><span class="nav-number">2.3.3.</span> <span class="nav-text">查看大小</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9F%A5%E8%AF%A2%E7%BB%9F%E8%AE%A1%E6%B5%8B%E8%AF%95"><span class="nav-number">2.3.4.</span> <span class="nav-text">查询统计测试</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B7%B2%E5%BC%80%E5%90%AF%EF%BC%88%E5%B7%B2%E6%B7%BB%E5%8A%A0%E7%B4%A2%E5%BC%95%EF%BC%89"><span class="nav-number">2.4.</span> <span class="nav-text">已开启（已添加索引）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BC%80%E5%90%AF%E5%8E%8B%E7%BC%A9"><span class="nav-number">2.4.1.</span> <span class="nav-text">开启压缩</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BB%BA%E8%A1%A8%EF%BC%8C%E5%B9%B6%E6%8F%92%E5%85%A5big-emp%E7%9A%84%E6%95%B0%E6%8D%AE"><span class="nav-number">2.4.2.</span> <span class="nav-text">建表，并插入big_emp的数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9E%84%E5%BB%BALZO%E6%96%87%E4%BB%B6%E7%B4%A2%E5%BC%95"><span class="nav-number">2.4.3.</span> <span class="nav-text">构建LZO文件索引</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9F%A5%E8%AF%A2%E7%BB%9F%E8%AE%A1%E6%B5%8B%E8%AF%95-1"><span class="nav-number">2.4.4.</span> <span class="nav-text">查询统计测试</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A1%A5%E5%85%85"><span class="nav-number">2.5.</span> <span class="nav-text">补充</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive%E6%94%AF%E6%8C%81%E5%A4%84%E7%90%86LZO%E5%8E%8B%E7%BC%A9%E6%A0%BC%E5%BC%8F%E5%88%86%E7%89%87%E6%AD%A5%E9%AA%A4"><span class="nav-number">2.6.</span> <span class="nav-text">Hive支持处理LZO压缩格式分片步骤</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">k12</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
