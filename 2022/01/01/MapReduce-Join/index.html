<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"k12coding.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.8.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>
<meta name="description" content="概述   在传统数据库（如：MySql）中，JOIN操作常常是非常耗时的。而在HADOOP中进行JOIN操作，同样常见且耗时，由于Hadoop的独特设计思想，当进行JOIN操作时，有一些特殊的技巧。下面分别介绍MapReduce中的几种常见join，比如有最常见的 map side join，reduce side join，semi join（这些在Hive中都有） 等。Map side joi">
<meta property="og:type" content="article">
<meta property="og:title" content="MapReduce Join">
<meta property="og:url" content="https://k12coding.github.io/2022/01/01/MapReduce-Join/index.html">
<meta property="og:site_name" content="k12的博客">
<meta property="og:description" content="概述   在传统数据库（如：MySql）中，JOIN操作常常是非常耗时的。而在HADOOP中进行JOIN操作，同样常见且耗时，由于Hadoop的独特设计思想，当进行JOIN操作时，有一些特殊的技巧。下面分别介绍MapReduce中的几种常见join，比如有最常见的 map side join，reduce side join，semi join（这些在Hive中都有） 等。Map side joi">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-01-01T08:38:34.000Z">
<meta property="article:modified_time" content="2022-01-05T08:39:35.839Z">
<meta property="article:author" content="k12">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://k12coding.github.io/2022/01/01/MapReduce-Join/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://k12coding.github.io/2022/01/01/MapReduce-Join/","path":"2022/01/01/MapReduce-Join/","title":"MapReduce Join"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>MapReduce Join | k12的博客</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">k12的博客</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">k12的笔记</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A6%82%E8%BF%B0"><span class="nav-text">概述</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B8%B8%E8%A7%81%E7%9A%84join%E6%96%B9%E6%B3%95%E4%BB%8B%E7%BB%8D"><span class="nav-text">常见的join方法介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#map-side-join"><span class="nav-text">map side join</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#reduce-side-join"><span class="nav-text">reduce side join</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Semi-Join"><span class="nav-text">Semi Join</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#reduce-side-join-BloomFilter"><span class="nav-text">reduce side join + BloomFilter</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90"><span class="nav-text">案例分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87"><span class="nav-text">数据准备</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%BA%8F%E5%88%97%E5%8C%96%E7%B1%BB"><span class="nav-text">自定义序列化类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Map-Join"><span class="nav-text">Map Join</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reduce-Join"><span class="nav-text">Reduce Join</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">k12</p>
  <div class="site-description" itemprop="description">2</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">54</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://k12coding.github.io/2022/01/01/MapReduce-Join/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="k12">
      <meta itemprop="description" content="2">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="k12的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          MapReduce Join
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-01-01 16:38:34" itemprop="dateCreated datePublished" datetime="2022-01-01T16:38:34+08:00">2022-01-01</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2022-01-05 16:39:35" itemprop="dateModified" datetime="2022-01-05T16:39:35+08:00">2022-01-05</time>
      </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>   在传统数据库（如：MySql）中，JOIN操作常常是非常耗时的。而在HADOOP中进行JOIN操作，同样常见且耗时，由于Hadoop的独特设计思想，当进行JOIN操作时，有一些特殊的技巧。下面分别介绍MapReduce中的几种常见join，比如有最常见的 map side join，reduce side join，semi join（这些在Hive中都有） 等。Map side join在处理多个小表关联大表时非常有用，而 reduce join 在处理多表关联时是比较麻烦的，会造成大量的网络IO，效率低下，但在有些时候也是非常有用的。</p>
<span id="more"></span>

<h2 id="常见的join方法介绍"><a href="#常见的join方法介绍" class="headerlink" title="常见的join方法介绍"></a>常见的join方法介绍</h2><h3 id="map-side-join"><a href="#map-side-join" class="headerlink" title="map side join"></a>map side join</h3><p> Map side  join是针对以下场景进行的优化：两个待连接表中，有一个表非常大，而另一个表非常小，以至于小表可以直接存放到内存中。这样，我们可以将小表复制多份，让每个map task内存中存在一份（比如存放到hash table中），然后只扫描大表：对于大表中的每一条记录key/value，在hash  table中查找是否有相同的key的记录，如果有，则连接后输出即可。</p>
<p> 为了支持文件的复制，Hadoop提供了一个类DistributedCache，使用该类的方法如下：</p>
<p> （1）用户使用静态方法DistributedCache.addCacheFile()指定要复制的文件，它的参数是文件的URI（如果是HDFS上的文件，可以这样：hdfs://namenode:9000/home/XXX/file，其中9000是自己配置的NameNode端口号）。JobTracker在作业启动之前会获取这个URI列表，并将相应的文件拷贝到各个TaskTracker的本地磁盘上。</p>
<p>（2）用户使用DistributedCache.getLocalCacheFiles()方法获取文件目录，并使用标准的文件读写API读取相应的文件。</p>
<p><strong>补充:</strong></p>
<p>旧版本的DistributedCache和getLocalCacheFiles已经被注解为过时，本人下面案例中是<code>job.addCacheFile(new URI(SmallTable))</code>指定要复制的文件，<code>context.getCacheFiles()</code>获取文件目录。和getLocalCacheFiles不同的是，getCacheFiles得到的路径是HDFS上的文件路径，如果使用这个方法，那么程序中读取的就不再试缓存在各个节点上的数据了，相当于共同访问HDFS上的同一个文件。</p>
<p>main方法中设置缓存文件，而且Map Join不需要Reduce阶段，设置Reduce Task数量为0</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">job.addCacheFile(new URI(&quot;file:/你的文件路径));</span><br><span class="line">job.setNumReduceTasks(0);</span><br></pre></td></tr></table></figure>

<p>或者是HDFS上的URI</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.addCacheFile(new URI(&quot;hdfs://url:port/filename&quot;));</span><br></pre></td></tr></table></figure>

<p>在Mapper类的setup方法中加载缓存文件，setup方法，在maptask运行前只调用一次，可进行初始化工作。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">protected void setup(Context context)throws IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">    //获取缓存文件路径</span><br><span class="line">    URI[] cacheFiles = context.getCacheFiles();</span><br><span class="line">    //新的检索缓存文件的API是 context.getCacheFiles() ，而 context.getLocalCacheFiles() 被弃用</span><br><span class="line">    //然而 context.getCacheFiles() 返回的是 HDFS 路径； context.getLocalCacheFiles() 返回的才是本地路径</span><br><span class="line">    String path = cacheFiles[0].getPath();</span><br><span class="line">    </span><br><span class="line"> 	//读文件</span><br><span class="line">    BufferedReader reader = new BufferedReader(new InputStreamReader(new FileInputStream(path)));</span><br><span class="line"></span><br><span class="line">	String line;</span><br><span class="line"> 	while(StringUtils.isNotEmpty(line = reader.readLine())) &#123;</span><br><span class="line"> 		String[] splits = line.split(&quot;\t&quot;);</span><br><span class="line"> 		cache.put(splits[0].trim(), splits[1].trim());</span><br><span class="line"> 	&#125;</span><br><span class="line"></span><br><span class="line"> 	IOUtils.closeStream(reader);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>特点：</p>
<ul>
<li>Join操作在map task中完成，因此无需启动reduce task</li>
<li>适合一个大表，一个小表的连接操作</li>
</ul>
<p>局限性：</p>
<ul>
<li>有一份数据比较小，在map端，能够把它加载在内存，并进行join操作。</li>
</ul>
<h3 id="reduce-side-join"><a href="#reduce-side-join" class="headerlink" title="reduce side join"></a>reduce side join</h3><p> reduce side join是一种最简单的join方式， 之所以存在reduce side join，是因为在map阶段不能获取所有需要的join字段，即：同一个key对应的字段可能位于不同map中。Reduce  side join是非常低效的，因为shuffle阶段要进行大量的数据传输。</p>
<p> 假设要进行join的数据分别来自File1和File2.</p>
<p> 在map阶段，map函数同时读取两个文件File1和File2，为了区分两种来源的key/value数据对，对每条数据打一个标签（tag）,比如：tag=0表示来自文件File1，tag=2表示来自文件File2。即：map阶段的主要任务是对不同文件中的数据打标签。</p>
<p> 在reduce阶段，reduce函数获取key相同的来自File1和File2文件的value list，  然后对于同一个key，对File1和File2中的数据进行join（笛卡尔乘积）。即：reduce阶段进行实际的连接操作。</p>
<p>特点：</p>
<ul>
<li>Join操作在reduce task中完成</li>
<li>适合两个大表的连接操作</li>
</ul>
<p>局限性：</p>
<ul>
<li>map阶段没有对数据瘦身，shuffle的网络传输和排序性能很低。</li>
<li>reduce端对2个集合做乘积计算，很耗内存，容易导致OOM。</li>
</ul>
<h3 id="Semi-Join"><a href="#Semi-Join" class="headerlink" title="Semi Join"></a>Semi Join</h3><p> SemiJoin，也叫半连接，是从分布式数据库中借鉴过来的方法。它的产生动机是：对于reduce side  join，跨机器的数据传输量非常大，这成了join操作的一个瓶颈，如果能够在map端过滤掉不会参加join操作的数据，则可以大大节省网络IO。</p>
<p> 实现方法很简单：选取一个小表，假设是File1，将其参与join的key抽取出来，保存到文件File3中，File3文件一般很小，可以放到内存中。在map阶段，使用DistributedCache将File3复制到各个TaskTracker上，然后将File2中不在File3中的key对应的记录过滤掉，剩下的reduce阶段的工作与reducee  side join相同。</p>
<h3 id="reduce-side-join-BloomFilter"><a href="#reduce-side-join-BloomFilter" class="headerlink" title="reduce side join + BloomFilter"></a>reduce side join + BloomFilter</h3><p> 在某些情况下，Semi Join抽取出来的小表的key集合在内存中仍然存放不下，这时候可以使用BloomFiler以节省空间。</p>
<p> BloomFilter最常见的作用是：判断某个元素是否在一个集合里面。它最重要的两个方法是：add()  和contains()。最大的特点是不会存在false  negative，即：如果contains()返回false，则该元素一定不在集合中，但会存在一定的true  negative，即：如果contains()返回true，则该元素可能在集合中。</p>
<p> 因而可将小表中的key保存到BloomFilter中，在map阶段过滤大表，可能有一些不在小表中的记录没有过滤掉（但是在小表中的记录一定不会过滤掉），这没关系，只不过增加了少量的网络IO而已。</p>
<p>Hadoop面试的时候也会问到 Hadoop上Join的实现，几乎是一道必问的问题，而极个别公司还会涉及到DistributedCache原理以及怎样利用DistributedCache进行Join操作。</p>
<h1 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h1><h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><p>data/input/join/emp.txt</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">7369    SMITH  CLERK  7902   1980-12-17 800.00    20</span><br><span class="line">7499   ALLEN  SALESMAN   7698   1981-2-20  1600.00    300.00 30</span><br><span class="line">7521   WARD   SALESMAN   7698   1981-2-22  1250.00    500.00 30</span><br><span class="line">7566   JONES  MANAGER    7839   1981-4-2   2975.00       20</span><br><span class="line">7654   MARTIN SALESMAN   7698   1981-9-28  1250.00    1400.00    30</span><br><span class="line">7698   BLAKE  MANAGER    7839   1981-5-1   2850.00       30</span><br><span class="line">7782   CLARK  MANAGER    7839   1981-6-9   2450.00       10</span><br><span class="line">7788   SCOTT  ANALYST    7566   1987-4-19  3000.00       20</span><br><span class="line">7839   KING   PRESIDENT     1981-11-17 5000.00       10</span><br><span class="line">7844   TURNER SALESMAN   7698   1981-9-8   1500.00    0.00   30</span><br><span class="line">7876   ADAMS  CLERK  7788   1987-5-23  1100.00       20</span><br><span class="line">7900   JAMES  CLERK  7698   1981-12-3  950.00    30</span><br><span class="line">7902   FORD   ANALYST    7566   1981-12-3  3000.00       20</span><br><span class="line">7934   MILLER CLERK  7782   1982-1-23  1300.00       10</span><br></pre></td></tr></table></figure>

<p>data/input/join/dept.txt</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">10	ACCOUNTING	NEW YORK</span><br><span class="line">20	RESEARCH	DALLAS</span><br><span class="line">30	SALES	CHICAGO</span><br><span class="line">40	OPERATIONS	BOSTON</span><br></pre></td></tr></table></figure>

<h2 id="自定义序列化类"><a href="#自定义序列化类" class="headerlink" title="自定义序列化类"></a>自定义序列化类</h2><p>info.java</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.hadoop.io.Writable;</span><br><span class="line">import java.io.DataInput;</span><br><span class="line">import java.io.DataOutput;</span><br><span class="line">import java.io.IOException;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * join结果最终需要的字段</span><br><span class="line"> */</span><br><span class="line">public class Info implements Writable &#123;</span><br><span class="line"></span><br><span class="line">    private int empno;</span><br><span class="line">    private String ename;</span><br><span class="line">    private int deptno;</span><br><span class="line">    private String dname;</span><br><span class="line">    private int flag;  // 标志位：用来区分数据来自于哪个表.mapjoin不需要flag，需要注释掉flag</span><br><span class="line"></span><br><span class="line">    public void write(DataOutput out) throws IOException &#123;</span><br><span class="line">        out.writeInt(empno);</span><br><span class="line">        out.writeUTF(ename);</span><br><span class="line">        out.writeInt(deptno);</span><br><span class="line">        out.writeUTF(dname);</span><br><span class="line">        out.writeInt(flag);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void readFields(DataInput in) throws IOException &#123;</span><br><span class="line">        this.empno = in.readInt();</span><br><span class="line">        this.ename = in.readUTF();</span><br><span class="line">        this.deptno = in.readInt();</span><br><span class="line">        this.dname = in.readUTF();</span><br><span class="line">        this.flag = in.readInt();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public Info() &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public Info(int empno, String ename, int deptno, String dname) &#123;</span><br><span class="line">        this.empno = empno;</span><br><span class="line">        this.ename = ename;</span><br><span class="line">        this.deptno = deptno;</span><br><span class="line">        this.dname = dname;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public Info(int empno, String ename, int deptno, String dname, int flag) &#123;</span><br><span class="line">        this.empno = empno;</span><br><span class="line">        this.ename = ename;</span><br><span class="line">        this.deptno = deptno;</span><br><span class="line">        this.dname = dname;</span><br><span class="line">        this.flag = flag;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public String toString() &#123;</span><br><span class="line">        return empno + &quot;\t&quot; + ename + &quot;\t&quot; + deptno + &quot;\t&quot; + dname;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public int getEmpno() &#123;</span><br><span class="line">        return empno;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void setEmpno(int empno) &#123;</span><br><span class="line">        this.empno = empno;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public String getEname() &#123;</span><br><span class="line">        return ename;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void setEname(String ename) &#123;</span><br><span class="line">        this.ename = ename;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public int getDeptno() &#123;</span><br><span class="line">        return deptno;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void setDeptno(int deptno) &#123;</span><br><span class="line">        this.deptno = deptno;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public String getDname() &#123;</span><br><span class="line">        return dname;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void setDname(String dname) &#123;</span><br><span class="line">        this.dname = dname;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public int getFlag() &#123;</span><br><span class="line">        return flag;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void setFlag(int flag) &#123;</span><br><span class="line">        this.flag = flag;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="Map-Join"><a href="#Map-Join" class="headerlink" title="Map Join"></a>Map Join</h2><p>main()：</p>
<ul>
<li>加载缓存数据：<code>job.addCacheFile(new URI(&quot;file:/你的文件路径))</code>或者<code>job.addCacheFile(new URI(&quot;hdfs://url:port/filename&quot;));</code></li>
<li>设置Reduce Task数量为0：<code>job.setNumReduceTasks(0);</code></li>
</ul>
<p>setup():</p>
<ol>
<li>获取缓存的文件</li>
<li>循环读取缓存文件的每一行</li>
<li>切割</li>
<li>缓存数据到集合hashtable</li>
<li>关闭资源</li>
</ol>
<p>map():</p>
<ol>
<li>获取一行数据</li>
<li>截取</li>
<li>根据公共字段获取数据</li>
<li>拼接</li>
<li>写出</li>
</ol>
<p>MapJoinDriver.java</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.commons.lang3.StringUtils;</span><br><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.fs.Path;</span><br><span class="line">import org.apache.hadoop.io.IOUtils;</span><br><span class="line">import org.apache.hadoop.io.LongWritable;</span><br><span class="line">import org.apache.hadoop.io.NullWritable;</span><br><span class="line">import org.apache.hadoop.io.Text;</span><br><span class="line">import org.apache.hadoop.mapreduce.Job;</span><br><span class="line">import org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line">import java.io.BufferedReader;</span><br><span class="line">import java.io.FileInputStream;</span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.io.InputStreamReader;</span><br><span class="line">import java.net.URI;</span><br><span class="line">import java.util.HashMap;</span><br><span class="line">import java.util.Map;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">public class MapJoinDriver &#123;</span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        String BigTable = &quot;data/input/join/emp.txt&quot;;</span><br><span class="line">        String SmallTable = &quot;data/input/join/dept.txt&quot;;</span><br><span class="line">        String output = &quot;out&quot;;</span><br><span class="line"></span><br><span class="line">        Configuration configuration = new Configuration();</span><br><span class="line">        Job job = Job.getInstance(configuration);</span><br><span class="line">        job.setJarByClass(MapJoinDriver.class);</span><br><span class="line">        job.setMapperClass(MyMapper.class);</span><br><span class="line"></span><br><span class="line">		//MapJoin需要把ReduceTasks数量设置为0</span><br><span class="line">        job.setNumReduceTasks(0);</span><br><span class="line"></span><br><span class="line">        // reduce的个数决定了最终文件输出的个数，如果没有reduce，那么就由map个数决定</span><br><span class="line">        job.setMapOutputKeyClass(Info.class);</span><br><span class="line">        job.setMapOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">        // 小表加入到缓存中</span><br><span class="line">        job.addCacheFile(new URI(SmallTable));</span><br><span class="line"></span><br><span class="line">        FileInputFormat.setInputPaths(job, new Path(BigTable));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, new Path(output));</span><br><span class="line">        boolean result = job.waitForCompletion(true);</span><br><span class="line">        System.exit(result?0:1);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static class MyMapper extends Mapper&lt;LongWritable, Text, Info, NullWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">        Map&lt;String,String&gt; cache = new HashMap&lt;String, String&gt;();</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected void setup(Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">        </span><br><span class="line">        	//获取到缓存文件，是一个 URI 的数组</span><br><span class="line">            URI[] cacheFiles = context.getCacheFiles();</span><br><span class="line">            </span><br><span class="line">            //此处应该遍历cacheFiles获取缓存的文件，但此案例中只有一个文件，所以不影响。</span><br><span class="line">            //由于只有一个缓存文件dept.txt，我们这里只需要拿到第一个元素即可，获取到缓存文件的路径</span><br><span class="line">            String path = cacheFiles[0].getPath();</span><br><span class="line">            </span><br><span class="line">            //获取到bufferedReader对象（缓冲字符流）</span><br><span class="line">            BufferedReader reader = new BufferedReader(new InputStreamReader(new FileInputStream(path)));</span><br><span class="line"></span><br><span class="line">            // 10	ACCOUNTING	NEW YORK</span><br><span class="line">            //对每行数据做迭代，进行切割，切割后的数据放入到map中</span><br><span class="line">            String line;</span><br><span class="line">            while(StringUtils.isNotEmpty(line = reader.readLine())) &#123;</span><br><span class="line">                String[] splits = line.split(&quot;\t&quot;);</span><br><span class="line">                cache.put(splits[0].trim(), splits[1].trim());</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            //关闭资源</span><br><span class="line">            IOUtils.closeStream(reader);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">        	</span><br><span class="line">        	//读取emp.txt 的每行数据，并进行切割</span><br><span class="line">            String[] splits = value.toString().split(&quot;\t&quot;);</span><br><span class="line">            </span><br><span class="line">            //获取 deptno 公共字段</span><br><span class="line">            int empno = Integer.parseInt(splits[0].trim());</span><br><span class="line">            String ename = splits[1].trim();</span><br><span class="line">            int deptno = Integer.parseInt(splits[7].trim());</span><br><span class="line"></span><br><span class="line">            Info info = new Info();</span><br><span class="line">            info.setEmpno(empno);</span><br><span class="line">            info.setEname(ename);</span><br><span class="line">            info.setDeptno(deptno);</span><br><span class="line"></span><br><span class="line">            //大的数据每读一条，就和内存中的小的数据做比对</span><br><span class="line">            //根据deptno从map中获取到pname</span><br><span class="line">            info.setDname(cache.get(deptno+&quot;&quot;));</span><br><span class="line"></span><br><span class="line">            context.write(info, NullWritable.get());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="Reduce-Join"><a href="#Reduce-Join" class="headerlink" title="Reduce Join"></a>Reduce Join</h2><p>ReduceJoinDriver.java</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.fs.Path;</span><br><span class="line">import org.apache.hadoop.io.IntWritable;</span><br><span class="line">import org.apache.hadoop.io.LongWritable;</span><br><span class="line">import org.apache.hadoop.io.NullWritable;</span><br><span class="line">import org.apache.hadoop.io.Text;</span><br><span class="line">import org.apache.hadoop.mapreduce.Job;</span><br><span class="line">import org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line">import org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.input.FileSplit;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.util.ArrayList;</span><br><span class="line">import java.util.List;</span><br><span class="line"></span><br><span class="line">public class ReduceJoinDriver &#123;</span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        String input = &quot;data/input/join/&quot;;</span><br><span class="line">        String output = &quot;out&quot;;</span><br><span class="line"></span><br><span class="line">        Configuration configuration = new Configuration();</span><br><span class="line">        Job job = Job.getInstance(configuration);</span><br><span class="line">        job.setJarByClass(JoinDriver.class);</span><br><span class="line">        job.setMapperClass(MyMapper.class);</span><br><span class="line">        job.setReducerClass(MyReducer.class);</span><br><span class="line">        job.setMapOutputKeyClass(IntWritable.class);</span><br><span class="line">        job.setMapOutputValueClass(Info.class);</span><br><span class="line">        job.setOutputKeyClass(Info.class);</span><br><span class="line">        job.setOutputValueClass(NullWritable.class);</span><br><span class="line">        FileInputFormat.setInputPaths(job, new Path(input));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, new Path(output));</span><br><span class="line">        boolean result = job.waitForCompletion(true);</span><br><span class="line">        System.exit(result?0:1);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 我们join的条件是deptno，所以key的类型是IntWritable</span><br><span class="line">     *</span><br><span class="line">     * 我们是两个文件一起进来的</span><br><span class="line">     * 要区分出数据到底是emp的还是dept的</span><br><span class="line">     *</span><br><span class="line">     *在序列化类中没有的字段也要set</span><br><span class="line">     */</span><br><span class="line">    public static class MyMapper extends Mapper&lt;LongWritable, Text, IntWritable, Info&gt; &#123;</span><br><span class="line"></span><br><span class="line">        String name;//文件名称区别数据来源的</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected void setup(Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">            FileSplit fileSplit = (FileSplit) context.getInputSplit();</span><br><span class="line">            name = fileSplit.getPath().getName();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">            String[] splits = value.toString().split(&quot;\t&quot;);</span><br><span class="line">            if(name.contains(&quot;emp&quot;)) &#123; // 来自于emp</span><br><span class="line">                int empno = Integer.parseInt(splits[0].trim());</span><br><span class="line">                String ename = splits[1].trim();</span><br><span class="line">                int deptno = Integer.parseInt(splits[7].trim());</span><br><span class="line"></span><br><span class="line">                Info info = new Info();</span><br><span class="line">                info.setEmpno(empno);</span><br><span class="line">                info.setEname(ename);</span><br><span class="line">                info.setDeptno(deptno);</span><br><span class="line">                info.setDname(&quot;&quot;);</span><br><span class="line">                info.setFlag(1); // 标志位</span><br><span class="line"></span><br><span class="line">                context.write(new IntWritable(deptno), info);</span><br><span class="line">            &#125; else &#123;  // 来自于dept</span><br><span class="line">                int deptno = Integer.parseInt(splits[0].trim());</span><br><span class="line">                String dname = splits[1].trim();</span><br><span class="line"></span><br><span class="line">                Info info = new Info();</span><br><span class="line">                info.setEmpno(0);</span><br><span class="line">                info.setEname(&quot;&quot;);</span><br><span class="line">                info.setDeptno(deptno);</span><br><span class="line">                info.setDname(dname);</span><br><span class="line">                info.setFlag(2); // 标志位</span><br><span class="line">                context.write(new IntWritable(deptno), info);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static class MyReducer extends Reducer&lt;IntWritable, Info,Info, NullWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">        // key = deptno</span><br><span class="line">        @Override</span><br><span class="line">        protected void reduce(IntWritable key, Iterable&lt;Info&gt; values, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">            String dname = &quot;&quot;;</span><br><span class="line">            </span><br><span class="line">            //提供一种思路：更规范的写法应该是新增一个depts，拼接时遍历两个List</span><br><span class="line">            //但这里一个deptno是dept表的唯一主键，只对应一个dname，所以也没有问题</span><br><span class="line">            List&lt;Info&gt; emps = new ArrayList&lt;Info&gt;();</span><br><span class="line"></span><br><span class="line">            for(Info info : values) &#123;</span><br><span class="line">                if(info.getFlag() == 1) &#123;  // emp</span><br><span class="line">                    Info tmp = new Info();</span><br><span class="line">                    tmp.setEmpno(info.getEmpno());</span><br><span class="line">                    tmp.setEname(info.getEname());</span><br><span class="line">                    tmp.setDeptno(info.getDeptno());</span><br><span class="line">                    emps.add(tmp);</span><br><span class="line">                &#125; else if(info.getFlag() == 2) &#123;  // dept</span><br><span class="line">                    dname = info.getDname();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            for(Info bean : emps) &#123;</span><br><span class="line">                bean.setDname(dname);</span><br><span class="line">                context.write(bean, NullWritable.get());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>参考链接：</p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/shudonghe/p/3260201.html">hadoop 多表join：Map side join及Reduce side join范例</a></p>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/12/30/MapReduce%E6%94%AF%E6%8C%81%E9%80%92%E5%BD%92%E5%AD%90%E7%9B%AE%E5%BD%95%E4%BD%9C%E4%B8%BA%E8%BE%93%E5%85%A5/" rel="prev" title="MapReduce支持递归子目录作为输入">
                  <i class="fa fa-chevron-left"></i> MapReduce支持递归子目录作为输入
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/01/05/SQL-WHERE%E3%80%81ON%E3%80%81HAVING%E7%9A%84%E5%8C%BA%E5%88%AB/" rel="next" title="SQL:WHERE、ON、HAVING的区别">
                  SQL:WHERE、ON、HAVING的区别 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">k12</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  





</body>
</html>
