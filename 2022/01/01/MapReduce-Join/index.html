<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="概述   在传统数据库（如：MySql）中，JOIN操作常常是非常耗时的。而在HADOOP中进行JOIN操作，同样常见且耗时，由于Hadoop的独特设计思想，当进行JOIN操作时，有一些特殊的技巧。下面分别介绍MapReduce中的几种常见join，比如有最常见的 map side join，reduce side join，semi join（这些在Hive中都有） 等。Map side joi">
<meta property="og:type" content="article">
<meta property="og:title" content="MapReduce Join">
<meta property="og:url" content="https://k12coding.github.io/2022/01/01/MapReduce-Join/index.html">
<meta property="og:site_name" content="k12的博客">
<meta property="og:description" content="概述   在传统数据库（如：MySql）中，JOIN操作常常是非常耗时的。而在HADOOP中进行JOIN操作，同样常见且耗时，由于Hadoop的独特设计思想，当进行JOIN操作时，有一些特殊的技巧。下面分别介绍MapReduce中的几种常见join，比如有最常见的 map side join，reduce side join，semi join（这些在Hive中都有） 等。Map side joi">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-01-01T08:38:34.000Z">
<meta property="article:modified_time" content="2022-01-05T08:39:35.839Z">
<meta property="article:author" content="k12">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://k12coding.github.io/2022/01/01/MapReduce-Join/"/>





  <title>MapReduce Join | k12的博客</title>
  








<meta name="generator" content="Hexo 5.4.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">k12的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">k12的笔记</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://k12coding.github.io/2022/01/01/MapReduce-Join/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="k12的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">MapReduce Join</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2022-01-01T16:38:34+08:00">
                2022-01-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>   在传统数据库（如：MySql）中，JOIN操作常常是非常耗时的。而在HADOOP中进行JOIN操作，同样常见且耗时，由于Hadoop的独特设计思想，当进行JOIN操作时，有一些特殊的技巧。下面分别介绍MapReduce中的几种常见join，比如有最常见的 map side join，reduce side join，semi join（这些在Hive中都有） 等。Map side join在处理多个小表关联大表时非常有用，而 reduce join 在处理多表关联时是比较麻烦的，会造成大量的网络IO，效率低下，但在有些时候也是非常有用的。</p>
<span id="more"></span>

<h2 id="常见的join方法介绍"><a href="#常见的join方法介绍" class="headerlink" title="常见的join方法介绍"></a>常见的join方法介绍</h2><h3 id="map-side-join"><a href="#map-side-join" class="headerlink" title="map side join"></a>map side join</h3><p> Map side  join是针对以下场景进行的优化：两个待连接表中，有一个表非常大，而另一个表非常小，以至于小表可以直接存放到内存中。这样，我们可以将小表复制多份，让每个map task内存中存在一份（比如存放到hash table中），然后只扫描大表：对于大表中的每一条记录key/value，在hash  table中查找是否有相同的key的记录，如果有，则连接后输出即可。</p>
<p> 为了支持文件的复制，Hadoop提供了一个类DistributedCache，使用该类的方法如下：</p>
<p> （1）用户使用静态方法DistributedCache.addCacheFile()指定要复制的文件，它的参数是文件的URI（如果是HDFS上的文件，可以这样：hdfs://namenode:9000/home/XXX/file，其中9000是自己配置的NameNode端口号）。JobTracker在作业启动之前会获取这个URI列表，并将相应的文件拷贝到各个TaskTracker的本地磁盘上。</p>
<p>（2）用户使用DistributedCache.getLocalCacheFiles()方法获取文件目录，并使用标准的文件读写API读取相应的文件。</p>
<p><strong>补充:</strong></p>
<p>旧版本的DistributedCache和getLocalCacheFiles已经被注解为过时，本人下面案例中是<code>job.addCacheFile(new URI(SmallTable))</code>指定要复制的文件，<code>context.getCacheFiles()</code>获取文件目录。和getLocalCacheFiles不同的是，getCacheFiles得到的路径是HDFS上的文件路径，如果使用这个方法，那么程序中读取的就不再试缓存在各个节点上的数据了，相当于共同访问HDFS上的同一个文件。</p>
<p>main方法中设置缓存文件，而且Map Join不需要Reduce阶段，设置Reduce Task数量为0</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">job.addCacheFile(new URI(&quot;file:/你的文件路径));</span><br><span class="line">job.setNumReduceTasks(0);</span><br></pre></td></tr></table></figure>

<p>或者是HDFS上的URI</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.addCacheFile(new URI(&quot;hdfs://url:port/filename&quot;));</span><br></pre></td></tr></table></figure>

<p>在Mapper类的setup方法中加载缓存文件，setup方法，在maptask运行前只调用一次，可进行初始化工作。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">protected void setup(Context context)throws IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">    //获取缓存文件路径</span><br><span class="line">    URI[] cacheFiles = context.getCacheFiles();</span><br><span class="line">    //新的检索缓存文件的API是 context.getCacheFiles() ，而 context.getLocalCacheFiles() 被弃用</span><br><span class="line">    //然而 context.getCacheFiles() 返回的是 HDFS 路径； context.getLocalCacheFiles() 返回的才是本地路径</span><br><span class="line">    String path = cacheFiles[0].getPath();</span><br><span class="line">    </span><br><span class="line"> 	//读文件</span><br><span class="line">    BufferedReader reader = new BufferedReader(new InputStreamReader(new FileInputStream(path)));</span><br><span class="line"></span><br><span class="line">	String line;</span><br><span class="line"> 	while(StringUtils.isNotEmpty(line = reader.readLine())) &#123;</span><br><span class="line"> 		String[] splits = line.split(&quot;\t&quot;);</span><br><span class="line"> 		cache.put(splits[0].trim(), splits[1].trim());</span><br><span class="line"> 	&#125;</span><br><span class="line"></span><br><span class="line"> 	IOUtils.closeStream(reader);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>特点：</p>
<ul>
<li>Join操作在map task中完成，因此无需启动reduce task</li>
<li>适合一个大表，一个小表的连接操作</li>
</ul>
<p>局限性：</p>
<ul>
<li>有一份数据比较小，在map端，能够把它加载在内存，并进行join操作。</li>
</ul>
<h3 id="reduce-side-join"><a href="#reduce-side-join" class="headerlink" title="reduce side join"></a>reduce side join</h3><p> reduce side join是一种最简单的join方式， 之所以存在reduce side join，是因为在map阶段不能获取所有需要的join字段，即：同一个key对应的字段可能位于不同map中。Reduce  side join是非常低效的，因为shuffle阶段要进行大量的数据传输。</p>
<p> 假设要进行join的数据分别来自File1和File2.</p>
<p> 在map阶段，map函数同时读取两个文件File1和File2，为了区分两种来源的key/value数据对，对每条数据打一个标签（tag）,比如：tag=0表示来自文件File1，tag=2表示来自文件File2。即：map阶段的主要任务是对不同文件中的数据打标签。</p>
<p> 在reduce阶段，reduce函数获取key相同的来自File1和File2文件的value list，  然后对于同一个key，对File1和File2中的数据进行join（笛卡尔乘积）。即：reduce阶段进行实际的连接操作。</p>
<p>特点：</p>
<ul>
<li>Join操作在reduce task中完成</li>
<li>适合两个大表的连接操作</li>
</ul>
<p>局限性：</p>
<ul>
<li>map阶段没有对数据瘦身，shuffle的网络传输和排序性能很低。</li>
<li>reduce端对2个集合做乘积计算，很耗内存，容易导致OOM。</li>
</ul>
<h3 id="Semi-Join"><a href="#Semi-Join" class="headerlink" title="Semi Join"></a>Semi Join</h3><p> SemiJoin，也叫半连接，是从分布式数据库中借鉴过来的方法。它的产生动机是：对于reduce side  join，跨机器的数据传输量非常大，这成了join操作的一个瓶颈，如果能够在map端过滤掉不会参加join操作的数据，则可以大大节省网络IO。</p>
<p> 实现方法很简单：选取一个小表，假设是File1，将其参与join的key抽取出来，保存到文件File3中，File3文件一般很小，可以放到内存中。在map阶段，使用DistributedCache将File3复制到各个TaskTracker上，然后将File2中不在File3中的key对应的记录过滤掉，剩下的reduce阶段的工作与reducee  side join相同。</p>
<h3 id="reduce-side-join-BloomFilter"><a href="#reduce-side-join-BloomFilter" class="headerlink" title="reduce side join + BloomFilter"></a>reduce side join + BloomFilter</h3><p> 在某些情况下，Semi Join抽取出来的小表的key集合在内存中仍然存放不下，这时候可以使用BloomFiler以节省空间。</p>
<p> BloomFilter最常见的作用是：判断某个元素是否在一个集合里面。它最重要的两个方法是：add()  和contains()。最大的特点是不会存在false  negative，即：如果contains()返回false，则该元素一定不在集合中，但会存在一定的true  negative，即：如果contains()返回true，则该元素可能在集合中。</p>
<p> 因而可将小表中的key保存到BloomFilter中，在map阶段过滤大表，可能有一些不在小表中的记录没有过滤掉（但是在小表中的记录一定不会过滤掉），这没关系，只不过增加了少量的网络IO而已。</p>
<p>Hadoop面试的时候也会问到 Hadoop上Join的实现，几乎是一道必问的问题，而极个别公司还会涉及到DistributedCache原理以及怎样利用DistributedCache进行Join操作。</p>
<h1 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h1><h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><p>data/input/join/emp.txt</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">7369    SMITH  CLERK  7902   1980-12-17 800.00    20</span><br><span class="line">7499   ALLEN  SALESMAN   7698   1981-2-20  1600.00    300.00 30</span><br><span class="line">7521   WARD   SALESMAN   7698   1981-2-22  1250.00    500.00 30</span><br><span class="line">7566   JONES  MANAGER    7839   1981-4-2   2975.00       20</span><br><span class="line">7654   MARTIN SALESMAN   7698   1981-9-28  1250.00    1400.00    30</span><br><span class="line">7698   BLAKE  MANAGER    7839   1981-5-1   2850.00       30</span><br><span class="line">7782   CLARK  MANAGER    7839   1981-6-9   2450.00       10</span><br><span class="line">7788   SCOTT  ANALYST    7566   1987-4-19  3000.00       20</span><br><span class="line">7839   KING   PRESIDENT     1981-11-17 5000.00       10</span><br><span class="line">7844   TURNER SALESMAN   7698   1981-9-8   1500.00    0.00   30</span><br><span class="line">7876   ADAMS  CLERK  7788   1987-5-23  1100.00       20</span><br><span class="line">7900   JAMES  CLERK  7698   1981-12-3  950.00    30</span><br><span class="line">7902   FORD   ANALYST    7566   1981-12-3  3000.00       20</span><br><span class="line">7934   MILLER CLERK  7782   1982-1-23  1300.00       10</span><br></pre></td></tr></table></figure>

<p>data/input/join/dept.txt</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">10	ACCOUNTING	NEW YORK</span><br><span class="line">20	RESEARCH	DALLAS</span><br><span class="line">30	SALES	CHICAGO</span><br><span class="line">40	OPERATIONS	BOSTON</span><br></pre></td></tr></table></figure>

<h2 id="自定义序列化类"><a href="#自定义序列化类" class="headerlink" title="自定义序列化类"></a>自定义序列化类</h2><p>info.java</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.hadoop.io.Writable;</span><br><span class="line">import java.io.DataInput;</span><br><span class="line">import java.io.DataOutput;</span><br><span class="line">import java.io.IOException;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * join结果最终需要的字段</span><br><span class="line"> */</span><br><span class="line">public class Info implements Writable &#123;</span><br><span class="line"></span><br><span class="line">    private int empno;</span><br><span class="line">    private String ename;</span><br><span class="line">    private int deptno;</span><br><span class="line">    private String dname;</span><br><span class="line">    private int flag;  // 标志位：用来区分数据来自于哪个表.mapjoin不需要flag，需要注释掉flag</span><br><span class="line"></span><br><span class="line">    public void write(DataOutput out) throws IOException &#123;</span><br><span class="line">        out.writeInt(empno);</span><br><span class="line">        out.writeUTF(ename);</span><br><span class="line">        out.writeInt(deptno);</span><br><span class="line">        out.writeUTF(dname);</span><br><span class="line">        out.writeInt(flag);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void readFields(DataInput in) throws IOException &#123;</span><br><span class="line">        this.empno = in.readInt();</span><br><span class="line">        this.ename = in.readUTF();</span><br><span class="line">        this.deptno = in.readInt();</span><br><span class="line">        this.dname = in.readUTF();</span><br><span class="line">        this.flag = in.readInt();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public Info() &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public Info(int empno, String ename, int deptno, String dname) &#123;</span><br><span class="line">        this.empno = empno;</span><br><span class="line">        this.ename = ename;</span><br><span class="line">        this.deptno = deptno;</span><br><span class="line">        this.dname = dname;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public Info(int empno, String ename, int deptno, String dname, int flag) &#123;</span><br><span class="line">        this.empno = empno;</span><br><span class="line">        this.ename = ename;</span><br><span class="line">        this.deptno = deptno;</span><br><span class="line">        this.dname = dname;</span><br><span class="line">        this.flag = flag;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public String toString() &#123;</span><br><span class="line">        return empno + &quot;\t&quot; + ename + &quot;\t&quot; + deptno + &quot;\t&quot; + dname;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public int getEmpno() &#123;</span><br><span class="line">        return empno;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void setEmpno(int empno) &#123;</span><br><span class="line">        this.empno = empno;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public String getEname() &#123;</span><br><span class="line">        return ename;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void setEname(String ename) &#123;</span><br><span class="line">        this.ename = ename;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public int getDeptno() &#123;</span><br><span class="line">        return deptno;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void setDeptno(int deptno) &#123;</span><br><span class="line">        this.deptno = deptno;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public String getDname() &#123;</span><br><span class="line">        return dname;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void setDname(String dname) &#123;</span><br><span class="line">        this.dname = dname;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public int getFlag() &#123;</span><br><span class="line">        return flag;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void setFlag(int flag) &#123;</span><br><span class="line">        this.flag = flag;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="Map-Join"><a href="#Map-Join" class="headerlink" title="Map Join"></a>Map Join</h2><p>main()：</p>
<ul>
<li>加载缓存数据：<code>job.addCacheFile(new URI(&quot;file:/你的文件路径))</code>或者<code>job.addCacheFile(new URI(&quot;hdfs://url:port/filename&quot;));</code></li>
<li>设置Reduce Task数量为0：<code>job.setNumReduceTasks(0);</code></li>
</ul>
<p>setup():</p>
<ol>
<li>获取缓存的文件</li>
<li>循环读取缓存文件的每一行</li>
<li>切割</li>
<li>缓存数据到集合hashtable</li>
<li>关闭资源</li>
</ol>
<p>map():</p>
<ol>
<li>获取一行数据</li>
<li>截取</li>
<li>根据公共字段获取数据</li>
<li>拼接</li>
<li>写出</li>
</ol>
<p>MapJoinDriver.java</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.commons.lang3.StringUtils;</span><br><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.fs.Path;</span><br><span class="line">import org.apache.hadoop.io.IOUtils;</span><br><span class="line">import org.apache.hadoop.io.LongWritable;</span><br><span class="line">import org.apache.hadoop.io.NullWritable;</span><br><span class="line">import org.apache.hadoop.io.Text;</span><br><span class="line">import org.apache.hadoop.mapreduce.Job;</span><br><span class="line">import org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line">import java.io.BufferedReader;</span><br><span class="line">import java.io.FileInputStream;</span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.io.InputStreamReader;</span><br><span class="line">import java.net.URI;</span><br><span class="line">import java.util.HashMap;</span><br><span class="line">import java.util.Map;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">public class MapJoinDriver &#123;</span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        String BigTable = &quot;data/input/join/emp.txt&quot;;</span><br><span class="line">        String SmallTable = &quot;data/input/join/dept.txt&quot;;</span><br><span class="line">        String output = &quot;out&quot;;</span><br><span class="line"></span><br><span class="line">        Configuration configuration = new Configuration();</span><br><span class="line">        Job job = Job.getInstance(configuration);</span><br><span class="line">        job.setJarByClass(MapJoinDriver.class);</span><br><span class="line">        job.setMapperClass(MyMapper.class);</span><br><span class="line"></span><br><span class="line">		//MapJoin需要把ReduceTasks数量设置为0</span><br><span class="line">        job.setNumReduceTasks(0);</span><br><span class="line"></span><br><span class="line">        // reduce的个数决定了最终文件输出的个数，如果没有reduce，那么就由map个数决定</span><br><span class="line">        job.setMapOutputKeyClass(Info.class);</span><br><span class="line">        job.setMapOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">        // 小表加入到缓存中</span><br><span class="line">        job.addCacheFile(new URI(SmallTable));</span><br><span class="line"></span><br><span class="line">        FileInputFormat.setInputPaths(job, new Path(BigTable));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, new Path(output));</span><br><span class="line">        boolean result = job.waitForCompletion(true);</span><br><span class="line">        System.exit(result?0:1);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static class MyMapper extends Mapper&lt;LongWritable, Text, Info, NullWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">        Map&lt;String,String&gt; cache = new HashMap&lt;String, String&gt;();</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected void setup(Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">        </span><br><span class="line">        	//获取到缓存文件，是一个 URI 的数组</span><br><span class="line">            URI[] cacheFiles = context.getCacheFiles();</span><br><span class="line">            </span><br><span class="line">            //此处应该遍历cacheFiles获取缓存的文件，但此案例中只有一个文件，所以不影响。</span><br><span class="line">            //由于只有一个缓存文件dept.txt，我们这里只需要拿到第一个元素即可，获取到缓存文件的路径</span><br><span class="line">            String path = cacheFiles[0].getPath();</span><br><span class="line">            </span><br><span class="line">            //获取到bufferedReader对象（缓冲字符流）</span><br><span class="line">            BufferedReader reader = new BufferedReader(new InputStreamReader(new FileInputStream(path)));</span><br><span class="line"></span><br><span class="line">            // 10	ACCOUNTING	NEW YORK</span><br><span class="line">            //对每行数据做迭代，进行切割，切割后的数据放入到map中</span><br><span class="line">            String line;</span><br><span class="line">            while(StringUtils.isNotEmpty(line = reader.readLine())) &#123;</span><br><span class="line">                String[] splits = line.split(&quot;\t&quot;);</span><br><span class="line">                cache.put(splits[0].trim(), splits[1].trim());</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            //关闭资源</span><br><span class="line">            IOUtils.closeStream(reader);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">        	</span><br><span class="line">        	//读取emp.txt 的每行数据，并进行切割</span><br><span class="line">            String[] splits = value.toString().split(&quot;\t&quot;);</span><br><span class="line">            </span><br><span class="line">            //获取 deptno 公共字段</span><br><span class="line">            int empno = Integer.parseInt(splits[0].trim());</span><br><span class="line">            String ename = splits[1].trim();</span><br><span class="line">            int deptno = Integer.parseInt(splits[7].trim());</span><br><span class="line"></span><br><span class="line">            Info info = new Info();</span><br><span class="line">            info.setEmpno(empno);</span><br><span class="line">            info.setEname(ename);</span><br><span class="line">            info.setDeptno(deptno);</span><br><span class="line"></span><br><span class="line">            //大的数据每读一条，就和内存中的小的数据做比对</span><br><span class="line">            //根据deptno从map中获取到pname</span><br><span class="line">            info.setDname(cache.get(deptno+&quot;&quot;));</span><br><span class="line"></span><br><span class="line">            context.write(info, NullWritable.get());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="Reduce-Join"><a href="#Reduce-Join" class="headerlink" title="Reduce Join"></a>Reduce Join</h2><p>ReduceJoinDriver.java</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.fs.Path;</span><br><span class="line">import org.apache.hadoop.io.IntWritable;</span><br><span class="line">import org.apache.hadoop.io.LongWritable;</span><br><span class="line">import org.apache.hadoop.io.NullWritable;</span><br><span class="line">import org.apache.hadoop.io.Text;</span><br><span class="line">import org.apache.hadoop.mapreduce.Job;</span><br><span class="line">import org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line">import org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.input.FileSplit;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.util.ArrayList;</span><br><span class="line">import java.util.List;</span><br><span class="line"></span><br><span class="line">public class ReduceJoinDriver &#123;</span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        String input = &quot;data/input/join/&quot;;</span><br><span class="line">        String output = &quot;out&quot;;</span><br><span class="line"></span><br><span class="line">        Configuration configuration = new Configuration();</span><br><span class="line">        Job job = Job.getInstance(configuration);</span><br><span class="line">        job.setJarByClass(JoinDriver.class);</span><br><span class="line">        job.setMapperClass(MyMapper.class);</span><br><span class="line">        job.setReducerClass(MyReducer.class);</span><br><span class="line">        job.setMapOutputKeyClass(IntWritable.class);</span><br><span class="line">        job.setMapOutputValueClass(Info.class);</span><br><span class="line">        job.setOutputKeyClass(Info.class);</span><br><span class="line">        job.setOutputValueClass(NullWritable.class);</span><br><span class="line">        FileInputFormat.setInputPaths(job, new Path(input));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, new Path(output));</span><br><span class="line">        boolean result = job.waitForCompletion(true);</span><br><span class="line">        System.exit(result?0:1);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 我们join的条件是deptno，所以key的类型是IntWritable</span><br><span class="line">     *</span><br><span class="line">     * 我们是两个文件一起进来的</span><br><span class="line">     * 要区分出数据到底是emp的还是dept的</span><br><span class="line">     *</span><br><span class="line">     *在序列化类中没有的字段也要set</span><br><span class="line">     */</span><br><span class="line">    public static class MyMapper extends Mapper&lt;LongWritable, Text, IntWritable, Info&gt; &#123;</span><br><span class="line"></span><br><span class="line">        String name;//文件名称区别数据来源的</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected void setup(Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">            FileSplit fileSplit = (FileSplit) context.getInputSplit();</span><br><span class="line">            name = fileSplit.getPath().getName();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">            String[] splits = value.toString().split(&quot;\t&quot;);</span><br><span class="line">            if(name.contains(&quot;emp&quot;)) &#123; // 来自于emp</span><br><span class="line">                int empno = Integer.parseInt(splits[0].trim());</span><br><span class="line">                String ename = splits[1].trim();</span><br><span class="line">                int deptno = Integer.parseInt(splits[7].trim());</span><br><span class="line"></span><br><span class="line">                Info info = new Info();</span><br><span class="line">                info.setEmpno(empno);</span><br><span class="line">                info.setEname(ename);</span><br><span class="line">                info.setDeptno(deptno);</span><br><span class="line">                info.setDname(&quot;&quot;);</span><br><span class="line">                info.setFlag(1); // 标志位</span><br><span class="line"></span><br><span class="line">                context.write(new IntWritable(deptno), info);</span><br><span class="line">            &#125; else &#123;  // 来自于dept</span><br><span class="line">                int deptno = Integer.parseInt(splits[0].trim());</span><br><span class="line">                String dname = splits[1].trim();</span><br><span class="line"></span><br><span class="line">                Info info = new Info();</span><br><span class="line">                info.setEmpno(0);</span><br><span class="line">                info.setEname(&quot;&quot;);</span><br><span class="line">                info.setDeptno(deptno);</span><br><span class="line">                info.setDname(dname);</span><br><span class="line">                info.setFlag(2); // 标志位</span><br><span class="line">                context.write(new IntWritable(deptno), info);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static class MyReducer extends Reducer&lt;IntWritable, Info,Info, NullWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">        // key = deptno</span><br><span class="line">        @Override</span><br><span class="line">        protected void reduce(IntWritable key, Iterable&lt;Info&gt; values, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">            String dname = &quot;&quot;;</span><br><span class="line">            </span><br><span class="line">            //提供一种思路：更规范的写法应该是新增一个depts，拼接时遍历两个List</span><br><span class="line">            //但这里一个deptno是dept表的唯一主键，只对应一个dname，所以也没有问题</span><br><span class="line">            List&lt;Info&gt; emps = new ArrayList&lt;Info&gt;();</span><br><span class="line"></span><br><span class="line">            for(Info info : values) &#123;</span><br><span class="line">                if(info.getFlag() == 1) &#123;  // emp</span><br><span class="line">                    Info tmp = new Info();</span><br><span class="line">                    tmp.setEmpno(info.getEmpno());</span><br><span class="line">                    tmp.setEname(info.getEname());</span><br><span class="line">                    tmp.setDeptno(info.getDeptno());</span><br><span class="line">                    emps.add(tmp);</span><br><span class="line">                &#125; else if(info.getFlag() == 2) &#123;  // dept</span><br><span class="line">                    dname = info.getDname();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            for(Info bean : emps) &#123;</span><br><span class="line">                bean.setDname(dname);</span><br><span class="line">                context.write(bean, NullWritable.get());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>参考链接：</p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/shudonghe/p/3260201.html">hadoop 多表join：Map side join及Reduce side join范例</a></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2021/12/30/MapReduce%E6%94%AF%E6%8C%81%E9%80%92%E5%BD%92%E5%AD%90%E7%9B%AE%E5%BD%95%E4%BD%9C%E4%B8%BA%E8%BE%93%E5%85%A5/" rel="next" title="MapReduce支持递归子目录作为输入">
                <i class="fa fa-chevron-left"></i> MapReduce支持递归子目录作为输入
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2022/01/05/SQL-WHERE%E3%80%81ON%E3%80%81HAVING%E7%9A%84%E5%8C%BA%E5%88%AB/" rel="prev" title="SQL:WHERE、ON、HAVING的区别">
                SQL:WHERE、ON、HAVING的区别 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">62</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A6%82%E8%BF%B0"><span class="nav-number">1.</span> <span class="nav-text">概述</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B8%B8%E8%A7%81%E7%9A%84join%E6%96%B9%E6%B3%95%E4%BB%8B%E7%BB%8D"><span class="nav-number">1.1.</span> <span class="nav-text">常见的join方法介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#map-side-join"><span class="nav-number">1.1.1.</span> <span class="nav-text">map side join</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#reduce-side-join"><span class="nav-number">1.1.2.</span> <span class="nav-text">reduce side join</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Semi-Join"><span class="nav-number">1.1.3.</span> <span class="nav-text">Semi Join</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#reduce-side-join-BloomFilter"><span class="nav-number">1.1.4.</span> <span class="nav-text">reduce side join + BloomFilter</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90"><span class="nav-number">2.</span> <span class="nav-text">案例分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87"><span class="nav-number">2.1.</span> <span class="nav-text">数据准备</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%BA%8F%E5%88%97%E5%8C%96%E7%B1%BB"><span class="nav-number">2.2.</span> <span class="nav-text">自定义序列化类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Map-Join"><span class="nav-number">2.3.</span> <span class="nav-text">Map Join</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reduce-Join"><span class="nav-number">2.4.</span> <span class="nav-text">Reduce Join</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">k12</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
