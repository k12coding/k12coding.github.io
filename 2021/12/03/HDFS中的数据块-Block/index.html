<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="我们在分布式存储原理总结中了解了分布式存储的三大特点：  数据分块，分布式的存储在多台机器上 数据块冗余存储在多台机器以提高数据块的高可用性 遵从主&#x2F;从(master&#x2F;slave)结构的分布式存储集群  HDFS作为分布式存储的实现，肯定也具有上面3个特点。">
<meta property="og:type" content="article">
<meta property="og:title" content="HDFS中的数据块(Block)">
<meta property="og:url" content="https://k12coding.github.io/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/index.html">
<meta property="og:site_name" content="k12的博客">
<meta property="og:description" content="我们在分布式存储原理总结中了解了分布式存储的三大特点：  数据分块，分布式的存储在多台机器上 数据块冗余存储在多台机器以提高数据块的高可用性 遵从主&#x2F;从(master&#x2F;slave)结构的分布式存储集群  HDFS作为分布式存储的实现，肯定也具有上面3个特点。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://k12coding.github.io/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193738768-2015006415.png">
<meta property="og:image" content="https://k12coding.github.io/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193745301-961787885.png">
<meta property="og:image" content="https://k12coding.github.io/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193756443-722084406.png">
<meta property="og:image" content="https://k12coding.github.io/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193801770-1600366947.png">
<meta property="og:image" content="https://k12coding.github.io/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193806888-1561633390.png">
<meta property="og:image" content="https://k12coding.github.io/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193841533-1801289433.png">
<meta property="og:image" content="https://k12coding.github.io/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193847536-1876269159.png">
<meta property="og:image" content="https://k12coding.github.io/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193851762-2045344208.png">
<meta property="og:image" content="https://k12coding.github.io/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193921505-989550889.png">
<meta property="og:image" content="https://k12coding.github.io/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193930783-1441983482.png">
<meta property="og:image" content="https://k12coding.github.io/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193941684-2013773685.png">
<meta property="article:published_time" content="2021-12-02T17:30:07.000Z">
<meta property="article:modified_time" content="2021-12-14T11:57:20.253Z">
<meta property="article:author" content="k12">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://k12coding.github.io/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193738768-2015006415.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://k12coding.github.io/2021/12/03/HDFS中的数据块-Block/"/>





  <title>HDFS中的数据块(Block) | k12的博客</title>
  








<meta name="generator" content="Hexo 5.4.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">k12的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">k12的笔记</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://k12coding.github.io/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="k12的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">HDFS中的数据块(Block)</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-12-03T01:30:07+08:00">
                2021-12-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>我们在分布式存储原理总结中了解了分布式存储的三大特点：</p>
<ol>
<li>数据分块，分布式的存储在多台机器上</li>
<li>数据块冗余存储在多台机器以提高数据块的高可用性</li>
<li>遵从主/从(master/slave)结构的分布式存储集群</li>
</ol>
<p>HDFS作为分布式存储的实现，肯定也具有上面3个特点。</p>
<span id="more"></span>

<h2 id="HDFS数据块"><a href="#HDFS数据块" class="headerlink" title="HDFS数据块"></a>HDFS数据块</h2><p>与一般文件系统一样，HDFS也有块（block）的概念，HDFS上的文件也被划分为块大小的多个分块作为独立的存储单元。与通常的磁盘文件系统不同的是：</p>
<p><strong>HDFS中小于一个块大小的文件不会占据整个块的空间（当一个1MB的文件存储在一个128MB的块中时，文件只使用1MB的磁盘空间，而不是128MB）</strong></p>
<p>在Hadoop1当中，文件的block块默认大小是64M，Hadoop2当中，文件的block块大小默认是128M，block块的大小可以通过<code>hdfs-site.xml</code>当中的配置文件（dfs.block.size）进行指定。</p>
<p><strong>设置数据块的好处</strong></p>
<p>（1）一个文件的大小可以大于集群任意节点磁盘的容量</p>
<p>（2）容易对数据进行备份，提高容错能力</p>
<p>（3）使用抽象块概念而非整个文件作为存储单元，大大简化存储子系统的设计</p>
<p><strong>块缓存</strong><br>通常DataNode从磁盘中读取块，但对于访问频繁的文件，其对应的块可能被显示的缓存在DataNode的内存中，以堆外块缓存的形式存在。默认情况下，一个块仅缓存在一个DataNode的内存中，当然可以针对每个文件配置DataNode的数量。作业调度器通过在缓存块的DataNode上运行任务，可以利用块缓存的优势提高读操作的性能。</p>
<h2 id="HDFS分布式存储"><a href="#HDFS分布式存储" class="headerlink" title="HDFS分布式存储"></a>HDFS分布式存储</h2><p>在HDFS中，数据块默认的大小是128M，当我们往HDFS上上传一个300多M的文件的时候，那么这个文件会被分成3个数据块： </p>
<p><img src="/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193738768-2015006415.png" alt="img"></p>
<p><img src="/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193745301-961787885.png" alt="img"></p>
<p> 所有的数据块是分布式的存储在所有的DataNode上：</p>
<p><img src="/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193756443-722084406.png" alt="img"></p>
<p><img src="/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193801770-1600366947.png" alt="img"></p>
<p><img src="/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193806888-1561633390.png" alt="img"></p>
<p>为了提高每一个数据块的高可用性，在HDFS中每一个数据块默认备份存储3份，在这里我们看到的只有1份，是因为我们在<code>hdfs-site.xml</code>中配置了如下的配置：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;1&lt;/value&gt;</span><br><span class="line">	&lt;description&gt;表示数据块的备份数量，不能大于DataNode的数量，默认值是3&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<p>我们也可以通过如下的命令，将文件<code>/user/hadoop-twq/cmd/big_file.txt</code>的所有的数据块都备份存储3份：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -setrep 3 /user/hadoop-twq/cmd/big_file.txt</span><br></pre></td></tr></table></figure>

<p>我们可以从如下可以看出：每一个数据块都冗余存储了3个备份</p>
<p><img src="/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193841533-1801289433.png" alt="img"> </p>
<p><img src="/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193847536-1876269159.png" alt="img"></p>
<p> <img src="/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193851762-2045344208.png" alt="img"></p>
<p><strong>在这里，可能会问这里为什么看到的是2个备份呢？这个是因为我们的集群只有2个DataNode，所以最多只有2个备份，即使你设置成3个备份也没用，所以我们设置的备份数一般都是比集群的DataNode的个数相等或者要少</strong></p>
<blockquote>
<p>一定要注意：当我们上传362.4MB的数据到HDFS上后，如果数据块的备份数是3个话，那么在HDFS上真正存储的数据量大小是：362.4MB * 3 = 1087.2MB</p>
</blockquote>
<blockquote>
<p>注意：我们上面是通过HDFS的WEB UI来查看HDFS文件的数据块的信息，除了这种方式查看数据块的信息，我们还可以通过命令fsck来查看</p>
</blockquote>
<h2 id="问题：HDFS里面为什么一般设置块大小为64MB或128MB？"><a href="#问题：HDFS里面为什么一般设置块大小为64MB或128MB？" class="headerlink" title="问题：HDFS里面为什么一般设置块大小为64MB或128MB？"></a>问题：HDFS里面为什么一般设置块大小为64MB或128MB？</h2><ul>
<li><p>为什么不能远少于64MB？</p>
<p>（1）<strong>减少硬盘寻道时间。</strong>HDFS设计前提是应对大数据量操作，若数据块大小设置过小，那需要读取的数据块数量就会增多，从而间接增加底层硬盘的寻道时间</p>
<blockquote>
<p>  “HDFS的块比磁盘块大，其目的是为了最小化寻址开销。如果块设置得足够大，从<strong>磁盘传输数据的时间</strong>可以明显大于<strong>定位这个块开始位置所需的时间</strong>。这样，传输一个由多个块组成的文件的时间就<strong>取决于磁盘传输速率</strong>。”</p>
<p> “我们做一个估计计算，如果寻址时间为10ms左右，而传输速率为100MB/s，为了使寻址时间仅占传输时间的1%，我们需要设置块大小为100MB左右。而默认的块大小实际为64MB，但是很多情况下HDFS使用128MB的块设置。<strong>以后随着新一代磁盘驱动器传输速率的提升，块的大小将被设置得更大。</strong>”</p>
</blockquote>
<p>（2）<strong>减少NameNode内存消耗。</strong>由于NameNode记录着DataNode中的数据块信息，若数据块大小设置过小，则数据块数量增多，需要维护的数据块信息就会增多，从而消耗NameNode的内存。</p>
</li>
<li><p>为什么不能远大于64MB？</p>
<p>原因主要从上层的MapReduce框架来寻找。</p>
<p>（1）<strong>Map崩溃问题。</strong>系统需要重新启动，启动过程中需要重新加载数据，数据块越大，数据加载时间越长，系统恢复过程越长</p>
<p>（2）<strong>监管时间问题。</strong>主节点监管其他节点的情况，每个节点会周期性的与主节点进行汇报通信。倘若某一个节点保持沉默的时间超过一个<strong>预设的时间间隔</strong>，主节点会记录这个节点状态为死亡，并将该节点的数据转发给别的节点。而这个“预设时间间隔”是从数据块的角度大致估算的。（加入对64MB的数据块，我可以假设你10分钟之内无论如何也能解决完了吧，超过10分钟还没反应，那我就认为你出故障或已经死了。）64MB大小的数据块，其时间尚可较为精准地估计，如果我将数据块大小设为640MB甚至上G，那这个“预设的时间间隔”便不好估算，估长估短对系统都会造成不必要的损失和资源浪费。</p>
<p>（3）<strong>问题分解问题。</strong>数据量的大小与问题解决的复杂度呈线性关系。对于同一个算法，处理的数据量越大，时间复杂度越高。</p>
<p>（4）<strong>约束Map输出。</strong>在Map Reduce框架里，Map之后的数据是要经过排序才执行Reduce操作的。这通常涉及到归并排序，而归并排序的算法思想便是“对小文件进行排序，然后将小文件归并成大文件”，因此“小文件”不宜过大。</p>
<blockquote>
<p>“<strong>但是，该参数也不会设置得过大。MapReduce中的map任务通常一次处理一个块中的数据，因此，如果任务数太少（少于集群中的节点数量），作业的运行速度就会变慢。</strong>”</p>
</blockquote>
</li>
</ul>
<h2 id="数据块的实现"><a href="#数据块的实现" class="headerlink" title="数据块的实现"></a>数据块的实现</h2><p>在HDFS的实现中，数据块被抽象成类<code>org.apache.hadoop.hdfs.protocol.Block(我们以下简称Block)</code>。在Block类中有如下几个属性字段：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Block</span> <span class="keyword">implements</span> <span class="title">Writable</span>, <span class="title">Comparable</span>&lt;<span class="title">Block</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> blockId; <span class="comment">// 标识一个Block的唯一Id</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> numBytes; <span class="comment">// Block的大小(单位是字节)</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> generationStamp; <span class="comment">// Block的生成时间戳</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们从WEB UI上的数据块信息也可以看到：</p>
<p><img src="/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193921505-989550889.png" alt="img"></p>
<p> 一个Block除了存储上面的3个字段信息，还需要知道这个Block含有多少个备份，每一个备份分别存储在哪一个DataNode上，为了存储这些信息，HDFS中有一个名为</p>
<p><code>org.apache.hadoop.hdfs.server.blockmanagement.BlockInfoContiguous</code>(下面我们简称为BlockInfo)</p>
<p>的类来存储这些信息，这个BlockInfo类继承Block类，如下：</p>
<p><img src="/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193930783-1441983482.png" alt="img"></p>
<p>BlockInfo类中只有一个非常核心的属性，就是名为triplets的数组，这个数组的长度是<code>3*replication</code>，<code>replication</code>表示数据块的备份数。这个数组中存储了该数据块所有的备份数据块对应的DataNode信息，我们现在假设备份数是<code>3</code>，那么这个数组的长度是<code>3*3=9</code>，这个数组存储的数据如下： </p>
<p><img src="/2021/12/03/HDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9D%97-Block/1598893-20190908193941684-2013773685.png" alt="img"></p>
<p>也就是说，triplets包含的信息：</p>
<ul>
<li>triplets[i]：Block所在的DataNode；</li>
<li>triplets[i+1]：该DataNode上前一个Block；</li>
<li>triplets[i+2]：该DataNode上后一个Block；</li>
</ul>
<p>其中i表示的是Block的第i个副本，i取值[0,replication)。</p>
<p>我们在HDFS的NameNode中的Namespace管理中讲到了，一个HDFS文件包含一个BlockInfo数组，表示这个文件分成的若干个数据块，这个BlockInfo数组实际上就是我们这里说的<code>BlockInfoContiguous</code>数组。以下是INodeFile的属性：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">INodeFile</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> header = <span class="number">0L</span>; <span class="comment">// 用于标识存储策略ID、副本数和数据块大小的信息</span></span><br><span class="line">    <span class="keyword">private</span> BlockInfoContiguous[] blocks; <span class="comment">// 该文件包含的数据块数组</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>那么，到现在为止，我们了解到了这些信息：文件包含了哪些Block，这些Block分别被实际存储在哪些DataNode上，DataNode上所有Block前后链表关系。</p>
<p>如果从信息完整度来看，以上信息数据足够支持所有关于HDFS文件系统的正常操作，但还存在一个使用场景较多的问题：怎样通过blockId快速定位BlockInfo？</p>
<p>我们其实可以在NameNode上用一个HashMap来维护blockId到Block的映射，也就是说我们可以使用<code>HashMap&lt;Block, BlockInfo&gt;</code>来维护，这样的话我们就可以快速的根据blockId定位BlockInfo，但是由于在内存使用、碰撞冲突解决和性能等方面存在问题，Hadoop团队之后使用重新实现的LightWeightGSet代替HashMap，该数据结构本质上也是利用链表解决碰撞冲突的<a target="_blank" rel="noopener" href="https://issues.apache.org/jira/browse/HDFS-1114">HashTable</a>，但是在易用性、内存占用和性能等方面表现更好。</p>
<p>HDFS为了解决通过blockId快速定位BlockInfo的问题，所以引入了BlocksMap，BlocksMap底层通过LightWeightGSet实现。</p>
<p>在HDFS集群启动过程，DataNode会进行BR（BlockReport，其实就是将DataNode自身存储的数据块上报给NameNode），根据BR的每一个Block计算其HashCode，之后将对应的BlockInfo插入到相应位置逐渐构建起来巨大的BlocksMap。前面在INodeFile里也提到的BlockInfo集合，如果我们将BlocksMap里的BlockInfo与所有INodeFile里的BlockInfo分别收集起来，可以发现两个集合完全相同，事实上BlocksMap里所有的BlockInfo就是INodeFile中对应BlockInfo的引用；通过Block查找对应BlockInfo时，也是先对Block计算HashCode，根据结果快速定位到对应的BlockInfo信息。至此涉及到HDFS文件系统本身元数据的问题基本上已经解决了。</p>
<h2 id="BlocksMap内存估算"><a href="#BlocksMap内存估算" class="headerlink" title="BlocksMap内存估算"></a>BlocksMap内存估算</h2><p>HDFS将文件按照一定的大小切成多个Block，为了保证数据可靠性，每个Block对应多个副本，存储在不同DataNode上。NameNode除需要维护Block本身的信息外，还需要维护从Block到DataNode列表的对应关系，用于描述每一个Block副本实际存储的物理位置，BlocksMap结构即用于Block到DataNode列表的映射关系，BlocksMap是常驻在内存中，而且占用内存非常大，所以对BlocksMap进行内存的估算是非常有必要的。</p>
<p><strong>BlocksMap</strong>的内部结构：</p>
<blockquote>
<p>以下的内存估算是在64位操作系统上且没有开启指针压缩功能场景下</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">class BlocksMap &#123;</span><br><span class="line">    private final int capacity; // 占 4 字节</span><br><span class="line">    // 我们使用GSet的实现者：LightWeightGSet</span><br><span class="line">    private GSet&lt;Block, BlockInfoContiguous&gt; blocks;  // 引用类型占8字节</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以得出BlocksMap的直接内存大小是：<strong>对象头16字节 + 4字节 + 8字节 = 28字节</strong></p>
<p><strong>Block</strong>的结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public class Block implements Writable, Comparable&lt;Block&gt; &#123;</span><br><span class="line">    private long blockId; // 标识一个Block的唯一Id     占 8字节</span><br><span class="line">    private long numBytes; // Block的大小(单位是字节)   占 8字节</span><br><span class="line">    private long generationStamp; // Block的生成时间戳   占 8字节</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以得出Block的直接内存大小是：<strong>对象头16字节 + 8字节 + 8字节 + 8字节 = 40字节</strong></p>
<p><strong>BlockInfoContiguous</strong>的结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public class BlockInfoContiguous extends Block &#123;</span><br><span class="line">    private BlockCollection bc;   // 引用类型占8字节</span><br><span class="line">    private LightWeightGSet.LinkedElement nextLinkedElement;  // 引用类型占8字节</span><br><span class="line">    private Object[] triplets;  // 引用类型 8字节 + 数组对象头24字节 + 3*3(备份数假设为3)*8 = 104字节</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以得出BlockInfoContiguous的直接内存大小是：<strong>对象头16字节 + 8字节 + 8字节 + 104字节 = 136字节</strong></p>
<p><strong>LightWeightGSet</strong>的结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public class LightWeightGSet&lt;K, E extends K&gt; implements GSet&lt;K, E&gt; &#123;</span><br><span class="line">    private final LinkedElement[] entries; // 引用类型 8字节 + 数组对象头24字节 = 32字节</span><br><span class="line">    private final int hash_mask; // 4字节</span><br><span class="line">    private int size = 0; // 4字节</span><br><span class="line">    private int modification = 0; // 4字节</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>　　LightWeightGSet本质是一个链式解决冲突的哈希表，为了避免rehash过程带来的性能开销，初始化时，LightWeightGSet的索引空间直接给到了整个JVM可用内存的2%，并且不再变化。 所以LightWeightGSet的直接内存大小为：**对象头16字节 + 32字节 + 4字节 + 4字节 + 4字节 + (2%<em>JVM可用内存) = 60字节 + (2%<em>JVM可用内存)</em></em></p>
<p>假设集群中共1亿Block，NameNode可用内存空间固定大小128GB，则BlocksMap占用内存情况：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">BlocksMap直接内存大小 + (Block直接内存大小 + BlockInfoContiguous直接内存大小) * 100M + LightWeightGSet直接内存大小</span><br><span class="line">即：</span><br><span class="line">28字节 + (40字节 + 136字节) * 100M + 60字节 + (2%*128G) = 19.7475GB</span><br></pre></td></tr></table></figure>

<blockquote>
<p>上面为什么是乘以100M呢？ 因为100M = 100 * 1024 * 1024 bytes = 104857600 bytes，约等于1亿字节，而上面的内存的单位都是字节的，我们乘以100M，就相当于1亿Block</p>
</blockquote>
<p>BlocksMap数据在NameNode整个生命周期内常驻内存，随着数据规模的增加，对应Block数会随之增多，BlocksMap所占用的JVM堆内存空间也会基本保持线性同步增加。</p>
<hr>
<p>参考：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/wjn19921104/article/details/80742655">https://blog.csdn.net/wjn19921104/article/details/80742655</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/tesla-turing/p/11488035.html">https://www.cnblogs.com/tesla-turing/p/11488035.html</a></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2021/12/02/%E7%AE%80%E6%98%8E-VIM-%E7%BB%83%E7%BA%A7%E6%94%BB%E7%95%A5%EF%BC%88%E8%BD%AC%E8%BD%BD%EF%BC%89/" rel="next" title="简明 VIM 练级攻略（转载）">
                <i class="fa fa-chevron-left"></i> 简明 VIM 练级攻略（转载）
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2021/12/03/HDFS%E7%9A%84%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B/" rel="prev" title="HDFS文件读写流程与副本放置策略">
                HDFS文件读写流程与副本放置策略 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">62</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS%E6%95%B0%E6%8D%AE%E5%9D%97"><span class="nav-number">1.</span> <span class="nav-text">HDFS数据块</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8"><span class="nav-number">2.</span> <span class="nav-text">HDFS分布式存储</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%97%AE%E9%A2%98%EF%BC%9AHDFS%E9%87%8C%E9%9D%A2%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%80%E8%88%AC%E8%AE%BE%E7%BD%AE%E5%9D%97%E5%A4%A7%E5%B0%8F%E4%B8%BA64MB%E6%88%96128MB%EF%BC%9F"><span class="nav-number">3.</span> <span class="nav-text">问题：HDFS里面为什么一般设置块大小为64MB或128MB？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%9D%97%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">4.</span> <span class="nav-text">数据块的实现</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BlocksMap%E5%86%85%E5%AD%98%E4%BC%B0%E7%AE%97"><span class="nav-number">5.</span> <span class="nav-text">BlocksMap内存估算</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">k12</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
