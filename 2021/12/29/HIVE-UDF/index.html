<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>HIVE UDF 与 HIVE源码编译 | k12的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="一、实现UDF需求：添加随机数add_random、去除随机数remove_random UDF函数中实现evaluate方法。 UDFAddRandom.java 1234567891011121314151617package org.apache.hadoop.hive.ql.udf;import org.apache.hadoop.hive.ql.exec.UDF;import java.">
<meta property="og:type" content="article">
<meta property="og:title" content="HIVE UDF 与 HIVE源码编译">
<meta property="og:url" content="https://k12coding.github.io/2021/12/29/HIVE-UDF/index.html">
<meta property="og:site_name" content="k12的博客">
<meta property="og:description" content="一、实现UDF需求：添加随机数add_random、去除随机数remove_random UDF函数中实现evaluate方法。 UDFAddRandom.java 1234567891011121314151617package org.apache.hadoop.hive.ql.udf;import org.apache.hadoop.hive.ql.exec.UDF;import java.">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://k12coding.github.io/2021/12/29/HIVE-UDF/BUILDSUCCESS.png">
<meta property="og:image" content="https://k12coding.github.io/2021/12/29/HIVE-UDF/aliyun.png">
<meta property="og:image" content="https://k12coding.github.io/2021/12/29/HIVE-UDF/LLAP.png">
<meta property="og:image" content="https://k12coding.github.io/2021/12/29/HIVE-UDF/hive1.png">
<meta property="og:image" content="https://k12coding.github.io/2021/12/29/HIVE-UDF/hive2.png">
<meta property="og:image" content="https://k12coding.github.io/2021/12/29/HIVE-UDF/hive3.png">
<meta property="og:image" content="https://k12coding.github.io/2021/12/29/HIVE-UDF/hive4.png">
<meta property="article:published_time" content="2021-12-28T17:19:11.000Z">
<meta property="article:modified_time" content="2021-12-31T08:50:32.322Z">
<meta property="article:author" content="k12">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://k12coding.github.io/2021/12/29/HIVE-UDF/BUILDSUCCESS.png">
  
    <link rel="alternate" href="/atom.xml" title="k12的博客" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">k12的博客</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">k12的笔记</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <!--
      <nav id="sub-nav">
        
          此处隐藏rss,注释掉 <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS 订阅"></a> -->
        
        <!--此处隐藏,注释掉 <a id="nav-search-btn" class="nav-icon" title="搜索"></a> 
      </nav>
      -->
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://k12coding.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-HIVE-UDF" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/12/29/HIVE-UDF/" class="article-date">
  <time class="dt-published" datetime="2021-12-28T17:19:11.000Z" itemprop="datePublished">2021-12-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      HIVE UDF 与 HIVE源码编译
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="一、实现UDF"><a href="#一、实现UDF" class="headerlink" title="一、实现UDF"></a>一、实现UDF</h2><p>需求：添加随机数<code>add_random</code>、去除随机数<code>remove_random</code></p>
<p>UDF函数中实现evaluate方法。</p>
<p>UDFAddRandom.java</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">package org.apache.hadoop.hive.ql.udf;</span><br><span class="line"></span><br><span class="line">import org.apache.hadoop.hive.ql.exec.UDF;</span><br><span class="line"></span><br><span class="line">import java.util.Random;</span><br><span class="line"></span><br><span class="line">public class UDFAddRandom extends UDF &#123;</span><br><span class="line">	public String evaluate(String s)&#123;</span><br><span class="line">		int num = new Random().nextInt(10);</span><br><span class="line">		return s+&quot;_&quot;+num;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public static void main(String[] args) &#123;</span><br><span class="line">		UDFAddRandom input = new UDFAddRandom();</span><br><span class="line">		System.out.println(input.evaluate(&quot;PK&quot;));</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>UDFRemoveRandom.java</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">package org.apache.hadoop.hive.ql.udf;</span><br><span class="line"></span><br><span class="line">import org.apache.hadoop.hive.ql.exec.UDF;</span><br><span class="line"></span><br><span class="line">public class UDFRemoveRandom extends UDF &#123;</span><br><span class="line">	public String evaluate(String s)&#123;</span><br><span class="line">		return s.split(&quot;_&quot;)[0];</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public static void main(String[] args) &#123;</span><br><span class="line">		UDFRemoveRandom input = new UDFRemoveRandom();</span><br><span class="line">		System.out.println(input.evaluate(&quot;PK_91&quot;));</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="二、在查询中使用函数"><a href="#二、在查询中使用函数" class="headerlink" title="二、在查询中使用函数"></a>二、在查询中使用函数</h2><h3 id="临时函数"><a href="#临时函数" class="headerlink" title="临时函数"></a>临时函数</h3><ol>
<li><p>将包含函数的jar包上传到服务器上，我的存放目录是<code>/home/hadoop/lib</code></p>
</li>
<li><p>开启hive会话，执行以下命令添加jar：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (hive)&gt; add jar /home/hadoop/lib/ruozedata-hive-1.0.jar;</span><br><span class="line">Added [/home/hadoop/lib/ruozedata-hive-1.0.jar] to class path</span><br><span class="line">Added resources: [/home/hadoop/lib/ruozedata-hive-1.0.jar]</span><br></pre></td></tr></table></figure></li>
<li><p>执行以下命令创建名为add_random的临时函数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (hive)&gt; create temporary function add_random as &#x27;com.ruozedata.hive.udf.UDFAddRandom&#x27;;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.025 seconds</span><br></pre></td></tr></table></figure>

<p>remove_random同理。</p>
</li>
<li><p>使用函数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">hive (hive)&gt; select * from emp;</span><br><span class="line">OK</span><br><span class="line">emp.empno	emp.ename	emp.job	emp.mgr	emp.hiredate	emp.sal	emp.comm	emp.deptno</span><br><span class="line">7369	SMITH	CLERK	7902	1980-12-17	800.0	NULL	20</span><br><span class="line">7499	ALLEN	SALESMAN	7698	1981-2-20	1600.0	300.0	30</span><br><span class="line">7521	WARD	SALESMAN	7698	1981-2-22	1250.0	500.0	30</span><br><span class="line">7566	JONES	MANAGER	7839	1981-4-2	2975.0	NULL	20</span><br><span class="line">7654	MARTIN	SALESMAN	7698	1981-9-28	1250.0	1400.0	30</span><br><span class="line">7698	BLAKE	MANAGER	7839	1981-5-1	2850.0	NULL	30</span><br><span class="line">7782	CLARK	MANAGER	7839	1981-6-9	2450.0	NULL	10</span><br><span class="line">7788	SCOTT	ANALYST	7566	1987-4-19	3000.0	NULL	20</span><br><span class="line">7839	KING	PRESIDENT	NULL	1981-11-17	5000.0	NULL	10</span><br><span class="line">7844	TURNER	SALESMAN	7698	1981-9-8	1500.0	0.0	30</span><br><span class="line">7876	ADAMS	CLERK	7788	1987-5-23	1100.0	NULL	20</span><br><span class="line">7900	JAMES	CLERK	7698	1981-12-3	950.0	NULL	30</span><br><span class="line">7902	FORD	ANALYST	7566	1981-12-3	3000.0	NULL	20</span><br><span class="line">7934	MILLER	CLERK	7782	1982-1-23	1300.0	NULL	10</span><br><span class="line">Time taken: 0.331 seconds, Fetched: 14 row(s)</span><br><span class="line">hive (hive)&gt; select ename,add_random(ename) from emp;</span><br><span class="line">OK</span><br><span class="line">ename	_c1</span><br><span class="line">SMITH	SMITH_8</span><br><span class="line">ALLEN	ALLEN_5</span><br><span class="line">WARD	WARD_1</span><br><span class="line">JONES	JONES_0</span><br><span class="line">MARTIN	MARTIN_0</span><br><span class="line">BLAKE	BLAKE_9</span><br><span class="line">CLARK	CLARK_5</span><br><span class="line">SCOTT	SCOTT_7</span><br><span class="line">KING	KING_8</span><br><span class="line">TURNER	TURNER_6</span><br><span class="line">ADAMS	ADAMS_6</span><br><span class="line">JAMES	JAMES_2</span><br><span class="line">FORD	FORD_6</span><br><span class="line">MILLER	MILLER_0</span><br><span class="line">Time taken: 0.882 seconds, Fetched: 14 row(s)</span><br><span class="line">hive (hive)&gt; </span><br></pre></td></tr></table></figure></li>
<li><p>这个UDF只在当前会话窗口生效，当您关闭了窗口此函数就不存在了；</p>
</li>
<li><p>如果您想在当前窗口将这个UDF清理掉，请依次执行以下两个命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">drop temporary function if exists add_random;</span><br><span class="line">delete jar /home/hadoop/lib/ruozedata-hive-1.0.jar;</span><br></pre></td></tr></table></figure></li>
<li><p>删除后再使用add_random会报错：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hive (hive)&gt; drop temporary function if exists add_random;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.024 seconds</span><br><span class="line">hive (hive)&gt; delete jar /home/hadoop/lib/ruozedata-hive-1.0.jar;</span><br><span class="line">Deleted [/home/hadoop/lib/ruozedata-hive-1.0.jar] from class path</span><br><span class="line">hive (hive)&gt; select ename,add_random(ename) from emp;</span><br><span class="line">FAILED: SemanticException [Error 10011]: Invalid function add_random</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="永久函数"><a href="#永久函数" class="headerlink" title="永久函数"></a>永久函数</h3><ol>
<li><p>UDF永久生效,并且对所有hive会话都生效</p>
</li>
<li><p>hdfs上创建目录</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 ~]$ hdfs dfs -mkdir /lib/udflib</span><br></pre></td></tr></table></figure></li>
<li><p>将jar文件上传到hdfs</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 ~]$ hdfs dfs -put /home/hadoop/lib/ruozedata-hive-1.0.jar /lib/udflib</span><br><span class="line">[hadoop@hadoop001 ~]$ hdfs dfs -ls /lib/udflib</span><br><span class="line">Found 1 items</span><br><span class="line">-rw-r--r--   1 hadoop supergroup       6098 2021-12-28 17:25 /lib/udflib/ruozedata-hive-1.0.jar</span><br></pre></td></tr></table></figure></li>
<li><p>开启hive会话，执行以下命令添加jar：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive (hive)&gt; create function add_random as &#x27;com.ruozedata.hive.udf.UDFAddRandom&#x27;</span><br><span class="line">           &gt; using jar &#x27;hdfs:///lib/udflib/ruozedata-hive-1.0.jar&#x27;;</span><br><span class="line">Added [/tmp/38a5942b-b210-4c46-b700-9a64ae6090b7_resources/ruozedata-hive-1.0.jar] to class path</span><br><span class="line">Added resources: [hdfs:///lib/udflib/ruozedata-hive-1.0.jar]</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.097 seconds</span><br></pre></td></tr></table></figure></li>
<li><p>函数可以使用，新开hive会话也可使用。</p>
</li>
</ol>
<h2 id="三、整合函数到hive源码中，编译hive"><a href="#三、整合函数到hive源码中，编译hive" class="headerlink" title="三、整合函数到hive源码中，编译hive"></a>三、整合函数到hive源码中，编译hive</h2><ol>
<li><p>解压src包到相应目录</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 apache-hive-3.1.2-src]$ pwd</span><br><span class="line">/home/hadoop/software/apache-hive-3.1.2-src</span><br></pre></td></tr></table></figure></li>
<li><p>把函数放到目录<code>ql/src/java/org/apache/hadoop/hive/ql/udf</code>下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 apache-hive-3.1.2-src]$ cd ql/src/java/org/apache/hadoop/hive/ql/udf</span><br><span class="line">[hadoop@hadoop001 udf]$ pwd</span><br><span class="line">/home/hadoop/software/apache-hive-3.1.2-src/ql/src/java/org/apache/hadoop/hive/ql/udf</span><br></pre></td></tr></table></figure></li>
<li><p>修改FunctionRegistry.java </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 apache-hive-3.1.2-src]$ cd ql/src/java/org/apache/hadoop/hive/ql/exec</span><br><span class="line">[hadoop@hadoop001 exec]$ pwd</span><br><span class="line">/home/hadoop/software/apache-hive-3.1.2-src/ql/src/java/org/apache/hadoop/hive/ql/exec</span><br><span class="line">[hadoop@hadoop001 exec]$ vi FunctionRegistry.java </span><br></pre></td></tr></table></figure>

<p>到相关位置插入添加的函数信息：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.hadoop.hive.ql.udf.UDFAddRandom; </span><br><span class="line">import org.apache.hadoop.hive.ql.udf.UDFRemoveRandom; </span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">static &#123;</span><br><span class="line">    system.registerUDF(&quot;add_random&quot;, UDFAddRandom.class, false);</span><br><span class="line">	system.registerUDF(&quot;remove_random&quot;, UDFRemoveRandom.class, false);</span><br><span class="line">    ……</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>编译</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 apache-hive-3.1.2-src]$ mvn clean package -Pdist -DskipTests -Dmaven.javadoc.skip=true</span><br></pre></td></tr></table></figure>

<p>等待编译</p>
<p><img src="/2021/12/29/HIVE-UDF/BUILDSUCCESS.png" alt="img"></p>
<p>目录<code>packaging/target/</code>下的<code>apache-hive-3.1.2-bin.tar.gz</code>就是我们需要的tar包。（不想重新部署的话可以参考第7步）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 apache-hive-3.1.2-src]$ cd packaging/target/</span><br><span class="line">[hadoop@hadoop001 target]$ ll</span><br><span class="line">total 410320</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop      4096 Dec 31 06:26 antrun</span><br><span class="line">drwxrwxr-x. 3 hadoop hadoop      4096 Dec 31 06:26 apache-hive-3.1.2-bin</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 315855613 Dec 31 06:26 apache-hive-3.1.2-bin.tar.gz</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop  77970637 Dec 31 06:27 apache-hive-3.1.2-jdbc.jar</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop  26307866 Dec 31 06:27 apache-hive-3.1.2-src.tar.gz</span><br><span class="line">drwxrwxr-x. 4 hadoop hadoop      4096 Dec 31 06:26 archive-tmp</span><br><span class="line">drwxrwxr-x. 3 hadoop hadoop      4096 Dec 31 06:26 maven-shared-archive-resources</span><br><span class="line">drwxrwxr-x. 7 hadoop hadoop      4096 Dec 31 06:26 testconf</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop      4096 Dec 31 06:26 tmp</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop      4096 Dec 31 06:26 warehouse</span><br></pre></td></tr></table></figure></li>
<li><p>部署hive（省略）</p>
</li>
<li><p>检查函数</p>
<p>用<code>show functions</code>或者<code>desc function 函数名</code>都可以</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 ~]$ hive</span><br><span class="line">which: no hbase in (/home/hadoop/app/hive/bin:/home/hadoop/app/scala/bin:/home/hadoop/app/hadoop/bin:/home/hadoop/app/hadoop/sbin:/home/hadoop/app/protobuf/bin:/home/hadoop/app/maven/bin:/usr/local/mysql/bin:/usr/java/jdk1.8.0_45/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin)</span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding in [jar:file:/home/hadoop/software/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding in [jar:file:/home/hadoop/software/hadoop-3.2.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</span><br><span class="line">SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]</span><br><span class="line">Hive Session ID = d35e6d35-1d7b-40ae-b86e-3bf09fc0f5d2</span><br><span class="line"></span><br><span class="line">Logging initialized using configuration in jar:file:/home/hadoop/software/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true</span><br><span class="line">Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span><br><span class="line">Hive Session ID = 5fca1029-8f4a-4c52-9d22-0b2a0942cc85</span><br><span class="line"></span><br><span class="line">hive (default)&gt; desc function add_random;</span><br><span class="line">OK</span><br><span class="line">tab_name</span><br><span class="line">There is no documentation for function &#x27;add_random&#x27;</span><br><span class="line">Time taken: 0.078 seconds, Fetched: 1 row(s)</span><br><span class="line">hive (default)&gt; desc function remove_random;</span><br><span class="line">OK</span><br><span class="line">tab_name</span><br><span class="line">There is no documentation for function &#x27;remove_random&#x27;</span><br><span class="line">Time taken: 0.049 seconds, Fetched: 1 row(s)</span><br><span class="line">hive (default)&gt; </span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>替换jar包</p>
<p>找到我们需要替换的<code>hive-exec-3.1.2.jar</code>包</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 lib]$ pwd</span><br><span class="line">/home/hadoop/software/apache-hive-3.1.2-src/packaging/target/apache-hive-3.1.2-bin/apache-hive-3.1.2-bin/lib</span><br><span class="line">[hadoop@hadoop001 lib]$ ll hive-exec-3.1.2.jar </span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 41063609 Dec 31 06:26 hive-exec-3.1.2.jar</span><br></pre></td></tr></table></figure>

<p>进入到正在使用的hive目录下，找到要被替换的包，改名备份</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 lib]$ pwd</span><br><span class="line">/home/hadoop/software/hive/lib</span><br><span class="line">[hadoop@hadoop001 lib]$ ll hive-exec-3.1.2.jar </span><br><span class="line">-rw-r--r--. 1 hadoop hadoop 40623961 Aug 23  2019 hive-exec-3.1.2.jar</span><br><span class="line">[hadoop@hadoop001 lib]$ mv hive-exec-3.1.2.jar hive-exec-3.1.2.jar_bak</span><br></pre></td></tr></table></figure>

<p>替换</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 lib]$ cp /home/hadoop/software/apache-hive-3.1.2-src/packaging/target/apache-hive-3.1.2-bin/apache-hive-3.1.2-bin/lib/hive-exec-3.1.2.jar ./</span><br><span class="line">[hadoop@hadoop001 lib]$ ll hive-exec-3.1.2.*</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 41063609 Dec 31 06:46 hive-exec-3.1.2.jar</span><br><span class="line">-rw-r--r--. 1 hadoop hadoop 40623961 Aug 23  2019 hive-exec-3.1.2.jar_bak</span><br></pre></td></tr></table></figure>

<p>然后重启Hive即可找到函数。</p>
</li>
</ol>
<h2 id="四、Hive源码编译"><a href="#四、Hive源码编译" class="headerlink" title="四、Hive源码编译"></a>四、Hive源码编译</h2><p>个人在上面操作的源码编译上遇到好几个坑，又是改仓库又是修改java文件的。</p>
<p>一开始是直接下载hive官网下载地址<a target="_blank" rel="noopener" href="https://dlcdn.apache.org/hive/hive-3.1.2/%E7%9A%84src%E5%8C%85%E3%80%82">https://dlcdn.apache.org/hive/hive-3.1.2/的src包。</a></p>
<p>在目录下执行命令开始编译</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn clean package -Pdist -DskipTests -Dmaven.javadoc.skip=true</span><br></pre></td></tr></table></figure>

<p>问题一：<strong>pentaho-aggdesigner-algorithm-5.1.5-jhyde.jar</strong>缺失</p>
<p>在maven的conf/settings.xml 中添加阿里云仓库地址</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 ~]$ vi app/maven/conf/settings.xml </span><br></pre></td></tr></table></figure>

<p>注意：<code>&lt;mirror&gt;&lt;/mirror&gt;</code>标签要在<code>&lt;mirrors&gt;&lt;/mirrors&gt;</code>内,我最开始没注意，原来文本下面有个<code>&lt;mirrors&gt;</code>没注释掉</p>
<p><img src="/2021/12/29/HIVE-UDF/aliyun.png" alt="img"></p>
<p>我这里注释掉了，因为后来使用maven仓库下载的，没有用到阿里云。</p>
<p>问题二：添加阿里云仓库后，重新编译，依然报错</p>
<p><img src="/2021/12/29/HIVE-UDF/LLAP.png" alt="image-20211231161907516"></p>
<p>网上搜查发现有同样问题的，然后需要根据错误提示，参考<a target="_blank" rel="noopener" href="https://github.com/gitlbo/hive/commits/3.1.2%E4%BF%AE%E6%94%B9%E6%BA%90%E7%A0%81%E4%B8%AD%E7%9A%84%E6%9F%90%E5%87%A0%E4%B8%AA%E7%B1%BB%E3%80%82%E4%BA%8E%E6%98%AF%E6%88%91%E6%8C%89%E6%AD%A5%E9%AA%A4%E4%BF%AE%E6%94%B9%E5%90%8E%EF%BC%8C%E5%8F%AF%E4%BB%A5%E7%BC%96%E8%AF%91%E8%BF%99%E4%B8%AA%E7%BB%84%E4%BB%B6%E4%BA%86%EF%BC%8C%E4%BD%86%E5%8F%88%E6%9C%89%E5%85%B6%E4%BB%96%E5%9C%B0%E6%96%B9%E6%8A%A5%E9%94%99%E3%80%82">https://github.com/gitlbo/hive/commits/3.1.2修改源码中的某几个类。于是我按步骤修改后，可以编译这个组件了，但又有其他地方报错。</a></p>
<p>既然都要按照修改，为什么不直接用最新的src包呢，于是我下载了一个新的src包。</p>
<p><img src="/2021/12/29/HIVE-UDF/hive1.png" alt="image-20211231162607453"></p>
<p><img src="/2021/12/29/HIVE-UDF/hive2.png" alt="image-20211231162633319"></p>
<p><img src="/2021/12/29/HIVE-UDF/hive3.png" alt="image-20211231162658887"></p>
<p><img src="/2021/12/29/HIVE-UDF/hive4.png" alt="image-20211231162727453"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 software]$ wget -O apache-hive-3.1.2-src.zip https://codeload.github.com/gitlbo/hive/zip/c073e71ef43699b7aa68cad7c69a2e8f487089fd</span><br></pre></td></tr></table></figure>

<p>然后解压，修改pom.xml里的hadoop.version为我的版本3.2.2.然后其他根据个人需要修改。</p>
<p>使用命令编译<code>mvn clean package -Pdist -DskipTests -Dmaven.javadoc.skip=true</code>，没有报错，编译成功。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 apache-hive-3.1.2-src]$ cd packaging/target/</span><br><span class="line">[hadoop@hadoop001 target]$ ll</span><br><span class="line">total 410320</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop      4096 Dec 31 06:26 antrun</span><br><span class="line">drwxrwxr-x. 3 hadoop hadoop      4096 Dec 31 06:26 apache-hive-3.1.2-bin</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 315855613 Dec 31 06:26 apache-hive-3.1.2-bin.tar.gz</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop  77970637 Dec 31 06:27 apache-hive-3.1.2-jdbc.jar</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop  26307866 Dec 31 06:27 apache-hive-3.1.2-src.tar.gz</span><br><span class="line">drwxrwxr-x. 4 hadoop hadoop      4096 Dec 31 06:26 archive-tmp</span><br><span class="line">drwxrwxr-x. 3 hadoop hadoop      4096 Dec 31 06:26 maven-shared-archive-resources</span><br><span class="line">drwxrwxr-x. 7 hadoop hadoop      4096 Dec 31 06:26 testconf</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop      4096 Dec 31 06:26 tmp</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop      4096 Dec 31 06:26 warehouse</span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="https://k12coding.github.io/2021/12/29/HIVE-UDF/" data-id="cl3b9tuab0009akudcnaa0ppt" data-title="HIVE UDF 与 HIVE源码编译" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/12/30/MapReduce%E6%94%AF%E6%8C%81%E9%80%92%E5%BD%92%E5%AD%90%E7%9B%AE%E5%BD%95%E4%BD%9C%E4%B8%BA%E8%BE%93%E5%85%A5/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">前一篇</strong>
      <div class="article-nav-title">
        
          MapReduce支持递归子目录作为输入
        
      </div>
    </a>
  
  
    <a href="/2021/12/28/HIVE%E7%9A%84%E9%83%A8%E7%BD%B2/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">后一篇</strong>
      <div class="article-nav-title">HIVE的部署</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/05/">五月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">三月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/">二月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">一月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">十二月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">十一月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/10/">十月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">九月 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/05/17/Flume%E7%9A%84%E4%BD%BF%E7%94%A8%E6%A1%88%E4%BE%8B/">Flume的使用案例</a>
          </li>
        
          <li>
            <a href="/2022/05/17/Flume-v1-9-0%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99ERROR-org-apache-flume-sink-hdfs-HDFSEventSink-process/">Flume v1.9.0启动报错ERROR - org.apache.flume.sink.hdfs.HDFSEventSink.process</a>
          </li>
        
          <li>
            <a href="/2022/05/16/Flume%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/">Flume介绍与使用</a>
          </li>
        
          <li>
            <a href="/2022/05/13/Kafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%83%BD%E9%82%A3%E4%B9%88%E5%BF%AB/">Kafka为什么能那么快</a>
          </li>
        
          <li>
            <a href="/2022/03/26/%E6%88%91%E7%9A%84mysql%E7%AC%94%E8%AE%B0/">我的mysql笔记</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 k12<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>