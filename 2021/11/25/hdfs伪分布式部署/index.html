<!DOCTYPE html>
<html lang=zh>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  <!-- Color theme for statusbar -->
  <meta name="theme-color" content="#000000" />
  <!-- 强制页面在当前窗口以独立页面显示,防止别人在框架里调用页面 -->
  <meta http-equiv="window-target" content="_top" />
  
  
  <title>hdfs伪分布式部署 | Hexo</title>
  <meta name="description" content="hdfs伪分布式部署Releases Archive中选择要部署的版本，我们以Release 3.2.2 available版本为例 参考文档：Hadoop: Setting up a Single Node Cluster. 一、部署1.软件要求 Java：Hadoop对Java版本有要求，具体参考Hadoop Java Versions，基本上Java8通用 ssh  补充：组件名称大写-数字">
<meta property="og:type" content="article">
<meta property="og:title" content="hdfs伪分布式部署">
<meta property="og:url" content="https://k12coding.github.io/2021/11/25/hdfs%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2/index.html">
<meta property="og:site_name" content="k12的博客">
<meta property="og:description" content="hdfs伪分布式部署Releases Archive中选择要部署的版本，我们以Release 3.2.2 available版本为例 参考文档：Hadoop: Setting up a Single Node Cluster. 一、部署1.软件要求 Java：Hadoop对Java版本有要求，具体参考Hadoop Java Versions，基本上Java8通用 ssh  补充：组件名称大写-数字">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://k12coding.github.io/2021/11/25/hdfs%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2/image-20211126093406585.png">
<meta property="article:published_time" content="2021-11-25T05:09:16.000Z">
<meta property="article:modified_time" content="2021-11-27T06:16:46.391Z">
<meta property="article:author" content="k12">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://k12coding.github.io/2021/11/25/hdfs%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2/image-20211126093406585.png">
  <!-- Canonical links -->
  <link rel="canonical" href="https://k12coding.github.io/2021/11/25/hdfs%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2/index.html">
  
    <link rel="alternate" href="/atom.xml" title="k12的博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png" type="image/x-icon">
  
  
<link rel="stylesheet" href="/css/style.css">

  
  
  
  
<meta name="generator" content="Hexo 5.4.0"></head>


<body class="main-center" itemscope itemtype="http://schema.org/WebPage">
  <header class="header" itemscope itemtype="http://schema.org/WPHeader">
  <div class="slimContent">
    <div class="navbar-header">
      
      
      <div class="profile-block text-center">
        <a id="avatar" href="https://github.com/cofess" target="_blank">
          <img class="img-circle img-rotate" src="/images/avatar.jpg" width="200" height="200">
        </a>
        <h2 id="name" class="hidden-xs hidden-sm">昵称</h2>
        <h3 id="title" class="hidden-xs hidden-sm hidden-md">Web Developer &amp; Designer</h3>
        <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> Shenzhen, China</small>
      </div>
      
      <div class="search" id="search-form-wrap">

    <form class="search-form sidebar-form">
        <div class="input-group">
            <input type="text" class="search-form-input form-control" placeholder="搜索" />
            <span class="input-group-btn">
                <button type="submit" class="search-form-submit btn btn-flat" onclick="return false;"><i class="icon icon-search"></i></button>
            </span>
        </div>
    </form>
    <div class="ins-search">
  <div class="ins-search-mask"></div>
  <div class="ins-search-container">
    <div class="ins-input-wrapper">
      <input type="text" class="ins-search-input" placeholder="想要查找什么..." x-webkit-speech />
      <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
    </div>
    <div class="ins-section-wrapper">
      <div class="ins-section-container"></div>
    </div>
  </div>
</div>


</div>
      <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
      <ul class="nav navbar-nav main-nav ">
        
        
        <li class="menu-item menu-item-home">
          <a href="/.">
            
            <i class="icon icon-home-fill"></i>
            
            <span class="menu-title">首页</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives">
            
            <i class="icon icon-archives-fill"></i>
            
            <span class="menu-title">归档</span>
          </a>
        </li>
        
      </ul>
      
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/cofess" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
        <li><a href="http://weibo.com/cofess" target="_blank" title="Weibo" data-toggle=tooltip data-placement=top><i class="icon icon-weibo"></i></a></li>
        
        <li><a href="https://twitter.com/iwebued" target="_blank" title="Twitter" data-toggle=tooltip data-placement=top><i class="icon icon-twitter"></i></a></li>
        
        <li><a href="https://www.behance.net/cofess" target="_blank" title="Behance" data-toggle=tooltip data-placement=top><i class="icon icon-behance"></i></a></li>
        
        <li><a href="/atom.xml" target="_blank" title="Rss" data-toggle=tooltip data-placement=top><i class="icon icon-rss"></i></a></li>
        
    </ul>

    </nav>
  </div>
</header>

  
    <aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    
      <div class="widget">
    <h3 class="widget-title">公告</h3>
    <div class="widget-body">
        <div id="board">
            <div class="content">
                <p>欢迎交流与分享经验!</p>
            </div>
        </div>
    </div>
</div>

    
      

    
      

    
      
    
      
  <div class="widget">
    <h3 class="widget-title">归档</h3>
    <div class="widget-body">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/05/">五月 2022</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">三月 2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/">二月 2022</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">一月 2022</a><span class="archive-list-count">26</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">十二月 2021</a><span class="archive-list-count">16</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">十一月 2021</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/10/">十月 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">九月 2021</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget-body">
      <ul class="recent-post-list list-unstyled no-thumbnail">
        
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                
              </p>
              <p class="item-title">
                <a href="/2022/05/17/Flume%E7%9A%84%E4%BD%BF%E7%94%A8%E6%A1%88%E4%BE%8B/" class="title">Flume的使用案例</a>
              </p>
              <p class="item-date">
                <time datetime="2022-05-16T23:41:07.000Z" itemprop="datePublished">2022-05-17</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                
              </p>
              <p class="item-title">
                <a href="/2022/05/17/Flume-v1-9-0%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99ERROR-org-apache-flume-sink-hdfs-HDFSEventSink-process/" class="title">Flume v1.9.0启动报错ERROR - org.apache.flume.sink.hdfs.HDFSEventSink.process</a>
              </p>
              <p class="item-date">
                <time datetime="2022-05-16T23:12:13.000Z" itemprop="datePublished">2022-05-17</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                
              </p>
              <p class="item-title">
                <a href="/2022/05/16/Flume%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/" class="title">Flume介绍与使用</a>
              </p>
              <p class="item-date">
                <time datetime="2022-05-16T09:47:05.000Z" itemprop="datePublished">2022-05-16</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                
              </p>
              <p class="item-title">
                <a href="/2022/05/13/Kafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%83%BD%E9%82%A3%E4%B9%88%E5%BF%AB/" class="title">Kafka为什么能那么快</a>
              </p>
              <p class="item-date">
                <time datetime="2022-05-12T18:33:47.000Z" itemprop="datePublished">2022-05-13</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                
              </p>
              <p class="item-title">
                <a href="/2022/03/26/%E6%88%91%E7%9A%84mysql%E7%AC%94%E8%AE%B0/" class="title">我的mysql笔记</a>
              </p>
              <p class="item-date">
                <time datetime="2022-03-26T14:01:37.000Z" itemprop="datePublished">2022-03-26</time>
              </p>
            </div>
          </li>
          
      </ul>
    </div>
  </div>
  

    
  </div>
</aside>

  
  
<main class="main" role="main">
  <div class="content">
  <article id="post-hdfs伪分布式部署" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
    
    <div class="article-header">
      
        
  
    <h1 class="article-title" itemprop="name">
      hdfs伪分布式部署
    </h1>
  

      
      <div class="article-meta">
        <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/2021/11/25/hdfs%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2/" class="article-date">
	  <time datetime="2021-11-25T05:09:16.000Z" itemprop="datePublished">2021-11-25</time>
	</a>
</span>
        
        

        

        <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2021/11/25/hdfs%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2/#comments" class="article-comment-link">评论</a></span>
        
      </div>
    </div>
    <div class="article-entry marked-body" itemprop="articleBody">
      
        <h1 id="hdfs伪分布式部署"><a href="#hdfs伪分布式部署" class="headerlink" title="hdfs伪分布式部署"></a>hdfs伪分布式部署</h1><p><a target="_blank" rel="noopener" href="https://hadoop.apache.org/release.html">Releases Archive</a>中选择要部署的版本，我们以<a target="_blank" rel="noopener" href="https://hadoop.apache.org/release/3.2.2.html">Release 3.2.2 available</a>版本为例</p>
<p>参考文档：<a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r3.2.2/hadoop-project-dist/hadoop-common/SingleCluster.html">Hadoop: Setting up a Single Node Cluster.</a></p>
<h2 id="一、部署"><a href="#一、部署" class="headerlink" title="一、部署"></a>一、部署</h2><h3 id="1-软件要求"><a href="#1-软件要求" class="headerlink" title="1.软件要求"></a>1.软件要求</h3><ul>
<li>Java：Hadoop对Java版本有要求，具体参考<a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/HADOOP/Hadoop+Java+Versions">Hadoop Java Versions</a>，基本上Java8通用</li>
<li>ssh</li>
</ul>
<p>补充：组件名称<code>大写-数字</code>，如：SPARK-2908，表明该组件是有问题的</p>
<span id="more"></span>

<h3 id="2-tar包解压"><a href="#2-tar包解压" class="headerlink" title="2.tar包解压"></a>2.tar包解压</h3><p>点击下载:<a target="_blank" rel="noopener" href="https://archive.apache.org/dist/hadoop/common/hadoop-3.2.2/hadoop-3.2.2.tar.gz">hadoop-3.2.2.tar.gz</a></p>
<p>下载后通过rz命令上传至Linux系统</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 ~]$ ll software/</span><br><span class="line">total 805204</span><br><span class="line">-rw-r--r--.  1 hadoop hadoop 395448622 Nov 21 10:03 hadoop-3.2.2.tar.gz</span><br></pre></td></tr></table></figure>

<p>解压hadoop到app目录下，创建软连接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 ~]$ tar -xzvf software/hadoop-3.2.2.tar.gz -C app/</span><br><span class="line">[hadoop@hadoop001 ~]$ cd app</span><br><span class="line">[hadoop@hadoop001 app]$ </span><br><span class="line">[hadoop@hadoop001 app]$ ln -s /home/hadoop/app/hadoop-3.2.2 hadoop</span><br><span class="line">[hadoop@hadoop001 app]$ ll</span><br><span class="line">total 2</span><br><span class="line">lrwxrwxrwx. 1 hadoop hadoop   29 Nov 25 16:28 hadoop -&gt; /home/hadoop/app/hadoop-3.2.2</span><br><span class="line">drwxr-xr-x. 9 hadoop hadoop 4096 Jan  3  2021 hadoop-3.2.2</span><br></pre></td></tr></table></figure>

<h3 id="3-查看文件目录"><a href="#3-查看文件目录" class="headerlink" title="3.查看文件目录"></a>3.查看文件目录</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 app]$ cd hadoop/</span><br><span class="line">[hadoop@hadoop001 hadoop]$ ll</span><br><span class="line">total 216</span><br><span class="line">drwxr-xr-x. 2 hadoop hadoop   4096 Jan  3  2021 bin				#命令执行脚本</span><br><span class="line">drwxr-xr-x. 3 hadoop hadoop   4096 Jan  3  2021 etc				#配置文件</span><br><span class="line">drwxr-xr-x. 2 hadoop hadoop   4096 Jan  3  2021 include</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop   4096 Nov 21 10:14 input</span><br><span class="line">drwxr-xr-x. 3 hadoop hadoop   4096 Jan  3  2021 lib</span><br><span class="line">drwxr-xr-x. 4 hadoop hadoop   4096 Jan  3  2021 libexec</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 150569 Dec  5  2020 LICENSE.txt</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop   4096 Nov 21 10:48 logs</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop  21943 Dec  5  2020 NOTICE.txt</span><br><span class="line">drwxr-xr-x. 3 hadoop hadoop   4096 Nov 21 11:01 output</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop   1361 Dec  5  2020 README.txt</span><br><span class="line">drwxr-xr-x. 3 hadoop hadoop   4096 Jan  3  2021 sbin			#启动停止脚本</span><br><span class="line">drwxr-xr-x. 4 hadoop hadoop   4096 Jan  3  2021 share</span><br></pre></td></tr></table></figure>

<p>大部分的大数据项目解压后目录：bin</p>
<h3 id="4-手动配置Java环境变量（必须）"><a href="#4-手动配置Java环境变量（必须）" class="headerlink" title="4.手动配置Java环境变量（必须）"></a>4.手动配置Java环境变量（必须）</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ vi etc/hadoop/hadoop-env.sh </span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># The java implementation to use. By default, this environment</span><br><span class="line"># variable is REQUIRED on ALL platforms except OS X!</span><br><span class="line"># export JAVA_HOME=/usr/java/latest</span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_45</span><br></pre></td></tr></table></figure>

<h3 id="5-执行bin-hadoop查看hdfs使用说明"><a href="#5-执行bin-hadoop查看hdfs使用说明" class="headerlink" title="5.执行bin/hadoop查看hdfs使用说明"></a>5.执行bin/hadoop查看hdfs使用说明</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ bin/hadoop</span><br><span class="line">Usage: hadoop [OPTIONS] SUBCOMMAND [SUBCOMMAND OPTIONS]</span><br><span class="line"> or    hadoop [OPTIONS] CLASSNAME [CLASSNAME OPTIONS]</span><br><span class="line">  where CLASSNAME is a user-provided Java class</span><br><span class="line"></span><br><span class="line">  OPTIONS is none or any of:</span><br><span class="line"></span><br><span class="line">buildpaths                       attempt to add class files from build tree</span><br><span class="line">--config dir                     Hadoop config directory</span><br><span class="line">--debug                          turn on shell script debug mode</span><br><span class="line">--help                           usage information</span><br><span class="line">hostnames list[,of,host,names]   hosts to use in slave mode</span><br><span class="line">hosts filename                   list of hosts to use in slave mode</span><br><span class="line">loglevel level                   set the log4j level for this command</span><br><span class="line">workers                          turn on worker mode</span><br><span class="line"></span><br><span class="line">  SUBCOMMAND is one of:</span><br><span class="line">  </span><br><span class="line">    Admin Commands:</span><br><span class="line"></span><br><span class="line">daemonlog     get/set the log level for each daemon</span><br><span class="line"></span><br><span class="line">    Client Commands:</span><br><span class="line"></span><br><span class="line">archive       create a Hadoop archive</span><br><span class="line">checknative   check native Hadoop and compression libraries availability</span><br><span class="line">classpath     prints the class path needed to get the Hadoop jar and the required libraries</span><br><span class="line">conftest      validate configuration XML files</span><br><span class="line">credential    interact with credential providers</span><br><span class="line">distch        distributed metadata changer</span><br><span class="line">distcp        copy file or directories recursively</span><br><span class="line">dtutil        operations related to delegation tokens</span><br><span class="line">envvars       display computed Hadoop environment variables</span><br><span class="line">fs            run a generic filesystem user client</span><br><span class="line">gridmix       submit a mix of synthetic job, modeling a profiled from production load</span><br><span class="line">jar &lt;jar&gt;     run a jar file. NOTE: please use &quot;yarn jar&quot; to launch YARN applications, not</span><br><span class="line">              this command.</span><br><span class="line">jnipath       prints the java.library.path</span><br><span class="line">kdiag         Diagnose Kerberos Problems</span><br><span class="line">kerbname      show auth_to_local principal conversion</span><br><span class="line">key           manage keys via the KeyProvider</span><br><span class="line">rumenfolder   scale a rumen input trace</span><br><span class="line">rumentrace    convert logs into a rumen trace</span><br><span class="line">s3guard       manage metadata on S3</span><br><span class="line">trace         view and modify Hadoop tracing settings</span><br><span class="line">version       print the version</span><br><span class="line"></span><br><span class="line">    Daemon Commands:</span><br><span class="line"></span><br><span class="line">kms           run KMS, the Key Management Server</span><br><span class="line"></span><br><span class="line">SUBCOMMAND may print help when invoked w/o parameters or with -h.</span><br></pre></td></tr></table></figure>

<h3 id="6-修改配置文件：伪分布式部署"><a href="#6-修改配置文件：伪分布式部署" class="headerlink" title="6.修改配置文件：伪分布式部署"></a>6.修改配置文件：伪分布式部署</h3><ul>
<li>前置修改： <strong>/etc/host</strong></li>
</ul>
<p>通过命令<code>ifconfig</code>找到本机ip地址</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ ifconfig</span><br><span class="line">eth0      Link encap:Ethernet  HWaddr 00:0C:29:E2:5A:5E  </span><br><span class="line">          inet addr:XXX.XXX.XXX.XXX//这个ip地址</span><br><span class="line">          inet6 addr: fea2::24c:29fs:fee2:5a7e/64 Scope:Link</span><br><span class="line">          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</span><br><span class="line">          RX packets:2742 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:3033 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:1000 </span><br><span class="line">          RX bytes:267707 (261.4 KiB)  TX bytes:1724144 (1.6 MiB)</span><br></pre></td></tr></table></figure>

<p><code>vi  /etc/host</code>修改域名与ip的对应关系（注意，在后面追加即可，前面的信息不要修改）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ cat /etc/host</span><br><span class="line">cat: /etc/host: No such file or directory</span><br><span class="line">[hadoop@hadoop001 hadoop]$ cat /etc/hosts</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">XXX.XXX.XXX.XXX hadoop001</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>etc/hadoop/core-site.xml</strong></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ vi etc/hadoop/core-site.xml </span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<p>我的域名：hadoop001,所以</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;hdfs://hadoop001:9000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<p>个人补充：可顺便添加以下代码更改tmp目录地址</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/home/hadoop/tmp/hadoop-$&#123;user.name&#125;&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>etc/hadoop/hdfs-site.xml</strong></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ vi etc/hadoop/hdfs-site.xml </span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<p>个人补充：可顺便添加以下代码（我的域名：hadoop001）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">		&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;hadoop001:9868&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;dfs.namenode.secondary.https-address&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;hadoop001:9869&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<p><strong>个人补充：</strong></p>
<ul>
<li><strong>etc/hadoop/workers</strong></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ vi etc/hadoop/workers</span><br><span class="line">hadoop001</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>etc/hadoop/hadoop-env.sh</strong></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ vi etc/hadoop/hadoop-env.sh</span><br><span class="line"># Where pid files are stored.  /tmp by default.</span><br><span class="line"># export HADOOP_PID_DIR=/tmp</span><br><span class="line">export HADOOP_PID_DIR=/home/hadoop/tmp</span><br></pre></td></tr></table></figure>

<h3 id="7-设置SSH私钥取消密码"><a href="#7-设置SSH私钥取消密码" class="headerlink" title="7.设置SSH私钥取消密码"></a>7.设置<em>SSH</em>私钥取消密码</h3><p>通过命令<code>ssh localhost</code>检查是否可以用ssh免密连接到localhost</p>
<ul>
<li>成功：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ ssh localhost</span><br><span class="line">Last login: Sat Oct  9 17:05:54 2021 from localhost</span><br></pre></td></tr></table></figure>

<ul>
<li>失败：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ ssh localhost</span><br><span class="line">hadoop@localhost&#x27;s password: </span><br><span class="line">Permission denied, please try again.</span><br></pre></td></tr></table></figure>

<p>执行以下命令：<code>ssh-keygen</code>，然后回车两次，若有Overwrite (y/n)?，则输入 y回车</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ ssh-keygen</span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file in which to save the key (/home/hadoop/.ssh/id_rsa): </span><br><span class="line">/home/hadoop/.ssh/id_rsa already exists.</span><br><span class="line">Overwrite (y/n)? y</span><br><span class="line">Enter passphrase (empty for no passphrase): </span><br><span class="line">Enter same passphrase again: </span><br><span class="line">Your identification has been saved in /home/hadoop/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved in /home/hadoop/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">9c:1c:53:05:cd:dc:23:1b:51:62:06:b0:92:57:66:da hadoop@hadoop001</span><br><span class="line">The key&#x27;s randomart image is:</span><br><span class="line">+--[ RSA 2048]----+</span><br><span class="line">|        ..BB*+ . |</span><br><span class="line">|       . O o*.o  |</span><br><span class="line">|      o * E  +.  |</span><br><span class="line">|       = + .     |</span><br><span class="line">|       S         |</span><br><span class="line">|                 |</span><br><span class="line">|                 |</span><br><span class="line">|                 |</span><br><span class="line">|                 |</span><br><span class="line">+-----------------+</span><br><span class="line">[hadoop@hadoop001 hadoop]$ ll ~/.ssh/</span><br><span class="line">total 16</span><br><span class="line">-rw-------. 1 hadoop hadoop  796 Nov 21 10:34 authorized_keys</span><br><span class="line">-rw-------. 1 hadoop hadoop 1675 Nov 25 17:04 id_rsa</span><br><span class="line">-rw-r--r--. 1 hadoop hadoop  398 Nov 25 17:04 id_rsa.pub</span><br><span class="line">-rw-r--r--. 1 hadoop hadoop  798 Nov 21 10:29 known_hosts</span><br></pre></td></tr></table></figure>

<p>添加ssh密钥到authorized_keys中,更改权限</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line">[hadoop@hadoop001 hadoop]$ chmod 600 ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure>

<p>测试：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ ssh localhost</span><br><span class="line">Last login: Thu Nov 25 16:57:28 2021 from localhost</span><br></pre></td></tr></table></figure>

<h2 id="二、执行"><a href="#二、执行" class="headerlink" title="二、执行"></a>二、执行</h2><p>我的系统中环境变量配置了HADOOP_HOME：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_HOME=/home/hadoop/app/hadoop</span><br><span class="line">export HADOOP_MAPRED_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_COMMON_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_HDFS_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_YARN_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native</span><br><span class="line">export PATH=$&#123;HADOOP_HOME&#125;/bin:$&#123;HADOOP_HOME&#125;/sbin:$PATH</span><br></pre></td></tr></table></figure>

<h3 id="本地执行"><a href="#本地执行" class="headerlink" title="本地执行"></a>本地执行</h3><p>以下介绍为在本地执行一个MapReduce任务：</p>
<h4 id="1-格式化文件系统"><a href="#1-格式化文件系统" class="headerlink" title="1.格式化文件系统"></a>1.格式化文件系统</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ hdfs namenode -format</span><br></pre></td></tr></table></figure>

<h4 id="2-启动NameNode节点和DataNode节点"><a href="#2-启动NameNode节点和DataNode节点" class="headerlink" title="2.启动NameNode节点和DataNode节点"></a>2.启动NameNode节点和DataNode节点</h4><p>The hadoop daemon log output is written to the <code>$HADOOP_LOG_DIR</code> directory (defaults to <code>$HADOOP_HOME/logs</code>).</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ start-dfs.sh </span><br><span class="line">Starting namenodes on [hadoop001]</span><br><span class="line">Starting datanodes</span><br><span class="line">Starting secondary namenodes [hadoop001]</span><br></pre></td></tr></table></figure>

<p>启动后，可以用jps命令查看：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ jps</span><br><span class="line">6530 Jps</span><br><span class="line">6355 SecondaryNameNode</span><br><span class="line">6197 DataNode</span><br><span class="line">6089 NameNode</span><br></pre></td></tr></table></figure>

<hr>
<p>个人补充：jps后发现DataNode节点丢失，没在运行。原因大概是我格式化太多次namenode导致csid不同步，网上解决办法是data和name文件夹的dfs/data/cruurt/VERSION的id进行同步。最终个人解决方法如下：</p>
<ol>
<li><p>找到自己临时文档/tmp/即core.site.xml文件中的/home/hadoop/data/tmp路径</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ cat etc/hadoop/core-site.xml </span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;/home/hadoop/tmp/hadoop-$&#123;user.name&#125;&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li>
<li><p>删除<code>home/hadoop/tmp</code>目录下文件，重新格式化Namenode</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ rm -rf tmp/*</span><br><span class="line">[hadoop@hadoop001 hadoop]$ hdfs namenode -format</span><br></pre></td></tr></table></figure></li>
<li><p>重启hdfs，问题解决</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ start-dfs.sh </span><br><span class="line">Starting namenodes on [hadoop001]</span><br><span class="line">Starting datanodes</span><br><span class="line">Starting secondary namenodes [hadoop001]</span><br><span class="line">2021-11-25 18:17:14,032 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">[hadoop@hadoop001 hadoop]$ jps</span><br><span class="line">14148 SecondaryNameNode</span><br><span class="line">13991 DataNode</span><br><span class="line">13883 NameNode</span><br><span class="line">14270 Jps</span><br><span class="line">[hadoop@hadoop001 hadoop]$ </span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="3-通过浏览器访问NameNode"><a href="#3-通过浏览器访问NameNode" class="headerlink" title="3.通过浏览器访问NameNode"></a>3.通过浏览器访问NameNode</h4><ul>
<li>NameNode - <code>http://localhost:9870/</code></li>
<li>hadoop 2.x版本是50070端口，现在版本是9870端口</li>
</ul>
<h4 id="4-在hdfs中创建目录执行MapReduce-jobs"><a href="#4-在hdfs中创建目录执行MapReduce-jobs" class="headerlink" title="4.在hdfs中创建目录执行MapReduce jobs"></a>4.在hdfs中创建目录执行MapReduce jobs</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs  -ls /</span><br><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs  -mkdir /user</span><br><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs  -ls /</span><br><span class="line">Found 1 items</span><br><span class="line">drwxr-xr-x   - hadoop supergroup          0 2021-11-25 19:58 /user</span><br><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs  -mkdir /user/hadoop</span><br><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs  -ls /user</span><br><span class="line">Found 1 items</span><br><span class="line">drwxr-xr-x   - hadoop supergroup          0 2021-11-25 19:59 /user/hadoop</span><br></pre></td></tr></table></figure>

<h4 id="5-复制input文件夹下的文件到hdfs系统中"><a href="#5-复制input文件夹下的文件到hdfs系统中" class="headerlink" title="5.复制input文件夹下的文件到hdfs系统中"></a>5.复制input文件夹下的文件到hdfs系统中</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs  -mkdir input</span><br><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs -put etc/hadoop/*.xml input</span><br><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs  -ls /user/hadoop</span><br><span class="line">Found 1 items</span><br><span class="line">drwxr-xr-x   - hadoop supergroup          0 2021-11-25 20:05 /user/hadoop/input</span><br><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs  -ls /user/hadoop/input</span><br><span class="line">Found 9 items</span><br><span class="line">-rw-r--r--   1 hadoop supergroup       9213 2021-11-25 20:05 /user/hadoop/input/capacity-scheduler.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup        975 2021-11-25 20:05 /user/hadoop/input/core-site.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup      11392 2021-11-25 20:05 /user/hadoop/input/hadoop-policy.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup       1068 2021-11-25 20:05 /user/hadoop/input/hdfs-site.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup        620 2021-11-25 20:05 /user/hadoop/input/httpfs-site.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup       3518 2021-11-25 20:05 /user/hadoop/input/kms-acls.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup        682 2021-11-25 20:05 /user/hadoop/input/kms-site.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup        758 2021-11-25 20:05 /user/hadoop/input/mapred-site.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup        690 2021-11-25 20:05 /user/hadoop/input/yarn-site.xml</span><br><span class="line">[hadoop@hadoop001 hadoop]$ </span><br></pre></td></tr></table></figure>

<p>可以看到，在第一句命令中，input的路径并没有写成<code>/user/hadoop/input</code>，因为执行后会在当前用户的路径下执行</p>
<h4 id="6-执行MapReduce任务"><a href="#6-执行MapReduce任务" class="headerlink" title="6.执行MapReduce任务"></a>6.执行MapReduce任务</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input output &#x27;dfs[a-z.]+&#x27;</span><br><span class="line">2021-11-25 20:10:12,608 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">2021-11-25 20:10:13,702 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties</span><br><span class="line">2021-11-25 20:10:13,807 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).</span><br><span class="line">2021-11-25 20:10:13,807 INFO impl.MetricsSystemImpl: JobTracker metrics system started</span><br><span class="line">2021-11-25 20:10:14,497 INFO input.FileInputFormat: Total input files to process : 9</span><br><span class="line">......</span><br><span class="line">	File Input Format Counters </span><br><span class="line">		Bytes Read=232</span><br><span class="line">	File Output Format Counters </span><br><span class="line">		Bytes Written=90</span><br></pre></td></tr></table></figure>

<h4 id="7-查看执行结果"><a href="#7-查看执行结果" class="headerlink" title="7.查看执行结果"></a>7.查看执行结果</h4><ul>
<li><p>直接在hdfs系统上看：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs  -ls /user/hadoop/output</span><br><span class="line">Found 2 items</span><br><span class="line">-rw-r--r--   1 hadoop supergroup          0 2021-11-25 20:10 /user/hadoop/output/_SUCCESS</span><br><span class="line">-rw-r--r--   1 hadoop supergroup         90 2021-11-25 20:10 /user/hadoop/output/part-r-00000</span><br><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs -cat output/*</span><br><span class="line">cat: `output/output&#x27;: No such file or directory</span><br><span class="line">1	dfsadmin</span><br><span class="line">1	dfs.replication</span><br></pre></td></tr></table></figure></li>
<li><p>拿到linux系统上看：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ hdfs dfs -get output output</span><br><span class="line">[hadoop@hadoop001 hadoop]$ cat output/*</span><br><span class="line">1	dfsadmin</span><br><span class="line">1	dfs.replication</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="8-停止服务"><a href="#8-停止服务" class="headerlink" title="8.停止服务"></a>8.停止服务</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ stop-dfs.sh </span><br><span class="line">Stopping namenodes on [hadoop001]</span><br><span class="line">Stopping datanodes</span><br><span class="line">Stopping secondary namenodes [hadoop001]</span><br><span class="line">[hadoop@hadoop001 hadoop]$ </span><br></pre></td></tr></table></figure>


<h3 id="YARN上执行"><a href="#YARN上执行" class="headerlink" title="YARN上执行"></a>YARN上执行</h3><p>想要在YARN上执行MapReduce任务，需要设置参数运行ResourceManager守护进程和NodeManager守护进程。下面执行的基础是已经执行上述<a href="#%E6%9C%AC%E5%9C%B0%E6%89%A7%E8%A1%8C">本地执行1~4</a>的步骤。</p>
<h4 id="1-修改配置文件"><a href="#1-修改配置文件" class="headerlink" title="1.修改配置文件"></a>1.修改配置文件</h4><ul>
<li><p><strong>etc/hadoop/mapred-site.xml</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.application.classpath&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>etc/hadoop/yarn-site.xml</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ,HADOOP_MAPRED_HOME&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<p>个人：HADOOP_CONF_DIR还没配置</p>
</li>
</ul>
<h4 id="2-启动ResourceManager守护进程和NodeManager守护进程"><a href="#2-启动ResourceManager守护进程和NodeManager守护进程" class="headerlink" title="2.启动ResourceManager守护进程和NodeManager守护进程"></a>2.启动ResourceManager守护进程和NodeManager守护进程</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ start-yarn.sh </span><br><span class="line">Starting resourcemanager</span><br><span class="line">Starting nodemanagers</span><br><span class="line">[hadoop@hadoop001 hadoop]$ jps</span><br><span class="line">20592 Jps</span><br><span class="line">18579 NameNode</span><br><span class="line">20392 ResourceManager</span><br><span class="line">18843 SecondaryNameNode</span><br><span class="line">18686 DataNode</span><br><span class="line">20495 NodeManager</span><br></pre></td></tr></table></figure>

<h4 id="3-通过浏览器访问访问ResourceManager"><a href="#3-通过浏览器访问访问ResourceManager" class="headerlink" title="3.通过浏览器访问访问ResourceManager"></a>3.通过浏览器访问访问ResourceManager</h4><ul>
<li>ResourceManager - <code>http://localhost:8088/</code></li>
</ul>
<h4 id="4-执行MapReduce任务"><a href="#4-执行MapReduce任务" class="headerlink" title="4.执行MapReduce任务"></a>4.执行MapReduce任务</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input output &#x27;dfs[a-z.]+&#x27;</span><br><span class="line">2021-11-26 08:15:32,639 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">2021-11-26 08:15:34,024 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032</span><br><span class="line">2021-11-26 08:15:35,285 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/hadoop/.staging/job_1637885511879_0001</span><br><span class="line">2021-11-26 08:15:36,280 INFO input.FileInputFormat: Total input files to process : 9</span><br><span class="line">2021-11-26 08:15:36,379 INFO mapreduce.JobSubmitter: number of splits:9</span><br><span class="line">2021-11-26 08:15:36,974 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1637885511879_0001</span><br><span class="line">2021-11-26 08:15:36,976 INFO mapreduce.JobSubmitter: Executing with tokens: []</span><br><span class="line">2021-11-26 08:15:37,319 INFO conf.Configuration: resource-types.xml not found</span><br><span class="line">2021-11-26 08:15:37,320 INFO resource.ResourceUtils: Unable to find &#x27;resource-types.xml&#x27;.</span><br><span class="line">2021-11-26 08:15:37,878 INFO impl.YarnClientImpl: Submitted application application_1637885511879_0001</span><br><span class="line">2021-11-26 08:15:37,945 INFO mapreduce.Job: The url to track the job: http://hadoop001:8088/proxy/application_1637885511879_0001/</span><br><span class="line">2021-11-26 08:15:37,945 INFO mapreduce.Job: Running job: job_1637885511879_0001</span><br><span class="line">2021-11-26 08:15:55,539 INFO mapreduce.Job: Job job_1637885511879_0001 running in uber mode : false</span><br><span class="line">2021-11-26 08:15:55,550 INFO mapreduce.Job:  map 0% reduce 0%</span><br><span class="line">2021-11-26 08:16:43,204 INFO mapreduce.Job:  map 44% reduce 0%</span><br><span class="line">2021-11-26 08:16:44,369 INFO mapreduce.Job:  map 67% reduce 0%</span><br><span class="line">2021-11-26 08:17:05,488 INFO mapreduce.Job:  map 100% reduce 0%</span><br><span class="line">2021-11-26 08:17:06,495 INFO mapreduce.Job:  map 100% reduce 100%</span><br><span class="line">2021-11-26 08:17:07,508 INFO mapreduce.Job: Job job_1637885511879_0001 completed successfully</span><br><span class="line">2021-11-26 08:17:07,638 INFO mapreduce.Job: Counters: 55</span><br><span class="line">	File System Counters</span><br><span class="line">		FILE: Number of bytes read=128</span><br><span class="line">		FILE: Number of bytes written=2350649</span><br><span class="line">		FILE: Number of read operations=0</span><br><span class="line">		FILE: Number of large read operations=0</span><br><span class="line">		FILE: Number of write operations=0</span><br><span class="line">		HDFS: Number of bytes read=29993</span><br><span class="line">		HDFS: Number of bytes written=232</span><br><span class="line">		HDFS: Number of read operations=32</span><br><span class="line">		HDFS: Number of large read operations=0</span><br><span class="line">		HDFS: Number of write operations=2</span><br><span class="line">		HDFS: Number of bytes read erasure-coded=0</span><br><span class="line">	Job Counters </span><br><span class="line">		Killed map tasks=1</span><br><span class="line">		Launched map tasks=10</span><br><span class="line">		Launched reduce tasks=1</span><br><span class="line">		Data-local map tasks=10</span><br><span class="line">		Total time spent by all maps in occupied slots (ms)=333545</span><br><span class="line">		Total time spent by all reduces in occupied slots (ms)=18937</span><br><span class="line">		Total time spent by all map tasks (ms)=333545</span><br><span class="line">		Total time spent by all reduce tasks (ms)=18937</span><br><span class="line">		Total vcore-milliseconds taken by all map tasks=333545</span><br><span class="line">		Total vcore-milliseconds taken by all reduce tasks=18937</span><br><span class="line">		Total megabyte-milliseconds taken by all map tasks=341550080</span><br><span class="line">		Total megabyte-milliseconds taken by all reduce tasks=19391488</span><br><span class="line">	Map-Reduce Framework</span><br><span class="line">		Map input records=781</span><br><span class="line">		Map output records=4</span><br><span class="line">		Map output bytes=114</span><br><span class="line">		Map output materialized bytes=176</span><br><span class="line">		Input split bytes=1077</span><br><span class="line">		Combine input records=4</span><br><span class="line">		Combine output records=4</span><br><span class="line">		Reduce input groups=4</span><br><span class="line">		Reduce shuffle bytes=176</span><br><span class="line">		Reduce input records=4</span><br><span class="line">		Reduce output records=4</span><br><span class="line">		Spilled Records=8</span><br><span class="line">		Shuffled Maps =9</span><br><span class="line">		Failed Shuffles=0</span><br><span class="line">		Merged Map outputs=9</span><br><span class="line">		GC time elapsed (ms)=6070</span><br><span class="line">		CPU time spent (ms)=7920</span><br><span class="line">		Physical memory (bytes) snapshot=1882726400</span><br><span class="line">		Virtual memory (bytes) snapshot=27148435456</span><br><span class="line">		Total committed heap usage (bytes)=1269469184</span><br><span class="line">		Peak Map Physical memory (bytes)=211144704</span><br><span class="line">		Peak Map Virtual memory (bytes)=2715578368</span><br><span class="line">		Peak Reduce Physical memory (bytes)=106315776</span><br><span class="line">		Peak Reduce Virtual memory (bytes)=2720391168</span><br><span class="line">	Shuffle Errors</span><br><span class="line">		BAD_ID=0</span><br><span class="line">		CONNECTION=0</span><br><span class="line">		IO_ERROR=0</span><br><span class="line">		WRONG_LENGTH=0</span><br><span class="line">		WRONG_MAP=0</span><br><span class="line">		WRONG_REDUCE=0</span><br><span class="line">	File Input Format Counters </span><br><span class="line">		Bytes Read=28916</span><br><span class="line">	File Output Format Counters </span><br><span class="line">		Bytes Written=232</span><br><span class="line">2021-11-26 08:17:07,682 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032</span><br><span class="line">org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://hadoop001:9000/user/hadoop/output already exists</span><br><span class="line">	at org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:164)</span><br><span class="line">	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:277)</span><br><span class="line">	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)</span><br><span class="line">	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1565)</span><br><span class="line">	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1562)</span><br><span class="line">	at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">	at javax.security.auth.Subject.doAs(Subject.java:422)</span><br><span class="line">	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)</span><br><span class="line">	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1562)</span><br><span class="line">	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1583)</span><br><span class="line">	at org.apache.hadoop.examples.Grep.run(Grep.java:94)</span><br><span class="line">	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)</span><br><span class="line">	at org.apache.hadoop.examples.Grep.main(Grep.java:103)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span><br><span class="line">	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">	at java.lang.reflect.Method.invoke(Method.java:497)</span><br><span class="line">	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)</span><br><span class="line">	at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)</span><br><span class="line">	at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span><br><span class="line">	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">	at java.lang.reflect.Method.invoke(Method.java:497)</span><br><span class="line">	at org.apache.hadoop.util.RunJar.run(RunJar.java:323)</span><br><span class="line">	at org.apache.hadoop.util.RunJar.main(RunJar.java:236)</span><br></pre></td></tr></table></figure>

<p><img src="/2021/11/25/hdfs%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2/image-20211126093406585.png" alt="通过浏览器查看任务"></p>
<h4 id="5-停止服务"><a href="#5-停止服务" class="headerlink" title="5.停止服务"></a>5.停止服务</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ stop-yarn.sh </span><br><span class="line">Stopping nodemanagers</span><br><span class="line">localhost: WARNING: nodemanager did not stop gracefully after 5 seconds: Trying to kill with kill -9</span><br><span class="line">Stopping resourcemanager</span><br><span class="line">[hadoop@hadoop001 hadoop]$ jps</span><br></pre></td></tr></table></figure>

      
    </div>
    <div class="article-footer">
      <blockquote class="mt-2x">
  <ul class="post-copyright list-unstyled">
    
    <li class="post-copyright-link hidden-xs">
      <strong>本文链接：</strong>
      <a href="https://k12coding.github.io/2021/11/25/hdfs%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2/" title="hdfs伪分布式部署" target="_blank" rel="external">https://k12coding.github.io/2021/11/25/hdfs伪分布式部署/</a>
    </li>
    
    <li class="post-copyright-license">
      <strong>版权声明： </strong> 本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external">CC BY 4.0 CN协议</a> 许可协议。转载请注明出处！
    </li>
  </ul>
</blockquote>


<div class="panel panel-default panel-badger">
  <div class="panel-body">
    <figure class="media">
      <div class="media-left">
        <a href="https://github.com/cofess" target="_blank" class="img-burn thumb-sm visible-lg">
          <img src="/images/avatar.jpg" class="img-rounded w-full" alt="">
        </a>
      </div>
      <div class="media-body">
        <h3 class="media-heading"><a href="https://github.com/cofess" target="_blank"><span class="text-dark">昵称</span><small class="ml-1x">Web Developer &amp; Designer</small></a></h3>
        <div>个人简介。</div>
      </div>
    </figure>
  </div>
</div>


    </div>
  </article>
  
    
  <section id="comments">
  	
      <div id="vcomments"></div>
    
  </section>


  
</div>

  <nav class="bar bar-footer clearfix" data-stick-bottom>
  <div class="bar-inner">
  
  <ul class="pager pull-left">
    
    <li class="prev">
      <a href="/2021/11/25/Hadoop%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" title="Hadoop基础知识"><i class="icon icon-angle-left" aria-hidden="true"></i><span>&nbsp;&nbsp;上一篇</span></a>
    </li>
    
    
    <li class="next">
      <a href="/2021/11/24/Mysql%E9%83%A8%E7%BD%B2/" title="在Linux系统上部署Mysql"><span>下一篇&nbsp;&nbsp;</span><i class="icon icon-angle-right" aria-hidden="true"></i></a>
    </li>
    
    
  </ul>
  
  
  <!-- Button trigger modal -->
  <button type="button" class="btn btn-fancy btn-donate pop-onhover bg-gradient-warning" data-toggle="modal" data-target="#donateModal"><span>赏</span></button>
  <!-- <div class="wave-icon wave-icon-danger btn-donate" data-toggle="modal" data-target="#donateModal">
    <div class="wave-circle"><span class="icon"><i class="icon icon-bill"></i></span></div>
  </div> -->
  
  
  <div class="bar-right">
    
    <div class="share-component" data-sites="weibo,qq,wechat,facebook,twitter" data-mobile-sites="weibo,qq,qzone"></div>
    
  </div>
  </div>
</nav>
  
<!-- Modal -->
<div class="modal modal-center modal-small modal-xs-full fade" id="donateModal" tabindex="-1" role="dialog">
  <div class="modal-dialog" role="document">
    <div class="modal-content donate">
      <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
      <div class="modal-body">
        <div class="donate-box">
          <div class="donate-head">
            <p>感谢您的支持，我会继续努力的!</p>
          </div>
          <div class="tab-content">
            <div role="tabpanel" class="tab-pane fade active in" id="alipay">
              <div class="donate-payimg">
                <img src="/images/donate/alipayimg.png" alt="扫码支持" title="扫一扫" />
              </div>
              <p class="text-muted mv">扫码打赏，你说多少就多少</p>
              <p class="text-grey">打开支付宝扫一扫，即可进行扫码打赏哦</p>
            </div>
            <div role="tabpanel" class="tab-pane fade" id="wechatpay">
              <div class="donate-payimg">
                <img src="/images/donate/wechatpayimg.png" alt="扫码支持" title="扫一扫" />
              </div>
              <p class="text-muted mv">扫码打赏，你说多少就多少</p>
              <p class="text-grey">打开微信扫一扫，即可进行扫码打赏哦</p>
            </div>
          </div>
          <div class="donate-footer">
            <ul class="nav nav-tabs nav-justified" role="tablist">
              <li role="presentation" class="active">
                <a href="#alipay" id="alipay-tab" role="tab" data-toggle="tab" aria-controls="alipay" aria-expanded="true"><i class="icon icon-alipay"></i> 支付宝</a>
              </li>
              <li role="presentation" class="">
                <a href="#wechatpay" role="tab" id="wechatpay-tab" data-toggle="tab" aria-controls="wechatpay" aria-expanded="false"><i class="icon icon-wepay"></i> 微信支付</a>
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>



</main>

  <footer class="footer" itemscope itemtype="http://schema.org/WPFooter">
	
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/cofess" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
        <li><a href="http://weibo.com/cofess" target="_blank" title="Weibo" data-toggle=tooltip data-placement=top><i class="icon icon-weibo"></i></a></li>
        
        <li><a href="https://twitter.com/iwebued" target="_blank" title="Twitter" data-toggle=tooltip data-placement=top><i class="icon icon-twitter"></i></a></li>
        
        <li><a href="https://www.behance.net/cofess" target="_blank" title="Behance" data-toggle=tooltip data-placement=top><i class="icon icon-behance"></i></a></li>
        
        <li><a href="/atom.xml" target="_blank" title="Rss" data-toggle=tooltip data-placement=top><i class="icon icon-rss"></i></a></li>
        
    </ul>

    <div class="copyright">
    	
        <div class="publishby">
        	Theme by <a href="https://github.com/cofess" target="_blank"> cofess </a>base on <a href="https://github.com/cofess/hexo-theme-pure" target="_blank">pure</a>.
        </div>
    </div>
</footer>
  <script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script>
<script>
window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')
</script>

<script src="/js/plugin.min.js"></script>


<script src="/js/application.js"></script>


    <script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>






   




   
    
  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/valine"></script>
  <script type="text/javascript">
  var GUEST = ['nick', 'mail', 'link'];
  var meta = 'nick,mail,link';
  meta = meta.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#vcomments',
    verify: false,
    notify: false,
    appId: '',
    appKey: '',
    placeholder: 'Just go go',
    avatar: 'mm',
    meta: meta,
    pageSize: '10' || 10,
    visitor: false
  });
  </script>

     







</body>
</html>