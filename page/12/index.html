<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>k12的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="2">
<meta property="og:type" content="website">
<meta property="og:title" content="k12的博客">
<meta property="og:url" content="https://k12coding.github.io/page/12/index.html">
<meta property="og:site_name" content="k12的博客">
<meta property="og:description" content="2">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="k12">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="k12的博客" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">k12的博客</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">k12的笔记</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <!--
      <nav id="sub-nav">
        
          此处隐藏rss,注释掉 <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS 订阅"></a> -->
        
        <!--此处隐藏,注释掉 <a id="nav-search-btn" class="nav-icon" title="搜索"></a> 
      </nav>
      -->
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://k12coding.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-Hadoop Shell命令" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/11/26/Hadoop%20Shell%E5%91%BD%E4%BB%A4/" class="article-date">
  <time class="dt-published" datetime="2021-11-26T05:24:25.000Z" itemprop="datePublished">2021-11-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/11/26/Hadoop%20Shell%E5%91%BD%E4%BB%A4/">Hadoop Shell命令</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Hadoop-Shell命令"><a href="#Hadoop-Shell命令" class="headerlink" title="Hadoop Shell命令"></a>Hadoop Shell命令</h1><h2 id="FS-Shell"><a href="#FS-Shell" class="headerlink" title="FS Shell"></a>FS Shell</h2><p>调用文件系统(FS)Shell命令应使用 bin/hadoop fs &lt;args&gt;的形式。 所有的的FS shell命令使用URI路径作为参数。URI格式是<em>scheme://authority/path</em>。对HDFS文件系统，scheme是<em>hdfs</em>，对本地文件系统，scheme是<em>file</em>。其中scheme和authority参数都是可选的，如果未加指定，就会使用配置中指定的默认scheme。一个HDFS文件或目录比如*/parent/child<em>可以表示成</em>hdfs://namenode:namenodeport/parent/child<em>，或者更简单的</em>/parent/child<em>（假设你配置文件中的默认值是</em>namenode:namenodeport<em>）。大多数FS Shell命令的行为和对应的Unix Shell命令类似，不同之处会在下面介绍各命令使用详情时指出。出错信息会输出到</em>stderr<em>，其他信息输出到</em>stdout*。</p>
        
          <p class="article-more-link" align="center">
            <a href="/2021/11/26/Hadoop%20Shell%E5%91%BD%E4%BB%A4/#more">阅读更多</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://k12coding.github.io/2021/11/26/Hadoop%20Shell%E5%91%BD%E4%BB%A4/" data-id="cl3b9tuac000bakudchuf20sv" data-title="Hadoop Shell命令" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Hadoop基础知识" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/11/25/Hadoop%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" class="article-date">
  <time class="dt-published" datetime="2021-11-25T12:44:11.000Z" itemprop="datePublished">2021-11-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/11/25/Hadoop%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">Hadoop基础知识</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="一、Hadoop"><a href="#一、Hadoop" class="headerlink" title="一、Hadoop"></a>一、Hadoop</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>狭义上：以Hadoop软件本身（hadoop.apache.org），指一个用于大数据分布式存储(HDFS)，分布式计算(MapReduce)和资源调度(YARN)的平台，这三样只能用来做离线批处理，不能用于实时处理，因此才需要生态系统的其他的组件。</p>
<p>广义上：指的是hadoop的生态系统，即其他各种组件在内的一整套软件（sqoop，flume，spark，flink，hbase，kafka，cdh环境等）。hadoop生态系统是一个很庞大的概念，hadoop只是其中最重要最基础的部分，生态系统的每一个子系统只结局的某一个特定的问题域。不是一个全能系统，而是多个小而精的系统。</p>
<h2 id="组成"><a href="#组成" class="headerlink" title="组成"></a>组成</h2><p>Hadoop common：提供一些通用的功能支持其他hadoop模块。</p>
<p><strong>Hadoop Distributed File System</strong>：即分布式文件系统，简称HDFS。主要用来做数据存储，并提供对应用数据高吞吐量的访问。</p>
<p><strong>Hadoop MapReduce</strong>：基于yarn的，能用来并行处理大数据集的计算框架。</p>
<p><strong>Hadoop Yarn</strong>：用于作业调度和集群资源管理的框架。</p>
<h1 id="二、HDFS概述"><a href="#二、HDFS概述" class="headerlink" title="二、HDFS概述"></a>二、HDFS概述</h1><h2 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h2><p>Hdfs（hadoop distribute file system），他是一个文件系统，用于存储文件，通过目录树来定位文件：其次，他是分布式的，有很多服务器联合起来实现其功能，集群中的服务器有各自的角色。</p>
<p>Hdfs的使用场景，适合一次写入，多次读出的场景，且不支持文件的修改。适合用来做数据存放。</p>
<h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ul>
<li><p>高容错性</p>
<p>数据自动保存多个副本。 （默认是三分）通过增加副本的形式，提高容错性</p>
<p>某一个副本丢失以后，它可以自动恢复</p>
</li>
<li><p>适合大数据处理</p>
<p>数据规模：能够处理数据规模达到GB、TB、甚至PB级别的数据</p>
<p>文件规模：能够处理百万规模以上的文件数量，</p>
</li>
<li><p>可构建在廉价机器上，通过多副本机制，提高可靠性</p>
</li>
</ul>
<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><ul>
<li>不适合低延时数据访问，比如毫秒级的存储数据，是做不到的</li>
<li>无法高效的对大量小文件进行存储<ul>
<li>存储大量小文件的话，它会占用NameNode大量的内存来存储文件目录和块信息。这样是不可取的，因为NameNode的内存总是有限的</li>
<li>小文件存储的寻址时间会超过读取时间，它违反了HDFS的设计目标</li>
</ul>
</li>
<li>不支持并发写入、文件随机修改<ul>
<li>一个文件只能有一个写，不允许多个线程同时写（重点）</li>
<li>仅支持数据append（追加），不支持文件的随机修改</li>
</ul>
</li>
</ul>
<h2 id="hdfs支持的三种模式"><a href="#hdfs支持的三种模式" class="headerlink" title="hdfs支持的三种模式"></a>hdfs支持的三种模式</h2><ul>
<li>Local (Standalone) Mode ：本地模式，不启动进程，实际工作中从来没用过</li>
<li>Pseudo-Distributed Mode：伪分布式，启动单个进程（1大 小），应用场景：学习</li>
<li>Fully-Distributed Mode    集群模式，启动多个进程（2个大多个小），应用场景：生产（CDH,按量付费）</li>
</ul>
<h1 id="三、HDFS架构"><a href="#三、HDFS架构" class="headerlink" title="三、HDFS架构"></a>三、HDFS架构</h1><p> <img src="/2021/11/25/Hadoop%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/1598893-20191129134655673-2083411338.png" alt="img"></p>
<p>1）<strong>NameNode（nn）</strong>：Master，它是一个主管、管理者。</p>
<ul>
<li><p>管理HDFS的名称空间</p>
<ul>
<li>文件的名称、目录结构、权限、大小、所属用户用户组  时间</li>
</ul>
</li>
<li><p>处理客户端读写请求</p>
</li>
<li><p>配置副本策略</p>
</li>
<li><p>管理数据块（Block）映射信息</p>
<ul>
<li><p>文件被切割哪些块、块(块本身+2副本=3个块)分布在哪些DN节点上，blockmap 块映射。</p>
</li>
<li><p>不会持久化存储这种映射关系，是通过集群<strong>启动</strong>和<strong>运行</strong>时候，DN定期给NN汇报blockreport（BR），然后NN在内存中动态维护这种映射关系；</p>
</li>
</ul>
</li>
</ul>
<p>2）<strong>DataNode</strong>：Slave。NameNode下达命令，DataNode执行实际的操作</p>
<ul>
<li><p>存储实际的数据块和块的校验和</p>
</li>
<li><p>执行数据块的读/写操作</p>
</li>
<li><p>定期给NN发送块报告</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dfs.blockreport.intervalMsec  21600000=6h</span><br><span class="line">dfs.datanode.directoryscan.interval  21600s=6h</span><br></pre></td></tr></table></figure></li>
</ul>
<p>3）<strong>Client</strong>：客户端</p>
<ul>
<li>文件切分。文件上传HDFS的时候，Client将文件切分成一个一个的Block，然后进行上传</li>
<li>与NameNode交互，获取文件的位置信息</li>
<li>与DataNode交互，读取或者写入数据</li>
<li>Client提供一些命令来管理HDFS，比如NameNode格式化</li>
<li>Client可以通过一些命令来访问HDFS，比如对HDFS增删查改操作</li>
</ul>
<p>4）<strong>Secondary NameNode</strong>：并非NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。</p>
<ul>
<li><p>辅助NameNode，分担其工作量，比如定期合并Fsimage和Edits，并推送给NameNode</p>
<ul>
<li><p>edits 编辑日志文件</p>
</li>
<li><p>fsimage 镜像文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">NN:</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop      42 Nov 28 08:07 edits_0000000000000000256-0000000000000000257</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop      42 Nov 28 09:07 edits_0000000000000000258-0000000000000000259</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop 1048576 Nov 28 09:07 edits_inprogress_0000000000000000260</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop    2874 Nov 28 08:07 fsimage_0000000000000000257</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop      62 Nov 28 08:07 fsimage_0000000000000000257.md5</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop    2874 Nov 28 09:07 fsimage_0000000000000000259</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop      62 Nov 28 09:07 fsimage_0000000000000000259.md5</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop       4 Nov 28 09:07 seen_txid</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop     219 Nov 26 22:01 VERSION</span><br><span class="line">[hadoop@hadoop001 current]$ pwd</span><br><span class="line">/home/hadoop/tmp/hadoop-hadoop/dfs/name/current</span><br><span class="line"></span><br><span class="line">SNN:</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop      42 Nov 28 08:07 edits_0000000000000000256-0000000000000000257</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop      42 Nov 28 09:07 edits_0000000000000000258-0000000000000000259</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop    2874 Nov 28 08:07 fsimage_0000000000000000257</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop      62 Nov 28 08:07 fsimage_0000000000000000257.md5</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop    2874 Nov 28 09:07 fsimage_0000000000000000259</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop      62 Nov 28 09:07 fsimage_0000000000000000259.md5</span><br><span class="line"></span><br><span class="line">将NN的 </span><br><span class="line">fsimage_0000000000000000257</span><br><span class="line">edits_0000000000000000258-0000000000000000259</span><br><span class="line">拿到SNN，进行【合并】，生成fsimage_0000000000000000259文件，然后将此文件【推送】给NN；</span><br><span class="line">同时，NN在新的编辑日志文件edits_inprogress_0000000000000000260</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>在紧急情况下，可辅助恢复NameNode</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">关于NN的补充：在大数据早期的时候，只有NN一个，假如挂了就真的挂了。</span><br><span class="line">中期的时候，新增SNN来定期来合并、 备份 、推送，但是这样的也就是满足一定条件，如1小时，备份1次。例如，12点合并备份，但是12点半挂了，从SNN恢复到NN，只能恢复12点的时刻的元数据，丢了12点-12点半期间的元数据。</span><br><span class="line"></span><br><span class="line">后期就取消SNN，新建一个实时NN，作为高可靠 HA。</span><br><span class="line">NN Active</span><br><span class="line">NN Standby 实时的等待active NN挂了，瞬间启动Standby--&gt;Active，对外提供读写服务。</span><br></pre></td></tr></table></figure>



<p>HDFS中的文件在物理上是分块存储，块的大小可以通过配置参数（dfs.Blocksize）来规定，默认大小在hadoop2.x版本中是128M,老版本是64M</p>
<p><strong>思考：为什么块的大小不能设置太小，也不能设置太大？</strong></p>
<p>（1）HDFS的块设置太小，会增加寻址时间，程序一直在找块的开始位置</p>
<p>（2）如果块设置的太大，从磁盘传输数据的时间会明显大于定位这个块开始位置所需的时间。导致程序在处理这块数据时，会非常慢。</p>
<p><strong>总结：HDFS块的大小设置主要取决于磁盘传输速率</strong></p>
<h1 id="四、MapReduce-on-Yarn-Yarn的工作流程"><a href="#四、MapReduce-on-Yarn-Yarn的工作流程" class="headerlink" title="四、MapReduce on Yarn/Yarn的工作流程"></a>四、MapReduce on Yarn/Yarn的工作流程</h1><p><img src="/2021/11/25/Hadoop%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/mronyarn.jpg" alt="MapReduce on Yarn"></p>
<p>1.客户端client向ResourceManager提交应用程序/Application/作业JOB，包含application master程序，启动application master的命令等，并请求一个ApplicationMaster实例<br>2.RM为该job分配第一个container,与对应的NM通信，要求它在这个container启动作业的application master<br>3.application master向applications manager注册，这样用户就可以通过RM Web查看job的状态,一直到最后<br>4.application master采用轮询的方式通过【RPC】协议向resource scheduler申请和领取资源（哪台DN机器，领取多少内存 CPU）<br>5.一旦application master申请到资源后，与对应的NM通信，要求启动task<br>6.NM为任务设置好运行环境后，将任务的启动命令写到一个脚本中，并通过该脚本启动任务，运行任务<br>7.各个任务 task 通过【RPC】协议汇报自己的状态和进度，以让application master随时掌握各个任务的运行状态，从而在任务失败时，重启启动任务。<br>8.job运行完成后，application master向applications manager注销并关闭自己。</p>
<p>总结:<br>启动主程序，领取资源；1-4<br>运行任务，直到完成；  5-8</p>
<p>客户端提交job给 Applications Manager 连接Node Manager去申请一个Container的容器，这个容器运行作业的App Mstr的主程序，启动后向App Manager进行注册，然后可以访问URL界面，然后App Mastr向 Resource Scheduler申请资源，拿到一个资源的列表，和对应的NodeManager进行通信，去启动对应的Container容器，去运行 Reduce Task 和 Map Task （两个先后运行顺序随机运行），它们是向App Mstr进行汇报它们的运行状态， 当所有作业运行完成后还需要向Applications Manager进行汇报并注销和关闭</p>
<p>yarn中，它按照实际资源需求为每个任务分配资源，比如一个任务需要1GB内存，1个CPU，则为其分配对应的资源，而资源是用container表示的，container是一个抽象概念，它实际上是一个JAVA对象，里面有资源描述（资源所在节点，资源优先级，资源量，比如CPU量，内存量等）。当一个applicationmaster向RM申请资源时，RM会以container的形式将资源发送给对应的applicationmaster，applicationmaster收到container后，与对应的nodemanager通信，告诉它我要利用这个container运行某个任务。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://k12coding.github.io/2021/11/25/Hadoop%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" data-id="cl3b9tuae000dakudb6bt3y8d" data-title="Hadoop基础知识" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-hdfs伪分布式部署" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/11/25/hdfs%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2/" class="article-date">
  <time class="dt-published" datetime="2021-11-25T05:09:16.000Z" itemprop="datePublished">2021-11-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/11/25/hdfs%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2/">hdfs伪分布式部署</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="hdfs伪分布式部署"><a href="#hdfs伪分布式部署" class="headerlink" title="hdfs伪分布式部署"></a>hdfs伪分布式部署</h1><p><a target="_blank" rel="noopener" href="https://hadoop.apache.org/release.html">Releases Archive</a>中选择要部署的版本，我们以<a target="_blank" rel="noopener" href="https://hadoop.apache.org/release/3.2.2.html">Release 3.2.2 available</a>版本为例</p>
<p>参考文档：<a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r3.2.2/hadoop-project-dist/hadoop-common/SingleCluster.html">Hadoop: Setting up a Single Node Cluster.</a></p>
<h2 id="一、部署"><a href="#一、部署" class="headerlink" title="一、部署"></a>一、部署</h2><h3 id="1-软件要求"><a href="#1-软件要求" class="headerlink" title="1.软件要求"></a>1.软件要求</h3><ul>
<li>Java：Hadoop对Java版本有要求，具体参考<a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/HADOOP/Hadoop+Java+Versions">Hadoop Java Versions</a>，基本上Java8通用</li>
<li>ssh</li>
</ul>
<p>补充：组件名称<code>大写-数字</code>，如：SPARK-2908，表明该组件是有问题的</p>
        
          <p class="article-more-link" align="center">
            <a href="/2021/11/25/hdfs%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2/#more">阅读更多</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://k12coding.github.io/2021/11/25/hdfs%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2/" data-id="cl3b9tub9001oakud0g4i7afr" data-title="hdfs伪分布式部署" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Mysql部署" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/11/24/Mysql%E9%83%A8%E7%BD%B2/" class="article-date">
  <time class="dt-published" datetime="2021-11-23T22:57:19.000Z" itemprop="datePublished">2021-11-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/11/24/Mysql%E9%83%A8%E7%BD%B2/">在Linux系统上部署Mysql</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="在Linux系统上部署Mysql"><a href="#在Linux系统上部署Mysql" class="headerlink" title="在Linux系统上部署Mysql"></a>在Linux系统上部署Mysql</h1><p>在Linux上部署Mysql的两种方式：</p>
<ul>
<li>rpm包部署：操作简单，适合学习的场景</li>
<li>tar包部署：定制化配置，生产上一般用tar包部署</li>
</ul>
        
          <p class="article-more-link" align="center">
            <a href="/2021/11/24/Mysql%E9%83%A8%E7%BD%B2/#more">阅读更多</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://k12coding.github.io/2021/11/24/Mysql%E9%83%A8%E7%BD%B2/" data-id="cl3b9tub7001lakud41ac51wt" data-title="在Linux系统上部署Mysql" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-什么是尾递归" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/11/19/%E4%BB%80%E4%B9%88%E6%98%AF%E5%B0%BE%E9%80%92%E5%BD%92/" class="article-date">
  <time class="dt-published" datetime="2021-11-19T11:23:17.000Z" itemprop="datePublished">2021-11-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/11/19/%E4%BB%80%E4%B9%88%E6%98%AF%E5%B0%BE%E9%80%92%E5%BD%92/">什么是尾递归</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h3 id="尾递归"><a href="#尾递归" class="headerlink" title="尾递归"></a>尾递归</h3><h4 id="一、概念"><a href="#一、概念" class="headerlink" title="一、概念"></a>一、概念</h4><p>​    如果一个函数中所有递归形式的调用都出现在函数的末尾，我们称这个递归函数是尾递归的。当递归调用是整个函数体中最后执行的语句且<strong>它的返回值不属于表达式的一部分</strong>时，这个递归调用就是尾递归。尾递归函数的特点是在<strong>回归过程中不用做任何操作</strong>，这个特性很重要，因为大多数现代的编译器会利用这种特点自动生成优化的代码。</p>
        
          <p class="article-more-link" align="center">
            <a href="/2021/11/19/%E4%BB%80%E4%B9%88%E6%98%AF%E5%B0%BE%E9%80%92%E5%BD%92/#more">阅读更多</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://k12coding.github.io/2021/11/19/%E4%BB%80%E4%B9%88%E6%98%AF%E5%B0%BE%E9%80%92%E5%BD%92/" data-id="cl3b9tuav0014akud2y8r30al" data-title="什么是尾递归" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/11/">&laquo; 上一页</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="page-number" href="/page/11/">11</a><span class="page-number current">12</span><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" href="/page/13/">下一页 &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/05/">五月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">三月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/">二月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">一月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">十二月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">十一月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/10/">十月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">九月 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/05/17/Flume%E7%9A%84%E4%BD%BF%E7%94%A8%E6%A1%88%E4%BE%8B/">Flume的使用案例</a>
          </li>
        
          <li>
            <a href="/2022/05/17/Flume-v1-9-0%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99ERROR-org-apache-flume-sink-hdfs-HDFSEventSink-process/">Flume v1.9.0启动报错ERROR - org.apache.flume.sink.hdfs.HDFSEventSink.process</a>
          </li>
        
          <li>
            <a href="/2022/05/16/Flume%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/">Flume介绍与使用</a>
          </li>
        
          <li>
            <a href="/2022/05/13/Kafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%83%BD%E9%82%A3%E4%B9%88%E5%BF%AB/">Kafka为什么能那么快</a>
          </li>
        
          <li>
            <a href="/2022/03/26/%E6%88%91%E7%9A%84mysql%E7%AC%94%E8%AE%B0/">我的mysql笔记</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 k12<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>